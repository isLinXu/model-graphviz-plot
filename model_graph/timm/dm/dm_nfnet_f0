digraph {
	graph [size="320.25,320.25"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140614972231984 [label="
 (1, 1000)" fillcolor=darkolivegreen1]
	140615278962624 [label=AddmmBackward0]
	140615278962912 -> 140615278962624
	140615279023344 [label="head.fc.bias
 (1000)" fillcolor=lightblue]
	140615279023344 -> 140615278962912
	140615278962912 [label=AccumulateGrad]
	140615278962864 -> 140615278962624
	140615278962864 [label=ReshapeAliasBackward0]
	140615278963920 -> 140615278962864
	140615278963920 [label=MeanBackward1]
	140614735737760 -> 140615278963920
	140614735737760 [label=MulBackward0]
	140614735737904 -> 140614735737760
	140614735737904 [label=GeluBackward0]
	140614735737856 -> 140614735737904
	140614735737856 [label=ConvolutionBackward0]
	140614735738192 -> 140614735737856
	140614735738192 [label=AddBackward0]
	140614735738048 -> 140614735738192
	140614735738048 [label=MulBackward0]
	140614735738000 -> 140614735738048
	140614735738000 [label=MulBackward0]
	140614735737280 -> 140614735738000
	140614735737280 [label=MulBackward0]
	140614735738480 -> 140614735737280
	140614735738480 [label=MulBackward0]
	140614735738576 -> 140614735738480
	140614735738576 [label=ConvolutionBackward0]
	140614735738720 -> 140614735738576
	140614735738720 [label=MulBackward0]
	140614735738912 -> 140614735738720
	140614735738912 [label=GeluBackward0]
	140614735739008 -> 140614735738912
	140614735739008 [label=ConvolutionBackward0]
	140614735739104 -> 140614735739008
	140614735739104 [label=MulBackward0]
	140614735739296 -> 140614735739104
	140614735739296 [label=GeluBackward0]
	140614735739392 -> 140614735739296
	140614735739392 [label=ConvolutionBackward0]
	140614735739488 -> 140614735739392
	140614735739488 [label=MulBackward0]
	140614735739680 -> 140614735739488
	140614735739680 [label=GeluBackward0]
	140614735739776 -> 140614735739680
	140614735739776 [label=ConvolutionBackward0]
	140614735739872 -> 140614735739776
	140614735739872 [label=MulBackward0]
	140614735740064 -> 140614735739872
	140614735740064 [label=MulBackward0]
	140614735740160 -> 140614735740064
	140614735740160 [label=GeluBackward0]
	140614735737328 -> 140614735740160
	140614735737328 [label=AddBackward0]
	140614735740304 -> 140614735737328
	140614735740304 [label=MulBackward0]
	140614735740448 -> 140614735740304
	140614735740448 [label=MulBackward0]
	140614735740544 -> 140614735740448
	140614735740544 [label=MulBackward0]
	140614735740688 -> 140614735740544
	140614735740688 [label=MulBackward0]
	140614735740784 -> 140614735740688
	140614735740784 [label=ConvolutionBackward0]
	140614735740880 -> 140614735740784
	140614735740880 [label=MulBackward0]
	140614972272896 -> 140614735740880
	140614972272896 [label=GeluBackward0]
	140614972272992 -> 140614972272896
	140614972272992 [label=ConvolutionBackward0]
	140614972273088 -> 140614972272992
	140614972273088 [label=MulBackward0]
	140614972273280 -> 140614972273088
	140614972273280 [label=GeluBackward0]
	140614972273376 -> 140614972273280
	140614972273376 [label=ConvolutionBackward0]
	140614972273472 -> 140614972273376
	140614972273472 [label=MulBackward0]
	140614972273664 -> 140614972273472
	140614972273664 [label=GeluBackward0]
	140614972273760 -> 140614972273664
	140614972273760 [label=ConvolutionBackward0]
	140614972273856 -> 140614972273760
	140614972273856 [label=MulBackward0]
	140614972274048 -> 140614972273856
	140614972274048 [label=MulBackward0]
	140614972274144 -> 140614972274048
	140614972274144 [label=GeluBackward0]
	140614735739968 -> 140614972274144
	140614735739968 [label=AddBackward0]
	140614972274288 -> 140614735739968
	140614972274288 [label=MulBackward0]
	140614972274432 -> 140614972274288
	140614972274432 [label=MulBackward0]
	140614972274528 -> 140614972274432
	140614972274528 [label=MulBackward0]
	140614972274672 -> 140614972274528
	140614972274672 [label=MulBackward0]
	140614972274768 -> 140614972274672
	140614972274768 [label=ConvolutionBackward0]
	140614972274912 -> 140614972274768
	140614972274912 [label=MulBackward0]
	140614972275104 -> 140614972274912
	140614972275104 [label=GeluBackward0]
	140614972275200 -> 140614972275104
	140614972275200 [label=ConvolutionBackward0]
	140614972275296 -> 140614972275200
	140614972275296 [label=MulBackward0]
	140614972275488 -> 140614972275296
	140614972275488 [label=GeluBackward0]
	140614972275584 -> 140614972275488
	140614972275584 [label=ConvolutionBackward0]
	140614972275680 -> 140614972275584
	140614972275680 [label=ConstantPadNdBackward0]
	140614972275872 -> 140614972275680
	140614972275872 [label=MulBackward0]
	140614972275968 -> 140614972275872
	140614972275968 [label=GeluBackward0]
	140614972276064 -> 140614972275968
	140614972276064 [label=ConvolutionBackward0]
	140614972276160 -> 140614972276064
	140614972276160 [label=MulBackward0]
	140614972276352 -> 140614972276160
	140614972276352 [label=MulBackward0]
	140614972276448 -> 140614972276352
	140614972276448 [label=GeluBackward0]
	140614972276544 -> 140614972276448
	140614972276544 [label=AddBackward0]
	140614972276640 -> 140614972276544
	140614972276640 [label=MulBackward0]
	140614972276688 -> 140614972276640
	140614972276688 [label=MulBackward0]
	140614972285136 -> 140614972276688
	140614972285136 [label=MulBackward0]
	140614972285280 -> 140614972285136
	140614972285280 [label=MulBackward0]
	140614972285376 -> 140614972285280
	140614972285376 [label=ConvolutionBackward0]
	140614972285520 -> 140614972285376
	140614972285520 [label=MulBackward0]
	140614972285712 -> 140614972285520
	140614972285712 [label=GeluBackward0]
	140614972285808 -> 140614972285712
	140614972285808 [label=ConvolutionBackward0]
	140614972285904 -> 140614972285808
	140614972285904 [label=MulBackward0]
	140614972286096 -> 140614972285904
	140614972286096 [label=GeluBackward0]
	140614972286192 -> 140614972286096
	140614972286192 [label=ConvolutionBackward0]
	140614972286240 -> 140614972286192
	140614972286240 [label=MulBackward0]
	140614972286528 -> 140614972286240
	140614972286528 [label=GeluBackward0]
	140614972286624 -> 140614972286528
	140614972286624 [label=ConvolutionBackward0]
	140614972286672 -> 140614972286624
	140614972286672 [label=MulBackward0]
	140614972286960 -> 140614972286672
	140614972286960 [label=MulBackward0]
	140614972287056 -> 140614972286960
	140614972287056 [label=GeluBackward0]
	140614972276592 -> 140614972287056
	140614972276592 [label=AddBackward0]
	140614972286864 -> 140614972276592
	140614972286864 [label=MulBackward0]
	140614972287392 -> 140614972286864
	140614972287392 [label=MulBackward0]
	140614972287488 -> 140614972287392
	140614972287488 [label=MulBackward0]
	140614972287632 -> 140614972287488
	140614972287632 [label=MulBackward0]
	140614972287728 -> 140614972287632
	140614972287728 [label=ConvolutionBackward0]
	140614972287872 -> 140614972287728
	140614972287872 [label=MulBackward0]
	140614972288064 -> 140614972287872
	140614972288064 [label=GeluBackward0]
	140614972288160 -> 140614972288064
	140614972288160 [label=ConvolutionBackward0]
	140614972288208 -> 140614972288160
	140614972288208 [label=MulBackward0]
	140614972288496 -> 140614972288208
	140614972288496 [label=GeluBackward0]
	140614972288592 -> 140614972288496
	140614972288592 [label=ConvolutionBackward0]
	140614972288640 -> 140614972288592
	140614972288640 [label=MulBackward0]
	140614972288928 -> 140614972288640
	140614972288928 [label=GeluBackward0]
	140614972288976 -> 140614972288928
	140614972288976 [label=ConvolutionBackward0]
	140614972297328 -> 140614972288976
	140614972297328 [label=MulBackward0]
	140614972297616 -> 140614972297328
	140614972297616 [label=MulBackward0]
	140614972297712 -> 140614972297616
	140614972297712 [label=GeluBackward0]
	140614972287104 -> 140614972297712
	140614972287104 [label=AddBackward0]
	140614972297520 -> 140614972287104
	140614972297520 [label=MulBackward0]
	140614972298048 -> 140614972297520
	140614972298048 [label=MulBackward0]
	140614972298144 -> 140614972298048
	140614972298144 [label=MulBackward0]
	140614972298288 -> 140614972298144
	140614972298288 [label=MulBackward0]
	140614972298384 -> 140614972298288
	140614972298384 [label=ConvolutionBackward0]
	140614972298528 -> 140614972298384
	140614972298528 [label=MulBackward0]
	140614972298720 -> 140614972298528
	140614972298720 [label=GeluBackward0]
	140614972298816 -> 140614972298720
	140614972298816 [label=ConvolutionBackward0]
	140614972298864 -> 140614972298816
	140614972298864 [label=MulBackward0]
	140614972299152 -> 140614972298864
	140614972299152 [label=GeluBackward0]
	140614972299248 -> 140614972299152
	140614972299248 [label=ConvolutionBackward0]
	140614972299296 -> 140614972299248
	140614972299296 [label=MulBackward0]
	140614972299584 -> 140614972299296
	140614972299584 [label=GeluBackward0]
	140614972299680 -> 140614972299584
	140614972299680 [label=ConvolutionBackward0]
	140614972299728 -> 140614972299680
	140614972299728 [label=MulBackward0]
	140614972300016 -> 140614972299728
	140614972300016 [label=MulBackward0]
	140614972300112 -> 140614972300016
	140614972300112 [label=GeluBackward0]
	140614972297760 -> 140614972300112
	140614972297760 [label=AddBackward0]
	140614972299920 -> 140614972297760
	140614972299920 [label=MulBackward0]
	140614972300448 -> 140614972299920
	140614972300448 [label=MulBackward0]
	140614972300544 -> 140614972300448
	140614972300544 [label=MulBackward0]
	140614972300688 -> 140614972300544
	140614972300688 [label=MulBackward0]
	140614972300784 -> 140614972300688
	140614972300784 [label=ConvolutionBackward0]
	140614972300928 -> 140614972300784
	140614972300928 [label=MulBackward0]
	140614972301120 -> 140614972300928
	140614972301120 [label=GeluBackward0]
	140614972301216 -> 140614972301120
	140614972301216 [label=ConvolutionBackward0]
	140614972301024 -> 140614972301216
	140614972301024 [label=MulBackward0]
	140614972309808 -> 140614972301024
	140614972309808 [label=GeluBackward0]
	140614972309904 -> 140614972309808
	140614972309904 [label=ConvolutionBackward0]
	140614972309952 -> 140614972309904
	140614972309952 [label=MulBackward0]
	140614972310240 -> 140614972309952
	140614972310240 [label=GeluBackward0]
	140614972310336 -> 140614972310240
	140614972310336 [label=ConvolutionBackward0]
	140614972310384 -> 140614972310336
	140614972310384 [label=MulBackward0]
	140614972310672 -> 140614972310384
	140614972310672 [label=MulBackward0]
	140614972310768 -> 140614972310672
	140614972310768 [label=GeluBackward0]
	140614972300160 -> 140614972310768
	140614972300160 [label=AddBackward0]
	140614972310576 -> 140614972300160
	140614972310576 [label=MulBackward0]
	140614972311104 -> 140614972310576
	140614972311104 [label=MulBackward0]
	140614972311200 -> 140614972311104
	140614972311200 [label=MulBackward0]
	140614972311344 -> 140614972311200
	140614972311344 [label=MulBackward0]
	140614972311440 -> 140614972311344
	140614972311440 [label=ConvolutionBackward0]
	140614972311584 -> 140614972311440
	140614972311584 [label=MulBackward0]
	140614972311776 -> 140614972311584
	140614972311776 [label=GeluBackward0]
	140614972311872 -> 140614972311776
	140614972311872 [label=ConvolutionBackward0]
	140614972311920 -> 140614972311872
	140614972311920 [label=MulBackward0]
	140614972312208 -> 140614972311920
	140614972312208 [label=GeluBackward0]
	140614972312304 -> 140614972312208
	140614972312304 [label=ConvolutionBackward0]
	140614972312352 -> 140614972312304
	140614972312352 [label=MulBackward0]
	140614972312640 -> 140614972312352
	140614972312640 [label=GeluBackward0]
	140614972312736 -> 140614972312640
	140614972312736 [label=ConvolutionBackward0]
	140614972312784 -> 140614972312736
	140614972312784 [label=MulBackward0]
	140614972313072 -> 140614972312784
	140614972313072 [label=MulBackward0]
	140614972313168 -> 140614972313072
	140614972313168 [label=GeluBackward0]
	140614972310816 -> 140614972313168
	140614972310816 [label=AddBackward0]
	140614972312976 -> 140614972310816
	140614972312976 [label=MulBackward0]
	140614972313504 -> 140614972312976
	140614972313504 [label=MulBackward0]
	140614972313552 -> 140614972313504
	140614972313552 [label=MulBackward0]
	140614972326096 -> 140614972313552
	140614972326096 [label=MulBackward0]
	140614972326192 -> 140614972326096
	140614972326192 [label=ConvolutionBackward0]
	140614972326336 -> 140614972326192
	140614972326336 [label=MulBackward0]
	140614972326528 -> 140614972326336
	140614972326528 [label=GeluBackward0]
	140614972326624 -> 140614972326528
	140614972326624 [label=ConvolutionBackward0]
	140614972326672 -> 140614972326624
	140614972326672 [label=MulBackward0]
	140614972326960 -> 140614972326672
	140614972326960 [label=GeluBackward0]
	140614972327056 -> 140614972326960
	140614972327056 [label=ConvolutionBackward0]
	140614972327104 -> 140614972327056
	140614972327104 [label=ConstantPadNdBackward0]
	140614972327392 -> 140614972327104
	140614972327392 [label=MulBackward0]
	140614972327440 -> 140614972327392
	140614972327440 [label=GeluBackward0]
	140614972327632 -> 140614972327440
	140614972327632 [label=ConvolutionBackward0]
	140614972327680 -> 140614972327632
	140614972327680 [label=MulBackward0]
	140614972327968 -> 140614972327680
	140614972327968 [label=MulBackward0]
	140614972328064 -> 140614972327968
	140614972328064 [label=GeluBackward0]
	140614972328160 -> 140614972328064
	140614972328160 [label=AddBackward0]
	140614972328208 -> 140614972328160
	140614972328208 [label=MulBackward0]
	140614972328448 -> 140614972328208
	140614972328448 [label=MulBackward0]
	140614972328544 -> 140614972328448
	140614972328544 [label=MulBackward0]
	140614972328688 -> 140614972328544
	140614972328688 [label=MulBackward0]
	140614972328784 -> 140614972328688
	140614972328784 [label=ConvolutionBackward0]
	140614972328928 -> 140614972328784
	140614972328928 [label=MulBackward0]
	140614972329120 -> 140614972328928
	140614972329120 [label=GeluBackward0]
	140614972329216 -> 140614972329120
	140614972329216 [label=ConvolutionBackward0]
	140614972329264 -> 140614972329216
	140614972329264 [label=MulBackward0]
	140614972329552 -> 140614972329264
	140614972329552 [label=GeluBackward0]
	140614972329648 -> 140614972329552
	140614972329648 [label=ConvolutionBackward0]
	140614972329696 -> 140614972329648
	140614972329696 [label=MulBackward0]
	140614972329936 -> 140614972329696
	140614972329936 [label=GeluBackward0]
	140614972342432 -> 140614972329936
	140614972342432 [label=ConvolutionBackward0]
	140614972342480 -> 140614972342432
	140614972342480 [label=MulBackward0]
	140614972342768 -> 140614972342480
	140614972342768 [label=MulBackward0]
	140614972342864 -> 140614972342768
	140614972342864 [label=GeluBackward0]
	140614972327872 -> 140614972342864
	140614972327872 [label=AddBackward0]
	140614972342672 -> 140614972327872
	140614972342672 [label=MulBackward0]
	140614972343200 -> 140614972342672
	140614972343200 [label=MulBackward0]
	140614972343296 -> 140614972343200
	140614972343296 [label=MulBackward0]
	140614972343440 -> 140614972343296
	140614972343440 [label=MulBackward0]
	140614972343536 -> 140614972343440
	140614972343536 [label=ConvolutionBackward0]
	140614972343680 -> 140614972343536
	140614972343680 [label=MulBackward0]
	140614972343872 -> 140614972343680
	140614972343872 [label=GeluBackward0]
	140614972343968 -> 140614972343872
	140614972343968 [label=ConvolutionBackward0]
	140614972344016 -> 140614972343968
	140614972344016 [label=MulBackward0]
	140614972344304 -> 140614972344016
	140614972344304 [label=GeluBackward0]
	140614972344400 -> 140614972344304
	140614972344400 [label=ConvolutionBackward0]
	140614972344448 -> 140614972344400
	140614972344448 [label=ConstantPadNdBackward0]
	140614972344736 -> 140614972344448
	140614972344736 [label=MulBackward0]
	140614972344784 -> 140614972344736
	140614972344784 [label=GeluBackward0]
	140614972344976 -> 140614972344784
	140614972344976 [label=ConvolutionBackward0]
	140614972345024 -> 140614972344976
	140614972345024 [label=MulBackward0]
	140614972345312 -> 140614972345024
	140614972345312 [label=MulBackward0]
	140614972345408 -> 140614972345312
	140614972345408 [label=GeluBackward0]
	140614972345504 -> 140614972345408
	140614972345504 [label=AddBackward0]
	140614972345552 -> 140614972345504
	140614972345552 [label=MulBackward0]
	140614972345792 -> 140614972345552
	140614972345792 [label=MulBackward0]
	140614972345888 -> 140614972345792
	140614972345888 [label=MulBackward0]
	140614972346032 -> 140614972345888
	140614972346032 [label=MulBackward0]
	140614972346128 -> 140614972346032
	140614972346128 [label=ConvolutionBackward0]
	140614972346272 -> 140614972346128
	140614972346272 [label=MulBackward0]
	140614972358816 -> 140614972346272
	140614972358816 [label=GeluBackward0]
	140614972358912 -> 140614972358816
	140614972358912 [label=ConvolutionBackward0]
	140614972358960 -> 140614972358912
	140614972358960 [label=MulBackward0]
	140614972359248 -> 140614972358960
	140614972359248 [label=GeluBackward0]
	140614972359344 -> 140614972359248
	140614972359344 [label=ConvolutionBackward0]
	140614972359392 -> 140614972359344
	140614972359392 [label=MulBackward0]
	140614972359680 -> 140614972359392
	140614972359680 [label=GeluBackward0]
	140614972359776 -> 140614972359680
	140614972359776 [label=ConvolutionBackward0]
	140614972359824 -> 140614972359776
	140614972359824 [label=MulBackward0]
	140614972360112 -> 140614972359824
	140614972360112 [label=MulBackward0]
	140614972360208 -> 140614972360112
	140614972360208 [label=GeluBackward0]
	140614972360304 -> 140614972360208
	140614972360304 [label=ConvolutionBackward0]
	140614972360352 -> 140614972360304
	140614972360352 [label=ConstantPadNdBackward0]
	140614972360640 -> 140614972360352
	140614972360640 [label=MulBackward0]
	140614972360688 -> 140614972360640
	140614972360688 [label=GeluBackward0]
	140614972360880 -> 140614972360688
	140614972360880 [label=ConvolutionBackward0]
	140614972360928 -> 140614972360880
	140614972360928 [label=MulBackward0]
	140614972361216 -> 140614972360928
	140614972361216 [label=GeluBackward0]
	140614972361312 -> 140614972361216
	140614972361312 [label=ConvolutionBackward0]
	140614972361360 -> 140614972361312
	140614972361360 [label=MulBackward0]
	140614972361648 -> 140614972361360
	140614972361648 [label=GeluBackward0]
	140614972361744 -> 140614972361648
	140614972361744 [label=ConvolutionBackward0]
	140614972361792 -> 140614972361744
	140614972361792 [label=ReshapeAliasBackward0]
	140614972362032 -> 140614972361792
	140614972362032 [label=NativeBatchNormBackward0]
	140614972362080 -> 140614972362032
	140614972362080 [label=ReshapeAliasBackward0]
	140614972362320 -> 140614972362080
	140615806694000 [label="stem.conv1.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	140615806694000 -> 140614972362320
	140614972362320 [label=AccumulateGrad]
	140614972361936 -> 140614972362032
	140614972361936 [label=ViewBackward0]
	140614972362560 -> 140614972361936
	140614972362560 [label=MulBackward0]
	140614972362656 -> 140614972362560
	140615806694160 [label="stem.conv1.gain
 (16, 1, 1, 1)" fillcolor=lightblue]
	140615806694160 -> 140614972362656
	140614972362656 [label=AccumulateGrad]
	140614972361552 -> 140614972361744
	140615806694080 [label="stem.conv1.bias
 (16)" fillcolor=lightblue]
	140615806694080 -> 140614972361552
	140614972361552 [label=AccumulateGrad]
	140614972361120 -> 140614972361312
	140614972361120 [label=ReshapeAliasBackward0]
	140614972361888 -> 140614972361120
	140614972361888 [label=NativeBatchNormBackward0]
	140614972362176 -> 140614972361888
	140614972362176 [label=ReshapeAliasBackward0]
	140614972362704 -> 140614972362176
	140614684232416 [label="stem.conv2.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140614684232416 -> 140614972362704
	140614972362704 [label=AccumulateGrad]
	140614972362608 -> 140614972361888
	140614972362608 [label=ViewBackward0]
	140614972361984 -> 140614972362608
	140614972361984 [label=MulBackward0]
	140614972371104 -> 140614972361984
	140615806693920 [label="stem.conv2.gain
 (32, 1, 1, 1)" fillcolor=lightblue]
	140615806693920 -> 140614972371104
	140614972371104 [label=AccumulateGrad]
	140614972361456 -> 140614972361312
	140614684230816 [label="stem.conv2.bias
 (32)" fillcolor=lightblue]
	140614684230816 -> 140614972361456
	140614972361456 [label=AccumulateGrad]
	140614972360784 -> 140614972360880
	140614972360784 [label=ReshapeAliasBackward0]
	140614972361504 -> 140614972360784
	140614972361504 [label=NativeBatchNormBackward0]
	140614972361600 -> 140614972361504
	140614972361600 [label=ReshapeAliasBackward0]
	140614972361696 -> 140614972361600
	140615806694320 [label="stem.conv3.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140615806694320 -> 140614972361696
	140614972361696 [label=AccumulateGrad]
	140614972362512 -> 140614972361504
	140614972362512 [label=ViewBackward0]
	140614972371152 -> 140614972362512
	140614972371152 [label=MulBackward0]
	140614972371248 -> 140614972371152
	140615806694480 [label="stem.conv3.gain
 (64, 1, 1, 1)" fillcolor=lightblue]
	140615806694480 -> 140614972371248
	140614972371248 [label=AccumulateGrad]
	140614972361024 -> 140614972360880
	140615806694400 [label="stem.conv3.bias
 (64)" fillcolor=lightblue]
	140615806694400 -> 140614972361024
	140614972361024 [label=AccumulateGrad]
	140614972360016 -> 140614972360304
	140614972360016 [label=ReshapeAliasBackward0]
	140614972360832 -> 140614972360016
	140614972360832 [label=NativeBatchNormBackward0]
	140614972361168 -> 140614972360832
	140614972361168 [label=ReshapeAliasBackward0]
	140614972361264 -> 140614972361168
	140615806694640 [label="stem.conv4.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	140615806694640 -> 140614972361264
	140614972361264 [label=AccumulateGrad]
	140614972361072 -> 140614972360832
	140614972361072 [label=ViewBackward0]
	140614972371344 -> 140614972361072
	140614972371344 [label=MulBackward0]
	140614972371200 -> 140614972371344
	140615806694800 [label="stem.conv4.gain
 (128, 1, 1, 1)" fillcolor=lightblue]
	140615806694800 -> 140614972371200
	140614972371200 [label=AccumulateGrad]
	140614972360448 -> 140614972360304
	140615806694720 [label="stem.conv4.bias
 (128)" fillcolor=lightblue]
	140615806694720 -> 140614972360448
	140614972360448 [label=AccumulateGrad]
	140614972359584 -> 140614972359776
	140614972359584 [label=ReshapeAliasBackward0]
	140614972360256 -> 140614972359584
	140614972360256 [label=NativeBatchNormBackward0]
	140614972360592 -> 140614972360256
	140614972360592 [label=ReshapeAliasBackward0]
	140614972360544 -> 140614972360592
	140615806695280 [label="stages.0.0.conv1.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	140615806695280 -> 140614972360544
	140614972360544 [label=AccumulateGrad]
	140614972360496 -> 140614972360256
	140614972360496 [label=ViewBackward0]
	140614972371440 -> 140614972360496
	140614972371440 [label=MulBackward0]
	140614972371008 -> 140614972371440
	140615806695440 [label="stages.0.0.conv1.gain
 (128, 1, 1, 1)" fillcolor=lightblue]
	140615806695440 -> 140614972371008
	140614972371008 [label=AccumulateGrad]
	140614972359920 -> 140614972359776
	140615806695360 [label="stages.0.0.conv1.bias
 (128)" fillcolor=lightblue]
	140615806695360 -> 140614972359920
	140614972359920 [label=AccumulateGrad]
	140614972359152 -> 140614972359344
	140614972359152 [label=ReshapeAliasBackward0]
	140614972359968 -> 140614972359152
	140614972359968 [label=NativeBatchNormBackward0]
	140614972360160 -> 140614972359968
	140614972360160 [label=ReshapeAliasBackward0]
	140614972371536 -> 140614972360160
	140615806695600 [label="stages.0.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140615806695600 -> 140614972371536
	140614972371536 [label=AccumulateGrad]
	140614972360064 -> 140614972359968
	140614972360064 [label=ViewBackward0]
	140614972371488 -> 140614972360064
	140614972371488 [label=MulBackward0]
	140614972371584 -> 140614972371488
	140615806695760 [label="stages.0.0.conv2.gain
 (128, 1, 1, 1)" fillcolor=lightblue]
	140615806695760 -> 140614972371584
	140614972371584 [label=AccumulateGrad]
	140614972359488 -> 140614972359344
	140615806695680 [label="stages.0.0.conv2.bias
 (128)" fillcolor=lightblue]
	140615806695680 -> 140614972359488
	140614972359488 [label=AccumulateGrad]
	140614972358720 -> 140614972358912
	140614972358720 [label=ReshapeAliasBackward0]
	140614972359536 -> 140614972358720
	140614972359536 [label=NativeBatchNormBackward0]
	140614972359728 -> 140614972359536
	140614972359728 [label=ReshapeAliasBackward0]
	140614972371680 -> 140614972359728
	140615806695920 [label="stages.0.0.conv2b.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140615806695920 -> 140614972371680
	140614972371680 [label=AccumulateGrad]
	140614972359632 -> 140614972359536
	140614972359632 [label=ViewBackward0]
	140614972371632 -> 140614972359632
	140614972371632 [label=MulBackward0]
	140614972371728 -> 140614972371632
	140615806696080 [label="stages.0.0.conv2b.gain
 (128, 1, 1, 1)" fillcolor=lightblue]
	140615806696080 -> 140614972371728
	140614972371728 [label=AccumulateGrad]
	140614972359056 -> 140614972358912
	140615806696000 [label="stages.0.0.conv2b.bias
 (128)" fillcolor=lightblue]
	140615806696000 -> 140614972359056
	140614972359056 [label=AccumulateGrad]
	140614972346224 -> 140614972346128
	140614972346224 [label=ReshapeAliasBackward0]
	140614972359104 -> 140614972346224
	140614972359104 [label=NativeBatchNormBackward0]
	140614972359296 -> 140614972359104
	140614972359296 [label=ReshapeAliasBackward0]
	140614972371824 -> 140614972359296
	140615806696240 [label="stages.0.0.conv3.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	140615806696240 -> 140614972371824
	140614972371824 [label=AccumulateGrad]
	140614972359200 -> 140614972359104
	140614972359200 [label=ViewBackward0]
	140614972371776 -> 140614972359200
	140614972371776 [label=MulBackward0]
	140614972371872 -> 140614972371776
	140615806696400 [label="stages.0.0.conv3.gain
 (256, 1, 1, 1)" fillcolor=lightblue]
	140615806696400 -> 140614972371872
	140614972371872 [label=AccumulateGrad]
	140614972346176 -> 140614972346128
	140615806696320 [label="stages.0.0.conv3.bias
 (256)" fillcolor=lightblue]
	140615806696320 -> 140614972346176
	140614972346176 [label=AccumulateGrad]
	140614972346080 -> 140614972346032
	140614972346080 [label=SigmoidBackward0]
	140614972358864 -> 140614972346080
	140614972358864 [label=ConvolutionBackward0]
	140614972346320 -> 140614972358864
	140614972346320 [label=ReluBackward0]
	140614972372016 -> 140614972346320
	140614972372016 [label=ConvolutionBackward0]
	140614972372112 -> 140614972372016
	140614972372112 [label=MeanBackward1]
	140614972346128 -> 140614972372112
	140614972372064 -> 140614972372016
	140615806696560 [label="stages.0.0.attn_last.fc1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	140615806696560 -> 140614972372064
	140614972372064 [label=AccumulateGrad]
	140614972371920 -> 140614972372016
	140615806696640 [label="stages.0.0.attn_last.fc1.bias
 (128)" fillcolor=lightblue]
	140615806696640 -> 140614972371920
	140614972371920 [label=AccumulateGrad]
	140614972371296 -> 140614972358864
	140615806696800 [label="stages.0.0.attn_last.fc2.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	140615806696800 -> 140614972371296
	140614972371296 [label=AccumulateGrad]
	140614972371392 -> 140614972358864
	140615806696880 [label="stages.0.0.attn_last.fc2.bias
 (256)" fillcolor=lightblue]
	140615806696880 -> 140614972371392
	140614972371392 [label=AccumulateGrad]
	140614972345840 -> 140614972345792
	140615806697040 [label="stages.0.0.skipinit_gain
 ()" fillcolor=lightblue]
	140615806697040 -> 140614972345840
	140614972345840 [label=AccumulateGrad]
	140614972345216 -> 140614972345504
	140614972345216 [label=ConvolutionBackward0]
	140614972359824 -> 140614972345216
	140614972358768 -> 140614972345216
	140614972358768 [label=ReshapeAliasBackward0]
	140614972345984 -> 140614972358768
	140614972345984 [label=NativeBatchNormBackward0]
	140614972372160 -> 140614972345984
	140614972372160 [label=ReshapeAliasBackward0]
	140614972372208 -> 140614972372160
	140615806694880 [label="stages.0.0.downsample.conv.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	140615806694880 -> 140614972372208
	140614972372208 [label=AccumulateGrad]
	140614972371056 -> 140614972345984
	140614972371056 [label=ViewBackward0]
	140614972372352 -> 140614972371056
	140614972372352 [label=MulBackward0]
	140614972372448 -> 140614972372352
	140615806695040 [label="stages.0.0.downsample.conv.gain
 (256, 1, 1, 1)" fillcolor=lightblue]
	140615806695040 -> 140614972372448
	140614972372448 [label=AccumulateGrad]
	140614972345696 -> 140614972345216
	140615806694960 [label="stages.0.0.downsample.conv.bias
 (256)" fillcolor=lightblue]
	140615806694960 -> 140614972345696
	140614972345696 [label=AccumulateGrad]
	140614972344880 -> 140614972344976
	140614972344880 [label=ReshapeAliasBackward0]
	140614972345456 -> 140614972344880
	140614972345456 [label=NativeBatchNormBackward0]
	140614972345744 -> 140614972345456
	140614972345744 [label=ReshapeAliasBackward0]
	140614972345936 -> 140614972345744
	140615806824512 [label="stages.1.0.conv1.weight
 (256, 256, 1, 1)" fillcolor=lightblue]
	140615806824512 -> 140614972345936
	140614972345936 [label=AccumulateGrad]
	140614972345648 -> 140614972345456
	140614972345648 [label=ViewBackward0]
	140614972372304 -> 140614972345648
	140614972372304 [label=MulBackward0]
	140614972372496 -> 140614972372304
	140615806824672 [label="stages.1.0.conv1.gain
 (256, 1, 1, 1)" fillcolor=lightblue]
	140615806824672 -> 140614972372496
	140614972372496 [label=AccumulateGrad]
	140614972345120 -> 140614972344976
	140615806824592 [label="stages.1.0.conv1.bias
 (256)" fillcolor=lightblue]
	140615806824592 -> 140614972345120
	140614972345120 [label=AccumulateGrad]
	140614972344208 -> 140614972344400
	140614972344208 [label=ReshapeAliasBackward0]
	140614972344928 -> 140614972344208
	140614972344928 [label=NativeBatchNormBackward0]
	140614972345264 -> 140614972344928
	140614972345264 [label=ReshapeAliasBackward0]
	140614972345360 -> 140614972345264
	140615806824832 [label="stages.1.0.conv2.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	140615806824832 -> 140614972345360
	140614972345360 [label=AccumulateGrad]
	140614972345168 -> 140614972344928
	140614972345168 [label=ViewBackward0]
	140614972372592 -> 140614972345168
	140614972372592 [label=MulBackward0]
	140614972371968 -> 140614972372592
	140615806824992 [label="stages.1.0.conv2.gain
 (256, 1, 1, 1)" fillcolor=lightblue]
	140615806824992 -> 140614972371968
	140614972371968 [label=AccumulateGrad]
	140614972344544 -> 140614972344400
	140615806824912 [label="stages.1.0.conv2.bias
 (256)" fillcolor=lightblue]
	140615806824912 -> 140614972344544
	140614972344544 [label=AccumulateGrad]
	140614972343776 -> 140614972343968
	140614972343776 [label=ReshapeAliasBackward0]
	140614972344592 -> 140614972343776
	140614972344592 [label=NativeBatchNormBackward0]
	140614972344640 -> 140614972344592
	140614972344640 [label=ReshapeAliasBackward0]
	140614972372688 -> 140614972344640
	140615806825152 [label="stages.1.0.conv2b.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	140615806825152 -> 140614972372688
	140614972372688 [label=AccumulateGrad]
	140614972344688 -> 140614972344592
	140614972344688 [label=ViewBackward0]
	140614972372640 -> 140614972344688
	140614972372640 [label=MulBackward0]
	140614972372736 -> 140614972372640
	140615806825312 [label="stages.1.0.conv2b.gain
 (256, 1, 1, 1)" fillcolor=lightblue]
	140615806825312 -> 140614972372736
	140614972372736 [label=AccumulateGrad]
	140614972344112 -> 140614972343968
	140615806825232 [label="stages.1.0.conv2b.bias
 (256)" fillcolor=lightblue]
	140615806825232 -> 140614972344112
	140614972344112 [label=AccumulateGrad]
	140614972343632 -> 140614972343536
	140614972343632 [label=ReshapeAliasBackward0]
	140614972344160 -> 140614972343632
	140614972344160 [label=NativeBatchNormBackward0]
	140614972344352 -> 140614972344160
	140614972344352 [label=ReshapeAliasBackward0]
	140614972372832 -> 140614972344352
	140615806825472 [label="stages.1.0.conv3.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	140615806825472 -> 140614972372832
	140614972372832 [label=AccumulateGrad]
	140614972344256 -> 140614972344160
	140614972344256 [label=ViewBackward0]
	140614972372784 -> 140614972344256
	140614972372784 [label=MulBackward0]
	140614972372880 -> 140614972372784
	140615806825632 [label="stages.1.0.conv3.gain
 (512, 1, 1, 1)" fillcolor=lightblue]
	140615806825632 -> 140614972372880
	140614972372880 [label=AccumulateGrad]
	140614972343584 -> 140614972343536
	140615806825552 [label="stages.1.0.conv3.bias
 (512)" fillcolor=lightblue]
	140615806825552 -> 140614972343584
	140614972343584 [label=AccumulateGrad]
	140614972343488 -> 140614972343440
	140614972343488 [label=SigmoidBackward0]
	140614972343920 -> 140614972343488
	140614972343920 [label=ConvolutionBackward0]
	140614972343728 -> 140614972343920
	140614972343728 [label=ReluBackward0]
	140614972373024 -> 140614972343728
	140614972373024 [label=ConvolutionBackward0]
	140614972373120 -> 140614972373024
	140614972373120 [label=MeanBackward1]
	140614972343536 -> 140614972373120
	140614972373072 -> 140614972373024
	140615806825792 [label="stages.1.0.attn_last.fc1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	140615806825792 -> 140614972373072
	140614972373072 [label=AccumulateGrad]
	140614972372928 -> 140614972373024
	140615806825872 [label="stages.1.0.attn_last.fc1.bias
 (256)" fillcolor=lightblue]
	140615806825872 -> 140614972372928
	140614972372928 [label=AccumulateGrad]
	140614972372400 -> 140614972343920
	140615806826032 [label="stages.1.0.attn_last.fc2.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	140615806826032 -> 140614972372400
	140614972372400 [label=AccumulateGrad]
	140614972372544 -> 140614972343920
	140615806826112 [label="stages.1.0.attn_last.fc2.bias
 (512)" fillcolor=lightblue]
	140615806826112 -> 140614972372544
	140614972372544 [label=AccumulateGrad]
	140614972343248 -> 140614972343200
	140615806826192 [label="stages.1.0.skipinit_gain
 ()" fillcolor=lightblue]
	140615806826192 -> 140614972343248
	140614972343248 [label=AccumulateGrad]
	140614972342912 -> 140614972327872
	140614972342912 [label=ConvolutionBackward0]
	140614972343824 -> 140614972342912
	140614972343824 [label=AvgPool2DBackward0]
	140614972345024 -> 140614972343824
	140614972343104 -> 140614972342912
	140614972343104 [label=ReshapeAliasBackward0]
	140614972343392 -> 140614972343104
	140614972343392 [label=NativeBatchNormBackward0]
	140614972373312 -> 140614972343392
	140614972373312 [label=ReshapeAliasBackward0]
	140614972373360 -> 140614972373312
	140615806697120 [label="stages.1.0.downsample.conv.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	140615806697120 -> 140614972373360
	140614972373360 [label=AccumulateGrad]
	140614972373168 -> 140614972343392
	140614972373168 [label=ViewBackward0]
	140614972373408 -> 140614972373168
	140614972373408 [label=MulBackward0]
	140614972373504 -> 140614972373408
	140615806697280 [label="stages.1.0.downsample.conv.gain
 (512, 1, 1, 1)" fillcolor=lightblue]
	140615806697280 -> 140614972373504
	140614972373504 [label=AccumulateGrad]
	140614972343152 -> 140614972342912
	140615806697200 [label="stages.1.0.downsample.conv.bias
 (512)" fillcolor=lightblue]
	140615806697200 -> 140614972343152
	140614972343152 [label=AccumulateGrad]
	140614972342336 -> 140614972342432
	140614972342336 [label=ReshapeAliasBackward0]
	140614972342960 -> 140614972342336
	140614972342960 [label=NativeBatchNormBackward0]
	140614972343344 -> 140614972342960
	140614972343344 [label=ReshapeAliasBackward0]
	140614972372976 -> 140614972343344
	140615806826352 [label="stages.1.1.conv1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	140615806826352 -> 140614972372976
	140614972372976 [label=AccumulateGrad]
	140614972343056 -> 140614972342960
	140614972343056 [label=ViewBackward0]
	140614972373264 -> 140614972343056
	140614972373264 [label=MulBackward0]
	140614972373552 -> 140614972373264
	140615806826512 [label="stages.1.1.conv1.gain
 (256, 1, 1, 1)" fillcolor=lightblue]
	140615806826512 -> 140614972373552
	140614972373552 [label=AccumulateGrad]
	140614972342576 -> 140614972342432
	140615806826432 [label="stages.1.1.conv1.bias
 (256)" fillcolor=lightblue]
	140615806826432 -> 140614972342576
	140614972342576 [label=AccumulateGrad]
	140614972329456 -> 140614972329648
	140614972329456 [label=ReshapeAliasBackward0]
	140614972329888 -> 140614972329456
	140614972329888 [label=NativeBatchNormBackward0]
	140614972342816 -> 140614972329888
	140614972342816 [label=ReshapeAliasBackward0]
	140614972373648 -> 140614972342816
	140615806826672 [label="stages.1.1.conv2.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	140615806826672 -> 140614972373648
	140614972373648 [label=AccumulateGrad]
	140614972342720 -> 140614972329888
	140614972342720 [label=ViewBackward0]
	140614972373216 -> 140614972342720
	140614972373216 [label=MulBackward0]
	140614972373696 -> 140614972373216
	140615806826832 [label="stages.1.1.conv2.gain
 (256, 1, 1, 1)" fillcolor=lightblue]
	140615806826832 -> 140614972373696
	140614972373696 [label=AccumulateGrad]
	140614972329792 -> 140614972329648
	140615806826752 [label="stages.1.1.conv2.bias
 (256)" fillcolor=lightblue]
	140615806826752 -> 140614972329792
	140614972329792 [label=AccumulateGrad]
	140614972329024 -> 140614972329216
	140614972329024 [label=ReshapeAliasBackward0]
	140614972329840 -> 140614972329024
	140614972329840 [label=NativeBatchNormBackward0]
	140614972342624 -> 140614972329840
	140614972342624 [label=ReshapeAliasBackward0]
	140614972373792 -> 140614972342624
	140615806826992 [label="stages.1.1.conv2b.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	140615806826992 -> 140614972373792
	140614972373792 [label=AccumulateGrad]
	140614972342384 -> 140614972329840
	140614972342384 [label=ViewBackward0]
	140614972373744 -> 140614972342384
	140614972373744 [label=MulBackward0]
	140614972373840 -> 140614972373744
	140615806827152 [label="stages.1.1.conv2b.gain
 (256, 1, 1, 1)" fillcolor=lightblue]
	140615806827152 -> 140614972373840
	140614972373840 [label=AccumulateGrad]
	140614972329360 -> 140614972329216
	140615806827072 [label="stages.1.1.conv2b.bias
 (256)" fillcolor=lightblue]
	140615806827072 -> 140614972329360
	140614972329360 [label=AccumulateGrad]
	140614972328880 -> 140614972328784
	140614972328880 [label=ReshapeAliasBackward0]
	140614972329408 -> 140614972328880
	140614972329408 [label=NativeBatchNormBackward0]
	140614972329600 -> 140614972329408
	140614972329600 [label=ReshapeAliasBackward0]
	140614972373936 -> 140614972329600
	140615806827312 [label="stages.1.1.conv3.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	140615806827312 -> 140614972373936
	140614972373936 [label=AccumulateGrad]
	140614972329504 -> 140614972329408
	140614972329504 [label=ViewBackward0]
	140614972373888 -> 140614972329504
	140614972373888 [label=MulBackward0]
	140614972373984 -> 140614972373888
	140615806827472 [label="stages.1.1.conv3.gain
 (512, 1, 1, 1)" fillcolor=lightblue]
	140615806827472 -> 140614972373984
	140614972373984 [label=AccumulateGrad]
	140614972328832 -> 140614972328784
	140615806827392 [label="stages.1.1.conv3.bias
 (512)" fillcolor=lightblue]
	140615806827392 -> 140614972328832
	140614972328832 [label=AccumulateGrad]
	140614972328736 -> 140614972328688
	140614972328736 [label=SigmoidBackward0]
	140614972329168 -> 140614972328736
	140614972329168 [label=ConvolutionBackward0]
	140614972328976 -> 140614972329168
	140614972328976 [label=ReluBackward0]
	140614972374128 -> 140614972328976
	140614972374128 [label=ConvolutionBackward0]
	140614972374224 -> 140614972374128
	140614972374224 [label=MeanBackward1]
	140614972328784 -> 140614972374224
	140614972374176 -> 140614972374128
	140615806827632 [label="stages.1.1.attn_last.fc1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	140615806827632 -> 140614972374176
	140614972374176 [label=AccumulateGrad]
	140614972374032 -> 140614972374128
	140615806827712 [label="stages.1.1.attn_last.fc1.bias
 (256)" fillcolor=lightblue]
	140615806827712 -> 140614972374032
	140614972374032 [label=AccumulateGrad]
	140614972373456 -> 140614972329168
	140615806827872 [label="stages.1.1.attn_last.fc2.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	140615806827872 -> 140614972373456
	140614972373456 [label=AccumulateGrad]
	140614972373600 -> 140614972329168
	140615806827952 [label="stages.1.1.attn_last.fc2.bias
 (512)" fillcolor=lightblue]
	140615806827952 -> 140614972373600
	140614972373600 [label=AccumulateGrad]
	140614972328496 -> 140614972328448
	140615806828032 [label="stages.1.1.skipinit_gain
 ()" fillcolor=lightblue]
	140615806828032 -> 140614972328496
	140614972328496 [label=AccumulateGrad]
	140614972327872 -> 140614972328160
	140614972327536 -> 140614972327632
	140614972327536 [label=ReshapeAliasBackward0]
	140614972328112 -> 140614972327536
	140614972328112 [label=NativeBatchNormBackward0]
	140614972328400 -> 140614972328112
	140614972328400 [label=ReshapeAliasBackward0]
	140614972328592 -> 140614972328400
	140615806959680 [label="stages.2.0.conv1.weight
 (768, 512, 1, 1)" fillcolor=lightblue]
	140615806959680 -> 140614972328592
	140614972328592 [label=AccumulateGrad]
	140614972328304 -> 140614972328112
	140614972328304 [label=ViewBackward0]
	140614972328352 -> 140614972328304
	140614972328352 [label=MulBackward0]
	140614972329072 -> 140614972328352
	140615806959840 [label="stages.2.0.conv1.gain
 (768, 1, 1, 1)" fillcolor=lightblue]
	140615806959840 -> 140614972329072
	140614972329072 [label=AccumulateGrad]
	140614972327776 -> 140614972327632
	140615806959760 [label="stages.2.0.conv1.bias
 (768)" fillcolor=lightblue]
	140615806959760 -> 140614972327776
	140614972327776 [label=AccumulateGrad]
	140614972326864 -> 140614972327056
	140614972326864 [label=ReshapeAliasBackward0]
	140614972327584 -> 140614972326864
	140614972327584 [label=NativeBatchNormBackward0]
	140614972328640 -> 140614972327584
	140614972328640 [label=ReshapeAliasBackward0]
	140614972328016 -> 140614972328640
	140615806960000 [label="stages.2.0.conv2.weight
 (768, 128, 3, 3)" fillcolor=lightblue]
	140615806960000 -> 140614972328016
	140614972328016 [label=AccumulateGrad]
	140614972327824 -> 140614972327584
	140614972327824 [label=ViewBackward0]
	140614972327920 -> 140614972327824
	140614972327920 [label=MulBackward0]
	140614972374080 -> 140614972327920
	140615806960160 [label="stages.2.0.conv2.gain
 (768, 1, 1, 1)" fillcolor=lightblue]
	140615806960160 -> 140614972374080
	140614972374080 [label=AccumulateGrad]
	140614972327200 -> 140614972327056
	140615806960080 [label="stages.2.0.conv2.bias
 (768)" fillcolor=lightblue]
	140615806960080 -> 140614972327200
	140614972327200 [label=AccumulateGrad]
	140614972326432 -> 140614972326624
	140614972326432 [label=ReshapeAliasBackward0]
	140614972327344 -> 140614972326432
	140614972327344 [label=NativeBatchNormBackward0]
	140614972327296 -> 140614972327344
	140614972327296 [label=ReshapeAliasBackward0]
	140614972374368 -> 140614972327296
	140615806960320 [label="stages.2.0.conv2b.weight
 (768, 128, 3, 3)" fillcolor=lightblue]
	140615806960320 -> 140614972374368
	140614972374368 [label=AccumulateGrad]
	140614972327008 -> 140614972327344
	140614972327008 [label=ViewBackward0]
	140614972374272 -> 140614972327008
	140614972374272 [label=MulBackward0]
	140614972374512 -> 140614972374272
	140615806960480 [label="stages.2.0.conv2b.gain
 (768, 1, 1, 1)" fillcolor=lightblue]
	140615806960480 -> 140614972374512
	140614972374512 [label=AccumulateGrad]
	140614972326768 -> 140614972326624
	140615806960400 [label="stages.2.0.conv2b.bias
 (768)" fillcolor=lightblue]
	140615806960400 -> 140614972326768
	140614972326768 [label=AccumulateGrad]
	140614972326288 -> 140614972326192
	140614972326288 [label=ReshapeAliasBackward0]
	140614972326816 -> 140614972326288
	140614972326816 [label=NativeBatchNormBackward0]
	140614972327248 -> 140614972326816
	140614972327248 [label=ReshapeAliasBackward0]
	140614972374608 -> 140614972327248
	140615806960640 [label="stages.2.0.conv3.weight
 (1536, 768, 1, 1)" fillcolor=lightblue]
	140615806960640 -> 140614972374608
	140614972374608 [label=AccumulateGrad]
	140614972326480 -> 140614972326816
	140614972326480 [label=ViewBackward0]
	140614972374560 -> 140614972326480
	140614972374560 [label=MulBackward0]
	140614972374656 -> 140614972374560
	140615806960800 [label="stages.2.0.conv3.gain
 (1536, 1, 1, 1)" fillcolor=lightblue]
	140615806960800 -> 140614972374656
	140614972374656 [label=AccumulateGrad]
	140614972326240 -> 140614972326192
	140615806960720 [label="stages.2.0.conv3.bias
 (1536)" fillcolor=lightblue]
	140615806960720 -> 140614972326240
	140614972326240 [label=AccumulateGrad]
	140614972326144 -> 140614972326096
	140614972326144 [label=SigmoidBackward0]
	140614972326576 -> 140614972326144
	140614972326576 [label=ConvolutionBackward0]
	140614972374416 -> 140614972326576
	140614972374416 [label=ReluBackward0]
	140614972374800 -> 140614972374416
	140614972374800 [label=ConvolutionBackward0]
	140614972374896 -> 140614972374800
	140614972374896 [label=MeanBackward1]
	140614972326192 -> 140614972374896
	140614972374848 -> 140614972374800
	140615806960960 [label="stages.2.0.attn_last.fc1.weight
 (768, 1536, 1, 1)" fillcolor=lightblue]
	140615806960960 -> 140614972374848
	140614972374848 [label=AccumulateGrad]
	140614972374704 -> 140614972374800
	140615806961040 [label="stages.2.0.attn_last.fc1.bias
 (768)" fillcolor=lightblue]
	140615806961040 -> 140614972374704
	140614972374704 [label=AccumulateGrad]
	140614972374464 -> 140614972326576
	140615806961200 [label="stages.2.0.attn_last.fc2.weight
 (1536, 768, 1, 1)" fillcolor=lightblue]
	140615806961200 -> 140614972374464
	140614972374464 [label=AccumulateGrad]
	140614972374320 -> 140614972326576
	140615806961280 [label="stages.2.0.attn_last.fc2.bias
 (1536)" fillcolor=lightblue]
	140615806961280 -> 140614972374320
	140614972374320 [label=AccumulateGrad]
	140614972313408 -> 140614972313504
	140615806961360 [label="stages.2.0.skipinit_gain
 ()" fillcolor=lightblue]
	140615806961360 -> 140614972313408
	140614972313408 [label=AccumulateGrad]
	140614972313216 -> 140614972310816
	140614972313216 [label=ConvolutionBackward0]
	140614972313456 -> 140614972313216
	140614972313456 [label=AvgPool2DBackward0]
	140614972327680 -> 140614972313456
	140614972326384 -> 140614972313216
	140614972326384 [label=ReshapeAliasBackward0]
	140614972326048 -> 140614972326384
	140614972326048 [label=NativeBatchNormBackward0]
	140614972374992 -> 140614972326048
	140614972374992 [label=ReshapeAliasBackward0]
	140615017128096 -> 140614972374992
	140615806828192 [label="stages.2.0.downsample.conv.weight
 (1536, 512, 1, 1)" fillcolor=lightblue]
	140615806828192 -> 140615017128096
	140615017128096 [label=AccumulateGrad]
	140614972374944 -> 140614972326048
	140614972374944 [label=ViewBackward0]
	140615017128144 -> 140614972374944
	140615017128144 [label=MulBackward0]
	140615017128240 -> 140615017128144
	140615806828352 [label="stages.2.0.downsample.conv.gain
 (1536, 1, 1, 1)" fillcolor=lightblue]
	140615806828352 -> 140615017128240
	140615017128240 [label=AccumulateGrad]
	140614972325952 -> 140614972313216
	140615806828272 [label="stages.2.0.downsample.conv.bias
 (1536)" fillcolor=lightblue]
	140615806828272 -> 140614972325952
	140614972325952 [label=AccumulateGrad]
	140614972312544 -> 140614972312736
	140614972312544 [label=ReshapeAliasBackward0]
	140614972313264 -> 140614972312544
	140614972313264 [label=NativeBatchNormBackward0]
	140614972326000 -> 140614972313264
	140614972326000 [label=ReshapeAliasBackward0]
	140614972374752 -> 140614972326000
	140615806961520 [label="stages.2.1.conv1.weight
 (768, 1536, 1, 1)" fillcolor=lightblue]
	140615806961520 -> 140614972374752
	140614972374752 [label=AccumulateGrad]
	140614972313360 -> 140614972313264
	140614972313360 [label=ViewBackward0]
	140614972372256 -> 140614972313360
	140614972372256 [label=MulBackward0]
	140615017128288 -> 140614972372256
	140615806961680 [label="stages.2.1.conv1.gain
 (768, 1, 1, 1)" fillcolor=lightblue]
	140615806961680 -> 140615017128288
	140615017128288 [label=AccumulateGrad]
	140614972312880 -> 140614972312736
	140615806961600 [label="stages.2.1.conv1.bias
 (768)" fillcolor=lightblue]
	140615806961600 -> 140614972312880
	140614972312880 [label=AccumulateGrad]
	140614972312112 -> 140614972312304
	140614972312112 [label=ReshapeAliasBackward0]
	140614972312928 -> 140614972312112
	140614972312928 [label=NativeBatchNormBackward0]
	140614972313120 -> 140614972312928
	140614972313120 [label=ReshapeAliasBackward0]
	140615017128384 -> 140614972313120
	140615806961840 [label="stages.2.1.conv2.weight
 (768, 128, 3, 3)" fillcolor=lightblue]
	140615806961840 -> 140615017128384
	140615017128384 [label=AccumulateGrad]
	140614972313024 -> 140614972312928
	140614972313024 [label=ViewBackward0]
	140615017128048 -> 140614972313024
	140615017128048 [label=MulBackward0]
	140615017128432 -> 140615017128048
	140615806962000 [label="stages.2.1.conv2.gain
 (768, 1, 1, 1)" fillcolor=lightblue]
	140615806962000 -> 140615017128432
	140615017128432 [label=AccumulateGrad]
	140614972312448 -> 140614972312304
	140615806961920 [label="stages.2.1.conv2.bias
 (768)" fillcolor=lightblue]
	140615806961920 -> 140614972312448
	140614972312448 [label=AccumulateGrad]
	140614972311680 -> 140614972311872
	140614972311680 [label=ReshapeAliasBackward0]
	140614972312496 -> 140614972311680
	140614972312496 [label=NativeBatchNormBackward0]
	140614972312688 -> 140614972312496
	140614972312688 [label=ReshapeAliasBackward0]
	140615017128528 -> 140614972312688
	140615806962160 [label="stages.2.1.conv2b.weight
 (768, 128, 3, 3)" fillcolor=lightblue]
	140615806962160 -> 140615017128528
	140615017128528 [label=AccumulateGrad]
	140614972312592 -> 140614972312496
	140614972312592 [label=ViewBackward0]
	140615017128480 -> 140614972312592
	140615017128480 [label=MulBackward0]
	140615017128576 -> 140615017128480
	140615806962320 [label="stages.2.1.conv2b.gain
 (768, 1, 1, 1)" fillcolor=lightblue]
	140615806962320 -> 140615017128576
	140615017128576 [label=AccumulateGrad]
	140614972312016 -> 140614972311872
	140615806962240 [label="stages.2.1.conv2b.bias
 (768)" fillcolor=lightblue]
	140615806962240 -> 140614972312016
	140614972312016 [label=AccumulateGrad]
	140614972311536 -> 140614972311440
	140614972311536 [label=ReshapeAliasBackward0]
	140614972312064 -> 140614972311536
	140614972312064 [label=NativeBatchNormBackward0]
	140614972312256 -> 140614972312064
	140614972312256 [label=ReshapeAliasBackward0]
	140615017128672 -> 140614972312256
	140615806962480 [label="stages.2.1.conv3.weight
 (1536, 768, 1, 1)" fillcolor=lightblue]
	140615806962480 -> 140615017128672
	140615017128672 [label=AccumulateGrad]
	140614972312160 -> 140614972312064
	140614972312160 [label=ViewBackward0]
	140615017128624 -> 140614972312160
	140615017128624 [label=MulBackward0]
	140615017128720 -> 140615017128624
	140615806962640 [label="stages.2.1.conv3.gain
 (1536, 1, 1, 1)" fillcolor=lightblue]
	140615806962640 -> 140615017128720
	140615017128720 [label=AccumulateGrad]
	140614972311488 -> 140614972311440
	140615806962560 [label="stages.2.1.conv3.bias
 (1536)" fillcolor=lightblue]
	140615806962560 -> 140614972311488
	140614972311488 [label=AccumulateGrad]
	140614972311392 -> 140614972311344
	140614972311392 [label=SigmoidBackward0]
	140614972311824 -> 140614972311392
	140614972311824 [label=ConvolutionBackward0]
	140614972311632 -> 140614972311824
	140614972311632 [label=ReluBackward0]
	140615017128864 -> 140614972311632
	140615017128864 [label=ConvolutionBackward0]
	140615017128960 -> 140615017128864
	140615017128960 [label=MeanBackward1]
	140614972311440 -> 140615017128960
	140615017128912 -> 140615017128864
	140615806962800 [label="stages.2.1.attn_last.fc1.weight
 (768, 1536, 1, 1)" fillcolor=lightblue]
	140615806962800 -> 140615017128912
	140615017128912 [label=AccumulateGrad]
	140615017128768 -> 140615017128864
	140615806962880 [label="stages.2.1.attn_last.fc1.bias
 (768)" fillcolor=lightblue]
	140615806962880 -> 140615017128768
	140615017128768 [label=AccumulateGrad]
	140615017128192 -> 140614972311824
	140615806963040 [label="stages.2.1.attn_last.fc2.weight
 (1536, 768, 1, 1)" fillcolor=lightblue]
	140615806963040 -> 140615017128192
	140615017128192 [label=AccumulateGrad]
	140615017128000 -> 140614972311824
	140615806963120 [label="stages.2.1.attn_last.fc2.bias
 (1536)" fillcolor=lightblue]
	140615806963120 -> 140615017128000
	140615017128000 [label=AccumulateGrad]
	140614972311152 -> 140614972311104
	140615806963200 [label="stages.2.1.skipinit_gain
 ()" fillcolor=lightblue]
	140615806963200 -> 140614972311152
	140614972311152 [label=AccumulateGrad]
	140614972310816 -> 140614972300160
	140614972310144 -> 140614972310336
	140614972310144 [label=ReshapeAliasBackward0]
	140614972310864 -> 140614972310144
	140614972310864 [label=NativeBatchNormBackward0]
	140614972311056 -> 140614972310864
	140614972311056 [label=ReshapeAliasBackward0]
	140614972311248 -> 140614972311056
	140615806963360 [label="stages.2.2.conv1.weight
 (768, 1536, 1, 1)" fillcolor=lightblue]
	140615806963360 -> 140614972311248
	140614972311248 [label=AccumulateGrad]
	140614972310960 -> 140614972310864
	140614972310960 [label=ViewBackward0]
	140614972311008 -> 140614972310960
	140614972311008 [label=MulBackward0]
	140614972311728 -> 140614972311008
	140615806963520 [label="stages.2.2.conv1.gain
 (768, 1, 1, 1)" fillcolor=lightblue]
	140615806963520 -> 140614972311728
	140614972311728 [label=AccumulateGrad]
	140614972310480 -> 140614972310336
	140615806963440 [label="stages.2.2.conv1.bias
 (768)" fillcolor=lightblue]
	140615806963440 -> 140614972310480
	140614972310480 [label=AccumulateGrad]
	140614972309712 -> 140614972309904
	140614972309712 [label=ReshapeAliasBackward0]
	140614972310528 -> 140614972309712
	140614972310528 [label=NativeBatchNormBackward0]
	140614972310624 -> 140614972310528
	140614972310624 [label=ReshapeAliasBackward0]
	140614972310720 -> 140614972310624
	140614691823680 [label="stages.2.2.conv2.weight
 (768, 128, 3, 3)" fillcolor=lightblue]
	140614691823680 -> 140614972310720
	140614972310720 [label=AccumulateGrad]
	140614972311296 -> 140614972310528
	140614972311296 [label=ViewBackward0]
	140615017129008 -> 140614972311296
	140615017129008 [label=MulBackward0]
	140615017129104 -> 140615017129008
	140614691823840 [label="stages.2.2.conv2.gain
 (768, 1, 1, 1)" fillcolor=lightblue]
	140614691823840 -> 140615017129104
	140615017129104 [label=AccumulateGrad]
	140614972310048 -> 140614972309904
	140614691823760 [label="stages.2.2.conv2.bias
 (768)" fillcolor=lightblue]
	140614691823760 -> 140614972310048
	140614972310048 [label=AccumulateGrad]
	140614972309568 -> 140614972301216
	140614972309568 [label=ReshapeAliasBackward0]
	140614972310096 -> 140614972309568
	140614972310096 [label=NativeBatchNormBackward0]
	140614972310288 -> 140614972310096
	140614972310288 [label=ReshapeAliasBackward0]
	140615017129200 -> 140614972310288
	140614691824000 [label="stages.2.2.conv2b.weight
 (768, 128, 3, 3)" fillcolor=lightblue]
	140614691824000 -> 140615017129200
	140615017129200 [label=AccumulateGrad]
	140614972310192 -> 140614972310096
	140614972310192 [label=ViewBackward0]
	140615017129056 -> 140614972310192
	140615017129056 [label=MulBackward0]
	140615017129248 -> 140615017129056
	140614691824160 [label="stages.2.2.conv2b.gain
 (768, 1, 1, 1)" fillcolor=lightblue]
	140614691824160 -> 140615017129248
	140615017129248 [label=AccumulateGrad]
	140614972309616 -> 140614972301216
	140614691824080 [label="stages.2.2.conv2b.bias
 (768)" fillcolor=lightblue]
	140614691824080 -> 140614972309616
	140614972309616 [label=AccumulateGrad]
	140614972300880 -> 140614972300784
	140614972300880 [label=ReshapeAliasBackward0]
	140614972301168 -> 140614972300880
	140614972301168 [label=NativeBatchNormBackward0]
	140614972309856 -> 140614972301168
	140614972309856 [label=ReshapeAliasBackward0]
	140615017129344 -> 140614972309856
	140614691824320 [label="stages.2.2.conv3.weight
 (1536, 768, 1, 1)" fillcolor=lightblue]
	140614691824320 -> 140615017129344
	140615017129344 [label=AccumulateGrad]
	140614972309760 -> 140614972301168
	140614972309760 [label=ViewBackward0]
	140615017129296 -> 140614972309760
	140615017129296 [label=MulBackward0]
	140615017129392 -> 140615017129296
	140614691824480 [label="stages.2.2.conv3.gain
 (1536, 1, 1, 1)" fillcolor=lightblue]
	140614691824480 -> 140615017129392
	140615017129392 [label=AccumulateGrad]
	140614972300832 -> 140614972300784
	140614691824400 [label="stages.2.2.conv3.bias
 (1536)" fillcolor=lightblue]
	140614691824400 -> 140614972300832
	140614972300832 [label=AccumulateGrad]
	140614972300736 -> 140614972300688
	140614972300736 [label=SigmoidBackward0]
	140614972301072 -> 140614972300736
	140614972301072 [label=ConvolutionBackward0]
	140614972309664 -> 140614972301072
	140614972309664 [label=ReluBackward0]
	140615017129536 -> 140614972309664
	140615017129536 [label=ConvolutionBackward0]
	140615017129632 -> 140615017129536
	140615017129632 [label=MeanBackward1]
	140614972300784 -> 140615017129632
	140615017129584 -> 140615017129536
	140614691824640 [label="stages.2.2.attn_last.fc1.weight
 (768, 1536, 1, 1)" fillcolor=lightblue]
	140614691824640 -> 140615017129584
	140615017129584 [label=AccumulateGrad]
	140615017129440 -> 140615017129536
	140614691824720 [label="stages.2.2.attn_last.fc1.bias
 (768)" fillcolor=lightblue]
	140614691824720 -> 140615017129440
	140615017129440 [label=AccumulateGrad]
	140615017129152 -> 140614972301072
	140614691824880 [label="stages.2.2.attn_last.fc2.weight
 (1536, 768, 1, 1)" fillcolor=lightblue]
	140614691824880 -> 140615017129152
	140615017129152 [label=AccumulateGrad]
	140615017128336 -> 140614972301072
	140614691824960 [label="stages.2.2.attn_last.fc2.bias
 (1536)" fillcolor=lightblue]
	140614691824960 -> 140615017128336
	140615017128336 [label=AccumulateGrad]
	140614972300496 -> 140614972300448
	140614691825040 [label="stages.2.2.skipinit_gain
 ()" fillcolor=lightblue]
	140614691825040 -> 140614972300496
	140614972300496 [label=AccumulateGrad]
	140614972300160 -> 140614972297760
	140614972299488 -> 140614972299680
	140614972299488 [label=ReshapeAliasBackward0]
	140614972300208 -> 140614972299488
	140614972300208 [label=NativeBatchNormBackward0]
	140614972300400 -> 140614972300208
	140614972300400 [label=ReshapeAliasBackward0]
	140614972300592 -> 140614972300400
	140614691825200 [label="stages.2.3.conv1.weight
 (768, 1536, 1, 1)" fillcolor=lightblue]
	140614691825200 -> 140614972300592
	140614972300592 [label=AccumulateGrad]
	140614972300304 -> 140614972300208
	140614972300304 [label=ViewBackward0]
	140614972300352 -> 140614972300304
	140614972300352 [label=MulBackward0]
	140614972300976 -> 140614972300352
	140614691825360 [label="stages.2.3.conv1.gain
 (768, 1, 1, 1)" fillcolor=lightblue]
	140614691825360 -> 140614972300976
	140614972300976 [label=AccumulateGrad]
	140614972299824 -> 140614972299680
	140614691825280 [label="stages.2.3.conv1.bias
 (768)" fillcolor=lightblue]
	140614691825280 -> 140614972299824
	140614972299824 [label=AccumulateGrad]
	140614972299056 -> 140614972299248
	140614972299056 [label=ReshapeAliasBackward0]
	140614972299872 -> 140614972299056
	140614972299872 [label=NativeBatchNormBackward0]
	140614972299968 -> 140614972299872
	140614972299968 [label=ReshapeAliasBackward0]
	140614972300064 -> 140614972299968
	140614691825520 [label="stages.2.3.conv2.weight
 (768, 128, 3, 3)" fillcolor=lightblue]
	140614691825520 -> 140614972300064
	140614972300064 [label=AccumulateGrad]
	140614972300640 -> 140614972299872
	140614972300640 [label=ViewBackward0]
	140615017129680 -> 140614972300640
	140615017129680 [label=MulBackward0]
	140615017129776 -> 140615017129680
	140614691825680 [label="stages.2.3.conv2.gain
 (768, 1, 1, 1)" fillcolor=lightblue]
	140614691825680 -> 140615017129776
	140615017129776 [label=AccumulateGrad]
	140614972299392 -> 140614972299248
	140614691825600 [label="stages.2.3.conv2.bias
 (768)" fillcolor=lightblue]
	140614691825600 -> 140614972299392
	140614972299392 [label=AccumulateGrad]
	140614972298624 -> 140614972298816
	140614972298624 [label=ReshapeAliasBackward0]
	140614972299440 -> 140614972298624
	140614972299440 [label=NativeBatchNormBackward0]
	140614972299632 -> 140614972299440
	140614972299632 [label=ReshapeAliasBackward0]
	140615017129872 -> 140614972299632
	140614691825840 [label="stages.2.3.conv2b.weight
 (768, 128, 3, 3)" fillcolor=lightblue]
	140614691825840 -> 140615017129872
	140615017129872 [label=AccumulateGrad]
	140614972299536 -> 140614972299440
	140614972299536 [label=ViewBackward0]
	140615017129728 -> 140614972299536
	140615017129728 [label=MulBackward0]
	140615017129920 -> 140615017129728
	140614691826000 [label="stages.2.3.conv2b.gain
 (768, 1, 1, 1)" fillcolor=lightblue]
	140614691826000 -> 140615017129920
	140615017129920 [label=AccumulateGrad]
	140614972298960 -> 140614972298816
	140614691825920 [label="stages.2.3.conv2b.bias
 (768)" fillcolor=lightblue]
	140614691825920 -> 140614972298960
	140614972298960 [label=AccumulateGrad]
	140614972298480 -> 140614972298384
	140614972298480 [label=ReshapeAliasBackward0]
	140614972299008 -> 140614972298480
	140614972299008 [label=NativeBatchNormBackward0]
	140614972299200 -> 140614972299008
	140614972299200 [label=ReshapeAliasBackward0]
	140615017130016 -> 140614972299200
	140614691826160 [label="stages.2.3.conv3.weight
 (1536, 768, 1, 1)" fillcolor=lightblue]
	140614691826160 -> 140615017130016
	140615017130016 [label=AccumulateGrad]
	140614972299104 -> 140614972299008
	140614972299104 [label=ViewBackward0]
	140615017129968 -> 140614972299104
	140615017129968 [label=MulBackward0]
	140615017130064 -> 140615017129968
	140614691826320 [label="stages.2.3.conv3.gain
 (1536, 1, 1, 1)" fillcolor=lightblue]
	140614691826320 -> 140615017130064
	140615017130064 [label=AccumulateGrad]
	140614972298432 -> 140614972298384
	140614691826240 [label="stages.2.3.conv3.bias
 (1536)" fillcolor=lightblue]
	140614691826240 -> 140614972298432
	140614972298432 [label=AccumulateGrad]
	140614972298336 -> 140614972298288
	140614972298336 [label=SigmoidBackward0]
	140614972298768 -> 140614972298336
	140614972298768 [label=ConvolutionBackward0]
	140614972298576 -> 140614972298768
	140614972298576 [label=ReluBackward0]
	140615017130208 -> 140614972298576
	140615017130208 [label=ConvolutionBackward0]
	140615017130304 -> 140615017130208
	140615017130304 [label=MeanBackward1]
	140614972298384 -> 140615017130304
	140615017130256 -> 140615017130208
	140614691826480 [label="stages.2.3.attn_last.fc1.weight
 (768, 1536, 1, 1)" fillcolor=lightblue]
	140614691826480 -> 140615017130256
	140615017130256 [label=AccumulateGrad]
	140615017130112 -> 140615017130208
	140614691826560 [label="stages.2.3.attn_last.fc1.bias
 (768)" fillcolor=lightblue]
	140614691826560 -> 140615017130112
	140615017130112 [label=AccumulateGrad]
	140615017129824 -> 140614972298768
	140614691826720 [label="stages.2.3.attn_last.fc2.weight
 (1536, 768, 1, 1)" fillcolor=lightblue]
	140614691826720 -> 140615017129824
	140615017129824 [label=AccumulateGrad]
	140615017128816 -> 140614972298768
	140614691826800 [label="stages.2.3.attn_last.fc2.bias
 (1536)" fillcolor=lightblue]
	140614691826800 -> 140615017128816
	140615017128816 [label=AccumulateGrad]
	140614972298096 -> 140614972298048
	140614691826880 [label="stages.2.3.skipinit_gain
 ()" fillcolor=lightblue]
	140614691826880 -> 140614972298096
	140614972298096 [label=AccumulateGrad]
	140614972297760 -> 140614972287104
	140614972297280 -> 140614972288976
	140614972297280 [label=ReshapeAliasBackward0]
	140614972297808 -> 140614972297280
	140614972297808 [label=NativeBatchNormBackward0]
	140614972298000 -> 140614972297808
	140614972298000 [label=ReshapeAliasBackward0]
	140614972298192 -> 140614972298000
	140614691827040 [label="stages.2.4.conv1.weight
 (768, 1536, 1, 1)" fillcolor=lightblue]
	140614691827040 -> 140614972298192
	140614972298192 [label=AccumulateGrad]
	140614972297904 -> 140614972297808
	140614972297904 [label=ViewBackward0]
	140614972297952 -> 140614972297904
	140614972297952 [label=MulBackward0]
	140614972298672 -> 140614972297952
	140614691827200 [label="stages.2.4.conv1.gain
 (768, 1, 1, 1)" fillcolor=lightblue]
	140614691827200 -> 140614972298672
	140614972298672 [label=AccumulateGrad]
	140614972297424 -> 140614972288976
	140614691827120 [label="stages.2.4.conv1.bias
 (768)" fillcolor=lightblue]
	140614691827120 -> 140614972297424
	140614972297424 [label=AccumulateGrad]
	140614972288400 -> 140614972288592
	140614972288400 [label=ReshapeAliasBackward0]
	140614972288832 -> 140614972288400
	140614972288832 [label=NativeBatchNormBackward0]
	140614972297568 -> 140614972288832
	140614972297568 [label=ReshapeAliasBackward0]
	140614972297664 -> 140614972297568
	140614691827360 [label="stages.2.4.conv2.weight
 (768, 128, 3, 3)" fillcolor=lightblue]
	140614691827360 -> 140614972297664
	140614972297664 [label=AccumulateGrad]
	140614972298240 -> 140614972288832
	140614972298240 [label=ViewBackward0]
	140615017130352 -> 140614972298240
	140615017130352 [label=MulBackward0]
	140615017130448 -> 140615017130352
	140614691827520 [label="stages.2.4.conv2.gain
 (768, 1, 1, 1)" fillcolor=lightblue]
	140614691827520 -> 140615017130448
	140615017130448 [label=AccumulateGrad]
	140614972288736 -> 140614972288592
	140614691827440 [label="stages.2.4.conv2.bias
 (768)" fillcolor=lightblue]
	140614691827440 -> 140614972288736
	140614972288736 [label=AccumulateGrad]
	140614972287968 -> 140614972288160
	140614972287968 [label=ReshapeAliasBackward0]
	140614972297472 -> 140614972287968
	140614972297472 [label=NativeBatchNormBackward0]
	140614972288880 -> 140614972297472
	140614972288880 [label=ReshapeAliasBackward0]
	140615017130544 -> 140614972288880
	140614691954752 [label="stages.2.4.conv2b.weight
 (768, 128, 3, 3)" fillcolor=lightblue]
	140614691954752 -> 140615017130544
	140615017130544 [label=AccumulateGrad]
	140614972288784 -> 140614972297472
	140614972288784 [label=ViewBackward0]
	140615017130400 -> 140614972288784
	140615017130400 [label=MulBackward0]
	140615017130592 -> 140615017130400
	140614691954912 [label="stages.2.4.conv2b.gain
 (768, 1, 1, 1)" fillcolor=lightblue]
	140614691954912 -> 140615017130592
	140615017130592 [label=AccumulateGrad]
	140614972288304 -> 140614972288160
	140614691954832 [label="stages.2.4.conv2b.bias
 (768)" fillcolor=lightblue]
	140614691954832 -> 140614972288304
	140614972288304 [label=AccumulateGrad]
	140614972287824 -> 140614972287728
	140614972287824 [label=ReshapeAliasBackward0]
	140614972288352 -> 140614972287824
	140614972288352 [label=NativeBatchNormBackward0]
	140614972288544 -> 140614972288352
	140614972288544 [label=ReshapeAliasBackward0]
	140615017130688 -> 140614972288544
	140614691955072 [label="stages.2.4.conv3.weight
 (1536, 768, 1, 1)" fillcolor=lightblue]
	140614691955072 -> 140615017130688
	140615017130688 [label=AccumulateGrad]
	140614972288448 -> 140614972288352
	140614972288448 [label=ViewBackward0]
	140615017130640 -> 140614972288448
	140615017130640 [label=MulBackward0]
	140615017130736 -> 140615017130640
	140614691955232 [label="stages.2.4.conv3.gain
 (1536, 1, 1, 1)" fillcolor=lightblue]
	140614691955232 -> 140615017130736
	140615017130736 [label=AccumulateGrad]
	140614972287776 -> 140614972287728
	140614691955152 [label="stages.2.4.conv3.bias
 (1536)" fillcolor=lightblue]
	140614691955152 -> 140614972287776
	140614972287776 [label=AccumulateGrad]
	140614972287680 -> 140614972287632
	140614972287680 [label=SigmoidBackward0]
	140614972288112 -> 140614972287680
	140614972288112 [label=ConvolutionBackward0]
	140614972287920 -> 140614972288112
	140614972287920 [label=ReluBackward0]
	140615017130880 -> 140614972287920
	140615017130880 [label=ConvolutionBackward0]
	140615017130976 -> 140615017130880
	140615017130976 [label=MeanBackward1]
	140614972287728 -> 140615017130976
	140615017130928 -> 140615017130880
	140614691955392 [label="stages.2.4.attn_last.fc1.weight
 (768, 1536, 1, 1)" fillcolor=lightblue]
	140614691955392 -> 140615017130928
	140615017130928 [label=AccumulateGrad]
	140615017130784 -> 140615017130880
	140614691955472 [label="stages.2.4.attn_last.fc1.bias
 (768)" fillcolor=lightblue]
	140614691955472 -> 140615017130784
	140615017130784 [label=AccumulateGrad]
	140615017130496 -> 140614972288112
	140614691955632 [label="stages.2.4.attn_last.fc2.weight
 (1536, 768, 1, 1)" fillcolor=lightblue]
	140614691955632 -> 140615017130496
	140615017130496 [label=AccumulateGrad]
	140615017129488 -> 140614972288112
	140614691955712 [label="stages.2.4.attn_last.fc2.bias
 (1536)" fillcolor=lightblue]
	140614691955712 -> 140615017129488
	140615017129488 [label=AccumulateGrad]
	140614972287440 -> 140614972287392
	140614691955792 [label="stages.2.4.skipinit_gain
 ()" fillcolor=lightblue]
	140614691955792 -> 140614972287440
	140614972287440 [label=AccumulateGrad]
	140614972287104 -> 140614972276592
	140614972286432 -> 140614972286624
	140614972286432 [label=ReshapeAliasBackward0]
	140614972287152 -> 140614972286432
	140614972287152 [label=NativeBatchNormBackward0]
	140614972287344 -> 140614972287152
	140614972287344 [label=ReshapeAliasBackward0]
	140614972287536 -> 140614972287344
	140614691955952 [label="stages.2.5.conv1.weight
 (768, 1536, 1, 1)" fillcolor=lightblue]
	140614691955952 -> 140614972287536
	140614972287536 [label=AccumulateGrad]
	140614972287248 -> 140614972287152
	140614972287248 [label=ViewBackward0]
	140614972287296 -> 140614972287248
	140614972287296 [label=MulBackward0]
	140614972288016 -> 140614972287296
	140614691956112 [label="stages.2.5.conv1.gain
 (768, 1, 1, 1)" fillcolor=lightblue]
	140614691956112 -> 140614972288016
	140614972288016 [label=AccumulateGrad]
	140614972286768 -> 140614972286624
	140614691956032 [label="stages.2.5.conv1.bias
 (768)" fillcolor=lightblue]
	140614691956032 -> 140614972286768
	140614972286768 [label=AccumulateGrad]
	140614972286000 -> 140614972286192
	140614972286000 [label=ReshapeAliasBackward0]
	140614972286816 -> 140614972286000
	140614972286816 [label=NativeBatchNormBackward0]
	140614972286912 -> 140614972286816
	140614972286912 [label=ReshapeAliasBackward0]
	140614972287008 -> 140614972286912
	140614691956272 [label="stages.2.5.conv2.weight
 (768, 128, 3, 3)" fillcolor=lightblue]
	140614691956272 -> 140614972287008
	140614972287008 [label=AccumulateGrad]
	140614972287584 -> 140614972286816
	140614972287584 [label=ViewBackward0]
	140615017131024 -> 140614972287584
	140615017131024 [label=MulBackward0]
	140615017131120 -> 140615017131024
	140614691956432 [label="stages.2.5.conv2.gain
 (768, 1, 1, 1)" fillcolor=lightblue]
	140614691956432 -> 140615017131120
	140615017131120 [label=AccumulateGrad]
	140614972286336 -> 140614972286192
	140614691956352 [label="stages.2.5.conv2.bias
 (768)" fillcolor=lightblue]
	140614691956352 -> 140614972286336
	140614972286336 [label=AccumulateGrad]
	140614972285856 -> 140614972285808
	140614972285856 [label=ReshapeAliasBackward0]
	140614972286384 -> 140614972285856
	140614972286384 [label=NativeBatchNormBackward0]
	140614972286576 -> 140614972286384
	140614972286576 [label=ReshapeAliasBackward0]
	140615017131216 -> 140614972286576
	140614691956592 [label="stages.2.5.conv2b.weight
 (768, 128, 3, 3)" fillcolor=lightblue]
	140614691956592 -> 140615017131216
	140615017131216 [label=AccumulateGrad]
	140614972286480 -> 140614972286384
	140614972286480 [label=ViewBackward0]
	140615017131072 -> 140614972286480
	140615017131072 [label=MulBackward0]
	140615017131264 -> 140615017131072
	140614691956752 [label="stages.2.5.conv2b.gain
 (768, 1, 1, 1)" fillcolor=lightblue]
	140614691956752 -> 140615017131264
	140615017131264 [label=AccumulateGrad]
	140614972285616 -> 140614972285808
	140614691956672 [label="stages.2.5.conv2b.bias
 (768)" fillcolor=lightblue]
	140614691956672 -> 140614972285616
	140614972285616 [label=AccumulateGrad]
	140614972285472 -> 140614972285376
	140614972285472 [label=ReshapeAliasBackward0]
	140614972285952 -> 140614972285472
	140614972285952 [label=NativeBatchNormBackward0]
	140614972286144 -> 140614972285952
	140614972286144 [label=ReshapeAliasBackward0]
	140615017131360 -> 140614972286144
	140614691956912 [label="stages.2.5.conv3.weight
 (1536, 768, 1, 1)" fillcolor=lightblue]
	140614691956912 -> 140615017131360
	140615017131360 [label=AccumulateGrad]
	140614972286048 -> 140614972285952
	140614972286048 [label=ViewBackward0]
	140615017131312 -> 140614972286048
	140615017131312 [label=MulBackward0]
	140615017131408 -> 140615017131312
	140614691957072 [label="stages.2.5.conv3.gain
 (1536, 1, 1, 1)" fillcolor=lightblue]
	140614691957072 -> 140615017131408
	140615017131408 [label=AccumulateGrad]
	140614972285424 -> 140614972285376
	140614691956992 [label="stages.2.5.conv3.bias
 (1536)" fillcolor=lightblue]
	140614691956992 -> 140614972285424
	140614972285424 [label=AccumulateGrad]
	140614972285328 -> 140614972285280
	140614972285328 [label=SigmoidBackward0]
	140614972285760 -> 140614972285328
	140614972285760 [label=ConvolutionBackward0]
	140614972285568 -> 140614972285760
	140614972285568 [label=ReluBackward0]
	140615017131552 -> 140614972285568
	140615017131552 [label=ConvolutionBackward0]
	140615017131648 -> 140615017131552
	140615017131648 [label=MeanBackward1]
	140614972285376 -> 140615017131648
	140615017131600 -> 140615017131552
	140614691957232 [label="stages.2.5.attn_last.fc1.weight
 (768, 1536, 1, 1)" fillcolor=lightblue]
	140614691957232 -> 140615017131600
	140615017131600 [label=AccumulateGrad]
	140615017131456 -> 140615017131552
	140614691957312 [label="stages.2.5.attn_last.fc1.bias
 (768)" fillcolor=lightblue]
	140614691957312 -> 140615017131456
	140615017131456 [label=AccumulateGrad]
	140615017131168 -> 140614972285760
	140614691957472 [label="stages.2.5.attn_last.fc2.weight
 (1536, 768, 1, 1)" fillcolor=lightblue]
	140614691957472 -> 140615017131168
	140615017131168 [label=AccumulateGrad]
	140615017130160 -> 140614972285760
	140614691957552 [label="stages.2.5.attn_last.fc2.bias
 (1536)" fillcolor=lightblue]
	140614691957552 -> 140615017130160
	140615017130160 [label=AccumulateGrad]
	140614972285088 -> 140614972276688
	140614691957632 [label="stages.2.5.skipinit_gain
 ()" fillcolor=lightblue]
	140614691957632 -> 140614972285088
	140614972285088 [label=AccumulateGrad]
	140614972276592 -> 140614972276544
	140614972276112 -> 140614972276064
	140614972276112 [label=ReshapeAliasBackward0]
	140614972276496 -> 140614972276112
	140614972276496 [label=NativeBatchNormBackward0]
	140614972276256 -> 140614972276496
	140614972276256 [label=ReshapeAliasBackward0]
	140614972285184 -> 140614972276256
	140614691958112 [label="stages.3.0.conv1.weight
 (768, 1536, 1, 1)" fillcolor=lightblue]
	140614691958112 -> 140614972285184
	140614972285184 [label=AccumulateGrad]
	140614972276304 -> 140614972276496
	140614972276304 [label=ViewBackward0]
	140614972284992 -> 140614972276304
	140614972284992 [label=MulBackward0]
	140614972285664 -> 140614972284992
	140614691958272 [label="stages.3.0.conv1.gain
 (768, 1, 1, 1)" fillcolor=lightblue]
	140614691958272 -> 140614972285664
	140614972285664 [label=AccumulateGrad]
	140614972275776 -> 140614972276064
	140614691958192 [label="stages.3.0.conv1.bias
 (768)" fillcolor=lightblue]
	140614691958192 -> 140614972275776
	140614972275776 [label=AccumulateGrad]
	140614972275632 -> 140614972275584
	140614972275632 [label=ReshapeAliasBackward0]
	140614972285040 -> 140614972275632
	140614972285040 [label=NativeBatchNormBackward0]
	140614972276016 -> 140614972285040
	140614972276016 [label=ReshapeAliasBackward0]
	140614972276400 -> 140614972276016
	140614691958432 [label="stages.3.0.conv2.weight
 (768, 128, 3, 3)" fillcolor=lightblue]
	140614691958432 -> 140614972276400
	140614972276400 [label=AccumulateGrad]
	140614972275920 -> 140614972285040
	140614972275920 [label=ViewBackward0]
	140614972276208 -> 140614972275920
	140614972276208 [label=MulBackward0]
	140615017131504 -> 140614972276208
	140614691958592 [label="stages.3.0.conv2.gain
 (768, 1, 1, 1)" fillcolor=lightblue]
	140614691958592 -> 140615017131504
	140615017131504 [label=AccumulateGrad]
	140614972275392 -> 140614972275584
	140614691958512 [label="stages.3.0.conv2.bias
 (768)" fillcolor=lightblue]
	140614691958512 -> 140614972275392
	140614972275392 [label=AccumulateGrad]
	140614972275248 -> 140614972275200
	140614972275248 [label=ReshapeAliasBackward0]
	140614972275728 -> 140614972275248
	140614972275728 [label=NativeBatchNormBackward0]
	140614972285232 -> 140614972275728
	140614972285232 [label=ReshapeAliasBackward0]
	140615017131744 -> 140614972285232
	140615278895168 [label="stages.3.0.conv2b.weight
 (768, 128, 3, 3)" fillcolor=lightblue]
	140615278895168 -> 140615017131744
	140615017131744 [label=AccumulateGrad]
	140614972275824 -> 140614972275728
	140614972275824 [label=ViewBackward0]
	140615017131792 -> 140614972275824
	140615017131792 [label=MulBackward0]
	140615017131888 -> 140615017131792
	140615278895328 [label="stages.3.0.conv2b.gain
 (768, 1, 1, 1)" fillcolor=lightblue]
	140615278895328 -> 140615017131888
	140615017131888 [label=AccumulateGrad]
	140614972275008 -> 140614972275200
	140615278895248 [label="stages.3.0.conv2b.bias
 (768)" fillcolor=lightblue]
	140615278895248 -> 140614972275008
	140614972275008 [label=AccumulateGrad]
	140614972274864 -> 140614972274768
	140614972274864 [label=ReshapeAliasBackward0]
	140614972275344 -> 140614972274864
	140614972275344 [label=NativeBatchNormBackward0]
	140614972275536 -> 140614972275344
	140614972275536 [label=ReshapeAliasBackward0]
	140615017131984 -> 140614972275536
	140615278895488 [label="stages.3.0.conv3.weight
 (1536, 768, 1, 1)" fillcolor=lightblue]
	140615278895488 -> 140615017131984
	140615017131984 [label=AccumulateGrad]
	140614972275440 -> 140614972275344
	140614972275440 [label=ViewBackward0]
	140615017131936 -> 140614972275440
	140615017131936 [label=MulBackward0]
	140615017131696 -> 140615017131936
	140615278895648 [label="stages.3.0.conv3.gain
 (1536, 1, 1, 1)" fillcolor=lightblue]
	140615278895648 -> 140615017131696
	140615017131696 [label=AccumulateGrad]
	140614972274816 -> 140614972274768
	140615278895568 [label="stages.3.0.conv3.bias
 (1536)" fillcolor=lightblue]
	140615278895568 -> 140614972274816
	140614972274816 [label=AccumulateGrad]
	140614972274720 -> 140614972274672
	140614972274720 [label=SigmoidBackward0]
	140614972275152 -> 140614972274720
	140614972275152 [label=ConvolutionBackward0]
	140615017131840 -> 140614972275152
	140615017131840 [label=ReluBackward0]
	140615017210064 -> 140615017131840
	140615017210064 [label=ConvolutionBackward0]
	140615017210160 -> 140615017210064
	140615017210160 [label=MeanBackward1]
	140614972274768 -> 140615017210160
	140615017210112 -> 140615017210064
	140615278895808 [label="stages.3.0.attn_last.fc1.weight
 (768, 1536, 1, 1)" fillcolor=lightblue]
	140615278895808 -> 140615017210112
	140615017210112 [label=AccumulateGrad]
	140615017209968 -> 140615017210064
	140615278895888 [label="stages.3.0.attn_last.fc1.bias
 (768)" fillcolor=lightblue]
	140615278895888 -> 140615017209968
	140615017209968 [label=AccumulateGrad]
	140615017130832 -> 140614972275152
	140615278896048 [label="stages.3.0.attn_last.fc2.weight
 (1536, 768, 1, 1)" fillcolor=lightblue]
	140615278896048 -> 140615017130832
	140615017130832 [label=AccumulateGrad]
	140614972274960 -> 140614972275152
	140615278896128 [label="stages.3.0.attn_last.fc2.bias
 (1536)" fillcolor=lightblue]
	140615278896128 -> 140614972274960
	140614972274960 [label=AccumulateGrad]
	140614972274480 -> 140614972274432
	140615278896208 [label="stages.3.0.skipinit_gain
 ()" fillcolor=lightblue]
	140615278896208 -> 140614972274480
	140614972274480 [label=AccumulateGrad]
	140614972273952 -> 140614735739968
	140614972273952 [label=ConvolutionBackward0]
	140614972275056 -> 140614972273952
	140614972275056 [label=AvgPool2DBackward0]
	140614972276160 -> 140614972275056
	140614972274336 -> 140614972273952
	140614972274336 [label=ReshapeAliasBackward0]
	140614972274624 -> 140614972274336
	140614972274624 [label=NativeBatchNormBackward0]
	140615017210352 -> 140614972274624
	140615017210352 [label=ReshapeAliasBackward0]
	140615017210400 -> 140615017210352
	140614691957792 [label="stages.3.0.downsample.conv.weight
 (1536, 1536, 1, 1)" fillcolor=lightblue]
	140614691957792 -> 140615017210400
	140615017210400 [label=AccumulateGrad]
	140615017210208 -> 140614972274624
	140615017210208 [label=ViewBackward0]
	140615017210448 -> 140615017210208
	140615017210448 [label=MulBackward0]
	140615017210544 -> 140615017210448
	140614691957952 [label="stages.3.0.downsample.conv.gain
 (1536, 1, 1, 1)" fillcolor=lightblue]
	140614691957952 -> 140615017210544
	140615017210544 [label=AccumulateGrad]
	140614972274384 -> 140614972273952
	140614691957872 [label="stages.3.0.downsample.conv.bias
 (1536)" fillcolor=lightblue]
	140614691957872 -> 140614972274384
	140614972274384 [label=AccumulateGrad]
	140614972273808 -> 140614972273760
	140614972273808 [label=ReshapeAliasBackward0]
	140614972274240 -> 140614972273808
	140614972274240 [label=NativeBatchNormBackward0]
	140614972274576 -> 140614972274240
	140614972274576 [label=ReshapeAliasBackward0]
	140615017210016 -> 140614972274576
	140615278896368 [label="stages.3.1.conv1.weight
 (768, 1536, 1, 1)" fillcolor=lightblue]
	140615278896368 -> 140615017210016
	140615017210016 [label=AccumulateGrad]
	140614972274192 -> 140614972274240
	140614972274192 [label=ViewBackward0]
	140615017210304 -> 140614972274192
	140615017210304 [label=MulBackward0]
	140615017210592 -> 140615017210304
	140615278896528 [label="stages.3.1.conv1.gain
 (768, 1, 1, 1)" fillcolor=lightblue]
	140615278896528 -> 140615017210592
	140615017210592 [label=AccumulateGrad]
	140614972273568 -> 140614972273760
	140615278896448 [label="stages.3.1.conv1.bias
 (768)" fillcolor=lightblue]
	140615278896448 -> 140614972273568
	140614972273568 [label=AccumulateGrad]
	140614972273424 -> 140614972273376
	140614972273424 [label=ReshapeAliasBackward0]
	140614972273904 -> 140614972273424
	140614972273904 [label=NativeBatchNormBackward0]
	140614972274096 -> 140614972273904
	140614972274096 [label=ReshapeAliasBackward0]
	140615017210688 -> 140614972274096
	140615278896688 [label="stages.3.1.conv2.weight
 (768, 128, 3, 3)" fillcolor=lightblue]
	140615278896688 -> 140615017210688
	140615017210688 [label=AccumulateGrad]
	140614972274000 -> 140614972273904
	140614972274000 [label=ViewBackward0]
	140615017210256 -> 140614972274000
	140615017210256 [label=MulBackward0]
	140615017210736 -> 140615017210256
	140615278896848 [label="stages.3.1.conv2.gain
 (768, 1, 1, 1)" fillcolor=lightblue]
	140615278896848 -> 140615017210736
	140615017210736 [label=AccumulateGrad]
	140614972273184 -> 140614972273376
	140615278896768 [label="stages.3.1.conv2.bias
 (768)" fillcolor=lightblue]
	140615278896768 -> 140614972273184
	140614972273184 [label=AccumulateGrad]
	140614972273040 -> 140614972272992
	140614972273040 [label=ReshapeAliasBackward0]
	140614972273520 -> 140614972273040
	140614972273520 [label=NativeBatchNormBackward0]
	140614972273712 -> 140614972273520
	140614972273712 [label=ReshapeAliasBackward0]
	140615017210832 -> 140614972273712
	140615278897008 [label="stages.3.1.conv2b.weight
 (768, 128, 3, 3)" fillcolor=lightblue]
	140615278897008 -> 140615017210832
	140615017210832 [label=AccumulateGrad]
	140614972273616 -> 140614972273520
	140614972273616 [label=ViewBackward0]
	140615017210784 -> 140614972273616
	140615017210784 [label=MulBackward0]
	140615017210880 -> 140615017210784
	140615278897168 [label="stages.3.1.conv2b.gain
 (768, 1, 1, 1)" fillcolor=lightblue]
	140615278897168 -> 140615017210880
	140615017210880 [label=AccumulateGrad]
	140614972272800 -> 140614972272992
	140615278897088 [label="stages.3.1.conv2b.bias
 (768)" fillcolor=lightblue]
	140615278897088 -> 140614972272800
	140614972272800 [label=AccumulateGrad]
	140614735740832 -> 140614735740784
	140614735740832 [label=ReshapeAliasBackward0]
	140614972273136 -> 140614735740832
	140614972273136 [label=NativeBatchNormBackward0]
	140614972273328 -> 140614972273136
	140614972273328 [label=ReshapeAliasBackward0]
	140615017210976 -> 140614972273328
	140615278897328 [label="stages.3.1.conv3.weight
 (1536, 768, 1, 1)" fillcolor=lightblue]
	140615278897328 -> 140615017210976
	140615017210976 [label=AccumulateGrad]
	140614972273232 -> 140614972273136
	140614972273232 [label=ViewBackward0]
	140615017210928 -> 140614972273232
	140615017210928 [label=MulBackward0]
	140615017211024 -> 140615017210928
	140615278897488 [label="stages.3.1.conv3.gain
 (1536, 1, 1, 1)" fillcolor=lightblue]
	140615278897488 -> 140615017211024
	140615017211024 [label=AccumulateGrad]
	140614972272704 -> 140614735740784
	140615278897408 [label="stages.3.1.conv3.bias
 (1536)" fillcolor=lightblue]
	140615278897408 -> 140614972272704
	140614972272704 [label=AccumulateGrad]
	140614735740736 -> 140614735740688
	140614735740736 [label=SigmoidBackward0]
	140614972272944 -> 140614735740736
	140614972272944 [label=ConvolutionBackward0]
	140614972272752 -> 140614972272944
	140614972272752 [label=ReluBackward0]
	140615017211168 -> 140614972272752
	140615017211168 [label=ConvolutionBackward0]
	140615017211264 -> 140615017211168
	140615017211264 [label=MeanBackward1]
	140614735740784 -> 140615017211264
	140615017211216 -> 140615017211168
	140615278897648 [label="stages.3.1.attn_last.fc1.weight
 (768, 1536, 1, 1)" fillcolor=lightblue]
	140615278897648 -> 140615017211216
	140615017211216 [label=AccumulateGrad]
	140615017211072 -> 140615017211168
	140615278897728 [label="stages.3.1.attn_last.fc1.bias
 (768)" fillcolor=lightblue]
	140615278897728 -> 140615017211072
	140615017211072 [label=AccumulateGrad]
	140615017210496 -> 140614972272944
	140615278897888 [label="stages.3.1.attn_last.fc2.weight
 (1536, 768, 1, 1)" fillcolor=lightblue]
	140615278897888 -> 140615017210496
	140615017210496 [label=AccumulateGrad]
	140615017210640 -> 140614972272944
	140615278897968 [label="stages.3.1.attn_last.fc2.bias
 (1536)" fillcolor=lightblue]
	140615278897968 -> 140615017210640
	140615017210640 [label=AccumulateGrad]
	140614735740496 -> 140614735740448
	140615278898048 [label="stages.3.1.skipinit_gain
 ()" fillcolor=lightblue]
	140615278898048 -> 140614735740496
	140614735740496 [label=AccumulateGrad]
	140614735739968 -> 140614735737328
	140614735739824 -> 140614735739776
	140614735739824 [label=ReshapeAliasBackward0]
	140614972272848 -> 140614735739824
	140614972272848 [label=NativeBatchNormBackward0]
	140614735740208 -> 140614972272848
	140614735740208 [label=ReshapeAliasBackward0]
	140614735740592 -> 140614735740208
	140615278898208 [label="stages.3.2.conv1.weight
 (768, 1536, 1, 1)" fillcolor=lightblue]
	140615278898208 -> 140614735740592
	140614735740592 [label=AccumulateGrad]
	140614735740256 -> 140614972272848
	140614735740256 [label=ViewBackward0]
	140614735740400 -> 140614735740256
	140614735740400 [label=MulBackward0]
	140614735740352 -> 140614735740400
	140615278898368 [label="stages.3.2.conv1.gain
 (768, 1, 1, 1)" fillcolor=lightblue]
	140615278898368 -> 140614735740352
	140614735740352 [label=AccumulateGrad]
	140614735739584 -> 140614735739776
	140615278898288 [label="stages.3.2.conv1.bias
 (768)" fillcolor=lightblue]
	140615278898288 -> 140614735739584
	140614735739584 [label=AccumulateGrad]
	140614735739440 -> 140614735739392
	140614735739440 [label=ReshapeAliasBackward0]
	140614735739920 -> 140614735739440
	140614735739920 [label=NativeBatchNormBackward0]
	140614735740016 -> 140614735739920
	140614735740016 [label=ReshapeAliasBackward0]
	140614735740112 -> 140614735740016
	140615278898528 [label="stages.3.2.conv2.weight
 (768, 128, 3, 3)" fillcolor=lightblue]
	140615278898528 -> 140614735740112
	140614735740112 [label=AccumulateGrad]
	140614735740640 -> 140614735739920
	140614735740640 [label=ViewBackward0]
	140615017211312 -> 140614735740640
	140615017211312 [label=MulBackward0]
	140615017211408 -> 140615017211312
	140615278898688 [label="stages.3.2.conv2.gain
 (768, 1, 1, 1)" fillcolor=lightblue]
	140615278898688 -> 140615017211408
	140615017211408 [label=AccumulateGrad]
	140614735739200 -> 140614735739392
	140615278898608 [label="stages.3.2.conv2.bias
 (768)" fillcolor=lightblue]
	140615278898608 -> 140614735739200
	140614735739200 [label=AccumulateGrad]
	140614735739056 -> 140614735739008
	140614735739056 [label=ReshapeAliasBackward0]
	140614735739536 -> 140614735739056
	140614735739536 [label=NativeBatchNormBackward0]
	140614735739728 -> 140614735739536
	140614735739728 [label=ReshapeAliasBackward0]
	140615017211504 -> 140614735739728
	140615278898848 [label="stages.3.2.conv2b.weight
 (768, 128, 3, 3)" fillcolor=lightblue]
	140615278898848 -> 140615017211504
	140615017211504 [label=AccumulateGrad]
	140614735739632 -> 140614735739536
	140614735739632 [label=ViewBackward0]
	140615017211360 -> 140614735739632
	140615017211360 [label=MulBackward0]
	140615017211552 -> 140615017211360
	140615278899008 [label="stages.3.2.conv2b.gain
 (768, 1, 1, 1)" fillcolor=lightblue]
	140615278899008 -> 140615017211552
	140615017211552 [label=AccumulateGrad]
	140614735738816 -> 140614735739008
	140615278898928 [label="stages.3.2.conv2b.bias
 (768)" fillcolor=lightblue]
	140615278898928 -> 140614735738816
	140614735738816 [label=AccumulateGrad]
	140614735738672 -> 140614735738576
	140614735738672 [label=ReshapeAliasBackward0]
	140614735739152 -> 140614735738672
	140614735739152 [label=NativeBatchNormBackward0]
	140614735739344 -> 140614735739152
	140614735739344 [label=ReshapeAliasBackward0]
	140615017211648 -> 140614735739344
	140615279022144 [label="stages.3.2.conv3.weight
 (1536, 768, 1, 1)" fillcolor=lightblue]
	140615279022144 -> 140615017211648
	140615017211648 [label=AccumulateGrad]
	140614735739248 -> 140614735739152
	140614735739248 [label=ViewBackward0]
	140615017211600 -> 140614735739248
	140615017211600 [label=MulBackward0]
	140615017211696 -> 140615017211600
	140615279022304 [label="stages.3.2.conv3.gain
 (1536, 1, 1, 1)" fillcolor=lightblue]
	140615279022304 -> 140615017211696
	140615017211696 [label=AccumulateGrad]
	140614735738624 -> 140614735738576
	140615279022224 [label="stages.3.2.conv3.bias
 (1536)" fillcolor=lightblue]
	140615279022224 -> 140614735738624
	140614735738624 [label=AccumulateGrad]
	140614735738528 -> 140614735738480
	140614735738528 [label=SigmoidBackward0]
	140614735738960 -> 140614735738528
	140614735738960 [label=ConvolutionBackward0]
	140614735738768 -> 140614735738960
	140614735738768 [label=ReluBackward0]
	140615017211840 -> 140614735738768
	140615017211840 [label=ConvolutionBackward0]
	140615017211936 -> 140615017211840
	140615017211936 [label=MeanBackward1]
	140614735738576 -> 140615017211936
	140615017211888 -> 140615017211840
	140615279022464 [label="stages.3.2.attn_last.fc1.weight
 (768, 1536, 1, 1)" fillcolor=lightblue]
	140615279022464 -> 140615017211888
	140615017211888 [label=AccumulateGrad]
	140615017211744 -> 140615017211840
	140615279022544 [label="stages.3.2.attn_last.fc1.bias
 (768)" fillcolor=lightblue]
	140615279022544 -> 140615017211744
	140615017211744 [label=AccumulateGrad]
	140615017211456 -> 140614735738960
	140615279022704 [label="stages.3.2.attn_last.fc2.weight
 (1536, 768, 1, 1)" fillcolor=lightblue]
	140615279022704 -> 140615017211456
	140615017211456 [label=AccumulateGrad]
	140615017209920 -> 140614735738960
	140615279022784 [label="stages.3.2.attn_last.fc2.bias
 (1536)" fillcolor=lightblue]
	140615279022784 -> 140615017209920
	140615017209920 [label=AccumulateGrad]
	140614735738096 -> 140614735738000
	140615279022864 [label="stages.3.2.skipinit_gain
 ()" fillcolor=lightblue]
	140615279022864 -> 140614735738096
	140614735738096 [label=AccumulateGrad]
	140614735737328 -> 140614735738192
	140614735737520 -> 140614735737856
	140614735737520 [label=ReshapeAliasBackward0]
	140614735737232 -> 140614735737520
	140614735737232 [label=NativeBatchNormBackward0]
	140614735738384 -> 140614735737232
	140614735738384 [label=ReshapeAliasBackward0]
	140614735738432 -> 140614735738384
	140615279023024 [label="final_conv.weight
 (3072, 1536, 1, 1)" fillcolor=lightblue]
	140615279023024 -> 140614735738432
	140614735738432 [label=AccumulateGrad]
	140614735738864 -> 140614735737232
	140614735738864 [label=ViewBackward0]
	140615017211984 -> 140614735738864
	140615017211984 [label=MulBackward0]
	140615017212080 -> 140615017211984
	140615279023184 [label="final_conv.gain
 (3072, 1, 1, 1)" fillcolor=lightblue]
	140615279023184 -> 140615017212080
	140615017212080 [label=AccumulateGrad]
	140614735737424 -> 140614735737856
	140615279023104 [label="final_conv.bias
 (3072)" fillcolor=lightblue]
	140615279023104 -> 140614735737424
	140614735737424 [label=AccumulateGrad]
	140615278963824 -> 140615278962624
	140615278963824 [label=TBackward0]
	140614735737952 -> 140615278963824
	140615279023264 [label="head.fc.weight
 (1000, 3072)" fillcolor=lightblue]
	140615279023264 -> 140614735737952
	140614735737952 [label=AccumulateGrad]
	140615278962624 -> 140614972231984
}
