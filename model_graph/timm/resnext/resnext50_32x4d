digraph {
	graph [size="152.25,152.25"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140342364274416 [label="
 ()" fillcolor=darkolivegreen1]
	140342907117920 [label=MeanBackward0]
	140342896134080 -> 140342907117920
	140342896134080 [label=AddmmBackward0]
	140342896132496 -> 140342896134080
	140342896081632 [label="fc.bias
 (1000)" fillcolor=lightblue]
	140342896081632 -> 140342896132496
	140342896132496 [label=AccumulateGrad]
	140342896134320 -> 140342896134080
	140342896134320 [label=ReshapeAliasBackward0]
	140342896133504 -> 140342896134320
	140342896133504 [label=MeanBackward1]
	140342896135952 -> 140342896133504
	140342896135952 [label=ReluBackward0]
	140342896133312 -> 140342896135952
	140342896133312 [label=AddBackward0]
	140342896133264 -> 140342896133312
	140342896133264 [label=NativeBatchNormBackward0]
	140342896132976 -> 140342896133264
	140342896132976 [label=ConvolutionBackward0]
	140342907230912 -> 140342896132976
	140342907230912 [label=ReluBackward0]
	140342907231152 -> 140342907230912
	140342907231152 [label=NativeBatchNormBackward0]
	140342907231056 -> 140342907231152
	140342907231056 [label=ConvolutionBackward0]
	140342907231440 -> 140342907231056
	140342907231440 [label=ReluBackward0]
	140342907230768 -> 140342907231440
	140342907230768 [label=NativeBatchNormBackward0]
	140342907231824 -> 140342907230768
	140342907231824 [label=ConvolutionBackward0]
	140342896134224 -> 140342907231824
	140342896134224 [label=ReluBackward0]
	140342907231872 -> 140342896134224
	140342907231872 [label=AddBackward0]
	140342907232064 -> 140342907231872
	140342907232064 [label=NativeBatchNormBackward0]
	140342907232208 -> 140342907232064
	140342907232208 [label=ConvolutionBackward0]
	140342364283088 -> 140342907232208
	140342364283088 [label=ReluBackward0]
	140342364283232 -> 140342364283088
	140342364283232 [label=NativeBatchNormBackward0]
	140342364283280 -> 140342364283232
	140342364283280 [label=ConvolutionBackward0]
	140342364283568 -> 140342364283280
	140342364283568 [label=ReluBackward0]
	140342364283712 -> 140342364283568
	140342364283712 [label=NativeBatchNormBackward0]
	140342364283760 -> 140342364283712
	140342364283760 [label=ConvolutionBackward0]
	140342907231920 -> 140342364283760
	140342907231920 [label=ReluBackward0]
	140342364284144 -> 140342907231920
	140342364284144 [label=AddBackward0]
	140342364284192 -> 140342364284144
	140342364284192 [label=NativeBatchNormBackward0]
	140342364284432 -> 140342364284192
	140342364284432 [label=ConvolutionBackward0]
	140342364284624 -> 140342364284432
	140342364284624 [label=ReluBackward0]
	140342364284768 -> 140342364284624
	140342364284768 [label=NativeBatchNormBackward0]
	140342364284816 -> 140342364284768
	140342364284816 [label=ConvolutionBackward0]
	140342364285104 -> 140342364284816
	140342364285104 [label=ReluBackward0]
	140342364285248 -> 140342364285104
	140342364285248 [label=NativeBatchNormBackward0]
	140342364285296 -> 140342364285248
	140342364285296 [label=ConvolutionBackward0]
	140342364285584 -> 140342364285296
	140342364285584 [label=ReluBackward0]
	140342364285728 -> 140342364285584
	140342364285728 [label=AddBackward0]
	140342364285776 -> 140342364285728
	140342364285776 [label=NativeBatchNormBackward0]
	140342364286016 -> 140342364285776
	140342364286016 [label=ConvolutionBackward0]
	140342364286208 -> 140342364286016
	140342364286208 [label=ReluBackward0]
	140342364286352 -> 140342364286208
	140342364286352 [label=NativeBatchNormBackward0]
	140342364286400 -> 140342364286352
	140342364286400 [label=ConvolutionBackward0]
	140342364286688 -> 140342364286400
	140342364286688 [label=ReluBackward0]
	140342364286832 -> 140342364286688
	140342364286832 [label=NativeBatchNormBackward0]
	140342364286880 -> 140342364286832
	140342364286880 [label=ConvolutionBackward0]
	140342364285632 -> 140342364286880
	140342364285632 [label=ReluBackward0]
	140342364365152 -> 140342364285632
	140342364365152 [label=AddBackward0]
	140342364365200 -> 140342364365152
	140342364365200 [label=NativeBatchNormBackward0]
	140342364365440 -> 140342364365200
	140342364365440 [label=ConvolutionBackward0]
	140342364365632 -> 140342364365440
	140342364365632 [label=ReluBackward0]
	140342364365776 -> 140342364365632
	140342364365776 [label=NativeBatchNormBackward0]
	140342364365824 -> 140342364365776
	140342364365824 [label=ConvolutionBackward0]
	140342364366112 -> 140342364365824
	140342364366112 [label=ReluBackward0]
	140342364366256 -> 140342364366112
	140342364366256 [label=NativeBatchNormBackward0]
	140342364366304 -> 140342364366256
	140342364366304 [label=ConvolutionBackward0]
	140342364364960 -> 140342364366304
	140342364364960 [label=ReluBackward0]
	140342364366688 -> 140342364364960
	140342364366688 [label=AddBackward0]
	140342364366736 -> 140342364366688
	140342364366736 [label=NativeBatchNormBackward0]
	140342364366976 -> 140342364366736
	140342364366976 [label=ConvolutionBackward0]
	140342364367168 -> 140342364366976
	140342364367168 [label=ReluBackward0]
	140342364367312 -> 140342364367168
	140342364367312 [label=NativeBatchNormBackward0]
	140342364367360 -> 140342364367312
	140342364367360 [label=ConvolutionBackward0]
	140342364367648 -> 140342364367360
	140342364367648 [label=ReluBackward0]
	140342364367792 -> 140342364367648
	140342364367792 [label=NativeBatchNormBackward0]
	140342364367840 -> 140342364367792
	140342364367840 [label=ConvolutionBackward0]
	140342364366496 -> 140342364367840
	140342364366496 [label=ReluBackward0]
	140342364368224 -> 140342364366496
	140342364368224 [label=AddBackward0]
	140342364368272 -> 140342364368224
	140342364368272 [label=NativeBatchNormBackward0]
	140342364368512 -> 140342364368272
	140342364368512 [label=ConvolutionBackward0]
	140342364368704 -> 140342364368512
	140342364368704 [label=ReluBackward0]
	140342364368848 -> 140342364368704
	140342364368848 [label=NativeBatchNormBackward0]
	140342364385392 -> 140342364368848
	140342364385392 [label=ConvolutionBackward0]
	140342364385632 -> 140342364385392
	140342364385632 [label=ReluBackward0]
	140342364385776 -> 140342364385632
	140342364385776 [label=NativeBatchNormBackward0]
	140342364385824 -> 140342364385776
	140342364385824 [label=ConvolutionBackward0]
	140342364368032 -> 140342364385824
	140342364368032 [label=ReluBackward0]
	140342364386208 -> 140342364368032
	140342364386208 [label=AddBackward0]
	140342364386256 -> 140342364386208
	140342364386256 [label=NativeBatchNormBackward0]
	140342364386496 -> 140342364386256
	140342364386496 [label=ConvolutionBackward0]
	140342364386688 -> 140342364386496
	140342364386688 [label=ReluBackward0]
	140342364386832 -> 140342364386688
	140342364386832 [label=NativeBatchNormBackward0]
	140342364386880 -> 140342364386832
	140342364386880 [label=ConvolutionBackward0]
	140342364387168 -> 140342364386880
	140342364387168 [label=ReluBackward0]
	140342364387312 -> 140342364387168
	140342364387312 [label=NativeBatchNormBackward0]
	140342364387360 -> 140342364387312
	140342364387360 [label=ConvolutionBackward0]
	140342364386016 -> 140342364387360
	140342364386016 [label=ReluBackward0]
	140342364387744 -> 140342364386016
	140342364387744 [label=AddBackward0]
	140342364387792 -> 140342364387744
	140342364387792 [label=NativeBatchNormBackward0]
	140342364388032 -> 140342364387792
	140342364388032 [label=ConvolutionBackward0]
	140342364388224 -> 140342364388032
	140342364388224 [label=ReluBackward0]
	140342364388368 -> 140342364388224
	140342364388368 [label=NativeBatchNormBackward0]
	140342364388416 -> 140342364388368
	140342364388416 [label=ConvolutionBackward0]
	140342364388704 -> 140342364388416
	140342364388704 [label=ReluBackward0]
	140342364388848 -> 140342364388704
	140342364388848 [label=NativeBatchNormBackward0]
	140342364388896 -> 140342364388848
	140342364388896 [label=ConvolutionBackward0]
	140342364389184 -> 140342364388896
	140342364389184 [label=ReluBackward0]
	140342364389328 -> 140342364389184
	140342364389328 [label=AddBackward0]
	140342364393584 -> 140342364389328
	140342364393584 [label=NativeBatchNormBackward0]
	140342364393776 -> 140342364393584
	140342364393776 [label=ConvolutionBackward0]
	140342364393968 -> 140342364393776
	140342364393968 [label=ReluBackward0]
	140342364394112 -> 140342364393968
	140342364394112 [label=NativeBatchNormBackward0]
	140342364394160 -> 140342364394112
	140342364394160 [label=ConvolutionBackward0]
	140342364394448 -> 140342364394160
	140342364394448 [label=ReluBackward0]
	140342364394592 -> 140342364394448
	140342364394592 [label=NativeBatchNormBackward0]
	140342364394640 -> 140342364394592
	140342364394640 [label=ConvolutionBackward0]
	140342364393536 -> 140342364394640
	140342364393536 [label=ReluBackward0]
	140342364395024 -> 140342364393536
	140342364395024 [label=AddBackward0]
	140342364395072 -> 140342364395024
	140342364395072 [label=NativeBatchNormBackward0]
	140342364395312 -> 140342364395072
	140342364395312 [label=ConvolutionBackward0]
	140342364395504 -> 140342364395312
	140342364395504 [label=ReluBackward0]
	140342364395648 -> 140342364395504
	140342364395648 [label=NativeBatchNormBackward0]
	140342364395696 -> 140342364395648
	140342364395696 [label=ConvolutionBackward0]
	140342364395984 -> 140342364395696
	140342364395984 [label=ReluBackward0]
	140342364396128 -> 140342364395984
	140342364396128 [label=NativeBatchNormBackward0]
	140342364396176 -> 140342364396128
	140342364396176 [label=ConvolutionBackward0]
	140342364394832 -> 140342364396176
	140342364394832 [label=ReluBackward0]
	140342364396560 -> 140342364394832
	140342364396560 [label=AddBackward0]
	140342364396608 -> 140342364396560
	140342364396608 [label=NativeBatchNormBackward0]
	140342364396848 -> 140342364396608
	140342364396848 [label=ConvolutionBackward0]
	140342364397040 -> 140342364396848
	140342364397040 [label=ReluBackward0]
	140342364397184 -> 140342364397040
	140342364397184 [label=NativeBatchNormBackward0]
	140342364397232 -> 140342364397184
	140342364397232 [label=ConvolutionBackward0]
	140342364397520 -> 140342364397232
	140342364397520 [label=ReluBackward0]
	140342364405920 -> 140342364397520
	140342364405920 [label=NativeBatchNormBackward0]
	140342364405968 -> 140342364405920
	140342364405968 [label=ConvolutionBackward0]
	140342364396368 -> 140342364405968
	140342364396368 [label=ReluBackward0]
	140342364406352 -> 140342364396368
	140342364406352 [label=AddBackward0]
	140342364406400 -> 140342364406352
	140342364406400 [label=NativeBatchNormBackward0]
	140342364406640 -> 140342364406400
	140342364406640 [label=ConvolutionBackward0]
	140342364406832 -> 140342364406640
	140342364406832 [label=ReluBackward0]
	140342364406976 -> 140342364406832
	140342364406976 [label=NativeBatchNormBackward0]
	140342364407024 -> 140342364406976
	140342364407024 [label=ConvolutionBackward0]
	140342364407312 -> 140342364407024
	140342364407312 [label=ReluBackward0]
	140342364407456 -> 140342364407312
	140342364407456 [label=NativeBatchNormBackward0]
	140342364407504 -> 140342364407456
	140342364407504 [label=ConvolutionBackward0]
	140342364407792 -> 140342364407504
	140342364407792 [label=ReluBackward0]
	140342364407936 -> 140342364407792
	140342364407936 [label=AddBackward0]
	140342364407984 -> 140342364407936
	140342364407984 [label=NativeBatchNormBackward0]
	140342364408224 -> 140342364407984
	140342364408224 [label=ConvolutionBackward0]
	140342364408416 -> 140342364408224
	140342364408416 [label=ReluBackward0]
	140342364408560 -> 140342364408416
	140342364408560 [label=NativeBatchNormBackward0]
	140342364408608 -> 140342364408560
	140342364408608 [label=ConvolutionBackward0]
	140342364408896 -> 140342364408608
	140342364408896 [label=ReluBackward0]
	140342364409040 -> 140342364408896
	140342364409040 [label=NativeBatchNormBackward0]
	140342364409088 -> 140342364409040
	140342364409088 [label=ConvolutionBackward0]
	140342364407840 -> 140342364409088
	140342364407840 [label=ReluBackward0]
	140342364409472 -> 140342364407840
	140342364409472 [label=AddBackward0]
	140342364409520 -> 140342364409472
	140342364409520 [label=NativeBatchNormBackward0]
	140342364409760 -> 140342364409520
	140342364409760 [label=ConvolutionBackward0]
	140342364418208 -> 140342364409760
	140342364418208 [label=ReluBackward0]
	140342364418352 -> 140342364418208
	140342364418352 [label=NativeBatchNormBackward0]
	140342364418400 -> 140342364418352
	140342364418400 [label=ConvolutionBackward0]
	140342364418688 -> 140342364418400
	140342364418688 [label=ReluBackward0]
	140342364418832 -> 140342364418688
	140342364418832 [label=NativeBatchNormBackward0]
	140342364418880 -> 140342364418832
	140342364418880 [label=ConvolutionBackward0]
	140342364409280 -> 140342364418880
	140342364409280 [label=ReluBackward0]
	140342364419264 -> 140342364409280
	140342364419264 [label=AddBackward0]
	140342364419312 -> 140342364419264
	140342364419312 [label=NativeBatchNormBackward0]
	140342364419552 -> 140342364419312
	140342364419552 [label=ConvolutionBackward0]
	140342364419744 -> 140342364419552
	140342364419744 [label=ReluBackward0]
	140342364419888 -> 140342364419744
	140342364419888 [label=NativeBatchNormBackward0]
	140342364419936 -> 140342364419888
	140342364419936 [label=ConvolutionBackward0]
	140342364420224 -> 140342364419936
	140342364420224 [label=ReluBackward0]
	140342364420368 -> 140342364420224
	140342364420368 [label=NativeBatchNormBackward0]
	140342364420416 -> 140342364420368
	140342364420416 [label=ConvolutionBackward0]
	140342364420704 -> 140342364420416
	140342364420704 [label=MaxPool2DWithIndicesBackward0]
	140342364420848 -> 140342364420704
	140342364420848 [label=ReluBackward0]
	140342364420896 -> 140342364420848
	140342364420896 [label=NativeBatchNormBackward0]
	140342364421040 -> 140342364420896
	140342364421040 [label=ConvolutionBackward0]
	140342364421328 -> 140342364421040
	140342511277056 [label="conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	140342511277056 -> 140342364421328
	140342364421328 [label=AccumulateGrad]
	140342364420992 -> 140342364420896
	140342511277136 [label="bn1.weight
 (64)" fillcolor=lightblue]
	140342511277136 -> 140342364420992
	140342364420992 [label=AccumulateGrad]
	140342364421136 -> 140342364420896
	140342511277216 [label="bn1.bias
 (64)" fillcolor=lightblue]
	140342511277216 -> 140342364421136
	140342364421136 [label=AccumulateGrad]
	140342364420656 -> 140342364420416
	140342511278256 [label="layer1.0.conv1.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	140342511278256 -> 140342364420656
	140342364420656 [label=AccumulateGrad]
	140342364420272 -> 140342364420368
	140342511278336 [label="layer1.0.bn1.weight
 (128)" fillcolor=lightblue]
	140342511278336 -> 140342364420272
	140342364420272 [label=AccumulateGrad]
	140342364420512 -> 140342364420368
	140342511278416 [label="layer1.0.bn1.bias
 (128)" fillcolor=lightblue]
	140342511278416 -> 140342364420512
	140342364420512 [label=AccumulateGrad]
	140342364420176 -> 140342364419936
	140342511278896 [label="layer1.0.conv2.weight
 (128, 4, 3, 3)" fillcolor=lightblue]
	140342511278896 -> 140342364420176
	140342364420176 [label=AccumulateGrad]
	140342364419792 -> 140342364419888
	140342511278816 [label="layer1.0.bn2.weight
 (128)" fillcolor=lightblue]
	140342511278816 -> 140342364419792
	140342364419792 [label=AccumulateGrad]
	140342364420032 -> 140342364419888
	140342511278976 [label="layer1.0.bn2.bias
 (128)" fillcolor=lightblue]
	140342511278976 -> 140342364420032
	140342364420032 [label=AccumulateGrad]
	140342364419696 -> 140342364419552
	140342511279376 [label="layer1.0.conv3.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	140342511279376 -> 140342364419696
	140342364419696 [label=AccumulateGrad]
	140342364419504 -> 140342364419312
	140342511279456 [label="layer1.0.bn3.weight
 (256)" fillcolor=lightblue]
	140342511279456 -> 140342364419504
	140342364419504 [label=AccumulateGrad]
	140342364419456 -> 140342364419312
	140342511279536 [label="layer1.0.bn3.bias
 (256)" fillcolor=lightblue]
	140342511279536 -> 140342364419456
	140342364419456 [label=AccumulateGrad]
	140342364419072 -> 140342364419264
	140342364419072 [label=NativeBatchNormBackward0]
	140342364420128 -> 140342364419072
	140342364420128 [label=ConvolutionBackward0]
	140342364420704 -> 140342364420128
	140342364420560 -> 140342364420128
	140342511277696 [label="layer1.0.downsample.0.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140342511277696 -> 140342364420560
	140342364420560 [label=AccumulateGrad]
	140342364419648 -> 140342364419072
	140342511277776 [label="layer1.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	140342511277776 -> 140342364419648
	140342364419648 [label=AccumulateGrad]
	140342364419600 -> 140342364419072
	140342511277856 [label="layer1.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	140342511277856 -> 140342364419600
	140342364419600 [label=AccumulateGrad]
	140342364419168 -> 140342364418880
	140342511279936 [label="layer1.1.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	140342511279936 -> 140342364419168
	140342364419168 [label=AccumulateGrad]
	140342364418736 -> 140342364418832
	140342511280016 [label="layer1.1.bn1.weight
 (128)" fillcolor=lightblue]
	140342511280016 -> 140342364418736
	140342364418736 [label=AccumulateGrad]
	140342364418976 -> 140342364418832
	140342760079424 [label="layer1.1.bn1.bias
 (128)" fillcolor=lightblue]
	140342760079424 -> 140342364418976
	140342364418976 [label=AccumulateGrad]
	140342364418640 -> 140342364418400
	140342760079904 [label="layer1.1.conv2.weight
 (128, 4, 3, 3)" fillcolor=lightblue]
	140342760079904 -> 140342364418640
	140342364418640 [label=AccumulateGrad]
	140342364418256 -> 140342364418352
	140342760079824 [label="layer1.1.bn2.weight
 (128)" fillcolor=lightblue]
	140342760079824 -> 140342364418256
	140342364418256 [label=AccumulateGrad]
	140342364418496 -> 140342364418352
	140342760079984 [label="layer1.1.bn2.bias
 (128)" fillcolor=lightblue]
	140342760079984 -> 140342364418496
	140342364418496 [label=AccumulateGrad]
	140342364418160 -> 140342364409760
	140342760080384 [label="layer1.1.conv3.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	140342760080384 -> 140342364418160
	140342364418160 [label=AccumulateGrad]
	140342364409712 -> 140342364409520
	140342760080464 [label="layer1.1.bn3.weight
 (256)" fillcolor=lightblue]
	140342760080464 -> 140342364409712
	140342364409712 [label=AccumulateGrad]
	140342364409664 -> 140342364409520
	140342760080544 [label="layer1.1.bn3.bias
 (256)" fillcolor=lightblue]
	140342760080544 -> 140342364409664
	140342364409664 [label=AccumulateGrad]
	140342364409280 -> 140342364409472
	140342364409376 -> 140342364409088
	140342760080944 [label="layer1.2.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	140342760080944 -> 140342364409376
	140342364409376 [label=AccumulateGrad]
	140342364408944 -> 140342364409040
	140342760081024 [label="layer1.2.bn1.weight
 (128)" fillcolor=lightblue]
	140342760081024 -> 140342364408944
	140342364408944 [label=AccumulateGrad]
	140342364409184 -> 140342364409040
	140342760081104 [label="layer1.2.bn1.bias
 (128)" fillcolor=lightblue]
	140342760081104 -> 140342364409184
	140342364409184 [label=AccumulateGrad]
	140342364408848 -> 140342364408608
	140342760081584 [label="layer1.2.conv2.weight
 (128, 4, 3, 3)" fillcolor=lightblue]
	140342760081584 -> 140342364408848
	140342364408848 [label=AccumulateGrad]
	140342364408464 -> 140342364408560
	140342760081504 [label="layer1.2.bn2.weight
 (128)" fillcolor=lightblue]
	140342760081504 -> 140342364408464
	140342364408464 [label=AccumulateGrad]
	140342364408704 -> 140342364408560
	140342760081664 [label="layer1.2.bn2.bias
 (128)" fillcolor=lightblue]
	140342760081664 -> 140342364408704
	140342364408704 [label=AccumulateGrad]
	140342364408368 -> 140342364408224
	140342760082064 [label="layer1.2.conv3.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	140342760082064 -> 140342364408368
	140342364408368 [label=AccumulateGrad]
	140342364408176 -> 140342364407984
	140342760082144 [label="layer1.2.bn3.weight
 (256)" fillcolor=lightblue]
	140342760082144 -> 140342364408176
	140342364408176 [label=AccumulateGrad]
	140342364408128 -> 140342364407984
	140342760082224 [label="layer1.2.bn3.bias
 (256)" fillcolor=lightblue]
	140342760082224 -> 140342364408128
	140342364408128 [label=AccumulateGrad]
	140342364407840 -> 140342364407936
	140342364407744 -> 140342364407504
	140342760083184 [label="layer2.0.conv1.weight
 (256, 256, 1, 1)" fillcolor=lightblue]
	140342760083184 -> 140342364407744
	140342364407744 [label=AccumulateGrad]
	140342364407360 -> 140342364407456
	140342760083264 [label="layer2.0.bn1.weight
 (256)" fillcolor=lightblue]
	140342760083264 -> 140342364407360
	140342364407360 [label=AccumulateGrad]
	140342364407600 -> 140342364407456
	140342760083344 [label="layer2.0.bn1.bias
 (256)" fillcolor=lightblue]
	140342760083344 -> 140342364407600
	140342364407600 [label=AccumulateGrad]
	140342364407264 -> 140342364407024
	140342760186320 [label="layer2.0.conv2.weight
 (256, 8, 3, 3)" fillcolor=lightblue]
	140342760186320 -> 140342364407264
	140342364407264 [label=AccumulateGrad]
	140342364406880 -> 140342364406976
	140342760186240 [label="layer2.0.bn2.weight
 (256)" fillcolor=lightblue]
	140342760186240 -> 140342364406880
	140342364406880 [label=AccumulateGrad]
	140342364407120 -> 140342364406976
	140342760186400 [label="layer2.0.bn2.bias
 (256)" fillcolor=lightblue]
	140342760186400 -> 140342364407120
	140342364407120 [label=AccumulateGrad]
	140342364406784 -> 140342364406640
	140342760186800 [label="layer2.0.conv3.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	140342760186800 -> 140342364406784
	140342364406784 [label=AccumulateGrad]
	140342364406592 -> 140342364406400
	140342760186880 [label="layer2.0.bn3.weight
 (512)" fillcolor=lightblue]
	140342760186880 -> 140342364406592
	140342364406592 [label=AccumulateGrad]
	140342364406544 -> 140342364406400
	140342760186960 [label="layer2.0.bn3.bias
 (512)" fillcolor=lightblue]
	140342760186960 -> 140342364406544
	140342364406544 [label=AccumulateGrad]
	140342364406160 -> 140342364406352
	140342364406160 [label=NativeBatchNormBackward0]
	140342364407216 -> 140342364406160
	140342364407216 [label=ConvolutionBackward0]
	140342364407792 -> 140342364407216
	140342364407648 -> 140342364407216
	140342760082624 [label="layer2.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	140342760082624 -> 140342364407648
	140342364407648 [label=AccumulateGrad]
	140342364406736 -> 140342364406160
	140342760082704 [label="layer2.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	140342760082704 -> 140342364406736
	140342364406736 [label=AccumulateGrad]
	140342364406688 -> 140342364406160
	140342760082784 [label="layer2.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	140342760082784 -> 140342364406688
	140342364406688 [label=AccumulateGrad]
	140342364406256 -> 140342364405968
	140342760187360 [label="layer2.1.conv1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	140342760187360 -> 140342364406256
	140342364406256 [label=AccumulateGrad]
	140342364405824 -> 140342364405920
	140342760187440 [label="layer2.1.bn1.weight
 (256)" fillcolor=lightblue]
	140342760187440 -> 140342364405824
	140342364405824 [label=AccumulateGrad]
	140342364406064 -> 140342364405920
	140342760187520 [label="layer2.1.bn1.bias
 (256)" fillcolor=lightblue]
	140342760187520 -> 140342364406064
	140342364406064 [label=AccumulateGrad]
	140342364397472 -> 140342364397232
	140342760188000 [label="layer2.1.conv2.weight
 (256, 8, 3, 3)" fillcolor=lightblue]
	140342760188000 -> 140342364397472
	140342364397472 [label=AccumulateGrad]
	140342364397088 -> 140342364397184
	140342760187920 [label="layer2.1.bn2.weight
 (256)" fillcolor=lightblue]
	140342760187920 -> 140342364397088
	140342364397088 [label=AccumulateGrad]
	140342364397328 -> 140342364397184
	140342760188080 [label="layer2.1.bn2.bias
 (256)" fillcolor=lightblue]
	140342760188080 -> 140342364397328
	140342364397328 [label=AccumulateGrad]
	140342364396992 -> 140342364396848
	140342760188480 [label="layer2.1.conv3.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	140342760188480 -> 140342364396992
	140342364396992 [label=AccumulateGrad]
	140342364396800 -> 140342364396608
	140342760188560 [label="layer2.1.bn3.weight
 (512)" fillcolor=lightblue]
	140342760188560 -> 140342364396800
	140342364396800 [label=AccumulateGrad]
	140342364396752 -> 140342364396608
	140342760188640 [label="layer2.1.bn3.bias
 (512)" fillcolor=lightblue]
	140342760188640 -> 140342364396752
	140342364396752 [label=AccumulateGrad]
	140342364396368 -> 140342364396560
	140342364396464 -> 140342364396176
	140342760189040 [label="layer2.2.conv1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	140342760189040 -> 140342364396464
	140342364396464 [label=AccumulateGrad]
	140342364396032 -> 140342364396128
	140342760189120 [label="layer2.2.bn1.weight
 (256)" fillcolor=lightblue]
	140342760189120 -> 140342364396032
	140342364396032 [label=AccumulateGrad]
	140342364396272 -> 140342364396128
	140342760189200 [label="layer2.2.bn1.bias
 (256)" fillcolor=lightblue]
	140342760189200 -> 140342364396272
	140342364396272 [label=AccumulateGrad]
	140342364395936 -> 140342364395696
	140342760189680 [label="layer2.2.conv2.weight
 (256, 8, 3, 3)" fillcolor=lightblue]
	140342760189680 -> 140342364395936
	140342364395936 [label=AccumulateGrad]
	140342364395552 -> 140342364395648
	140342760189600 [label="layer2.2.bn2.weight
 (256)" fillcolor=lightblue]
	140342760189600 -> 140342364395552
	140342364395552 [label=AccumulateGrad]
	140342364395792 -> 140342364395648
	140342760189760 [label="layer2.2.bn2.bias
 (256)" fillcolor=lightblue]
	140342760189760 -> 140342364395792
	140342364395792 [label=AccumulateGrad]
	140342364395456 -> 140342364395312
	140342760288560 [label="layer2.2.conv3.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	140342760288560 -> 140342364395456
	140342364395456 [label=AccumulateGrad]
	140342364395264 -> 140342364395072
	140342760288640 [label="layer2.2.bn3.weight
 (512)" fillcolor=lightblue]
	140342760288640 -> 140342364395264
	140342364395264 [label=AccumulateGrad]
	140342364395216 -> 140342364395072
	140342760288720 [label="layer2.2.bn3.bias
 (512)" fillcolor=lightblue]
	140342760288720 -> 140342364395216
	140342364395216 [label=AccumulateGrad]
	140342364394832 -> 140342364395024
	140342364394928 -> 140342364394640
	140342760289120 [label="layer2.3.conv1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	140342760289120 -> 140342364394928
	140342364394928 [label=AccumulateGrad]
	140342364394496 -> 140342364394592
	140342760289200 [label="layer2.3.bn1.weight
 (256)" fillcolor=lightblue]
	140342760289200 -> 140342364394496
	140342364394496 [label=AccumulateGrad]
	140342364394736 -> 140342364394592
	140342760289280 [label="layer2.3.bn1.bias
 (256)" fillcolor=lightblue]
	140342760289280 -> 140342364394736
	140342364394736 [label=AccumulateGrad]
	140342364394400 -> 140342364394160
	140342760289760 [label="layer2.3.conv2.weight
 (256, 8, 3, 3)" fillcolor=lightblue]
	140342760289760 -> 140342364394400
	140342364394400 [label=AccumulateGrad]
	140342364394016 -> 140342364394112
	140342760289680 [label="layer2.3.bn2.weight
 (256)" fillcolor=lightblue]
	140342760289680 -> 140342364394016
	140342364394016 [label=AccumulateGrad]
	140342364394256 -> 140342364394112
	140342760289840 [label="layer2.3.bn2.bias
 (256)" fillcolor=lightblue]
	140342760289840 -> 140342364394256
	140342364394256 [label=AccumulateGrad]
	140342364393920 -> 140342364393776
	140342760290240 [label="layer2.3.conv3.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	140342760290240 -> 140342364393920
	140342364393920 [label=AccumulateGrad]
	140342364393728 -> 140342364393584
	140342760290320 [label="layer2.3.bn3.weight
 (512)" fillcolor=lightblue]
	140342760290320 -> 140342364393728
	140342364393728 [label=AccumulateGrad]
	140342364393680 -> 140342364393584
	140342760290400 [label="layer2.3.bn3.bias
 (512)" fillcolor=lightblue]
	140342760290400 -> 140342364393680
	140342364393680 [label=AccumulateGrad]
	140342364393536 -> 140342364389328
	140342364389136 -> 140342364388896
	140342760291360 [label="layer3.0.conv1.weight
 (512, 512, 1, 1)" fillcolor=lightblue]
	140342760291360 -> 140342364389136
	140342364389136 [label=AccumulateGrad]
	140342364388752 -> 140342364388848
	140342760291440 [label="layer3.0.bn1.weight
 (512)" fillcolor=lightblue]
	140342760291440 -> 140342364388752
	140342364388752 [label=AccumulateGrad]
	140342364388992 -> 140342364388848
	140342760291520 [label="layer3.0.bn1.bias
 (512)" fillcolor=lightblue]
	140342760291520 -> 140342364388992
	140342364388992 [label=AccumulateGrad]
	140342364388656 -> 140342364388416
	140342760292000 [label="layer3.0.conv2.weight
 (512, 16, 3, 3)" fillcolor=lightblue]
	140342760292000 -> 140342364388656
	140342364388656 [label=AccumulateGrad]
	140342364388272 -> 140342364388368
	140342760291920 [label="layer3.0.bn2.weight
 (512)" fillcolor=lightblue]
	140342760291920 -> 140342364388272
	140342364388272 [label=AccumulateGrad]
	140342364388512 -> 140342364388368
	140342760292080 [label="layer3.0.bn2.bias
 (512)" fillcolor=lightblue]
	140342760292080 -> 140342364388512
	140342364388512 [label=AccumulateGrad]
	140342364388176 -> 140342364388032
	140342238703840 [label="layer3.0.conv3.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	140342238703840 -> 140342364388176
	140342364388176 [label=AccumulateGrad]
	140342364387984 -> 140342364387792
	140342238703920 [label="layer3.0.bn3.weight
 (1024)" fillcolor=lightblue]
	140342238703920 -> 140342364387984
	140342364387984 [label=AccumulateGrad]
	140342364387936 -> 140342364387792
	140342238704000 [label="layer3.0.bn3.bias
 (1024)" fillcolor=lightblue]
	140342238704000 -> 140342364387936
	140342364387936 [label=AccumulateGrad]
	140342364387552 -> 140342364387744
	140342364387552 [label=NativeBatchNormBackward0]
	140342364388608 -> 140342364387552
	140342364388608 [label=ConvolutionBackward0]
	140342364389184 -> 140342364388608
	140342364389040 -> 140342364388608
	140342760290800 [label="layer3.0.downsample.0.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	140342760290800 -> 140342364389040
	140342364389040 [label=AccumulateGrad]
	140342364388128 -> 140342364387552
	140342760290880 [label="layer3.0.downsample.1.weight
 (1024)" fillcolor=lightblue]
	140342760290880 -> 140342364388128
	140342364388128 [label=AccumulateGrad]
	140342364388080 -> 140342364387552
	140342760290960 [label="layer3.0.downsample.1.bias
 (1024)" fillcolor=lightblue]
	140342760290960 -> 140342364388080
	140342364388080 [label=AccumulateGrad]
	140342364387648 -> 140342364387360
	140342238704400 [label="layer3.1.conv1.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	140342238704400 -> 140342364387648
	140342364387648 [label=AccumulateGrad]
	140342364387216 -> 140342364387312
	140342238704480 [label="layer3.1.bn1.weight
 (512)" fillcolor=lightblue]
	140342238704480 -> 140342364387216
	140342364387216 [label=AccumulateGrad]
	140342364387456 -> 140342364387312
	140342238704560 [label="layer3.1.bn1.bias
 (512)" fillcolor=lightblue]
	140342238704560 -> 140342364387456
	140342364387456 [label=AccumulateGrad]
	140342364387120 -> 140342364386880
	140342238705040 [label="layer3.1.conv2.weight
 (512, 16, 3, 3)" fillcolor=lightblue]
	140342238705040 -> 140342364387120
	140342364387120 [label=AccumulateGrad]
	140342364386736 -> 140342364386832
	140342238704960 [label="layer3.1.bn2.weight
 (512)" fillcolor=lightblue]
	140342238704960 -> 140342364386736
	140342364386736 [label=AccumulateGrad]
	140342364386976 -> 140342364386832
	140342238705120 [label="layer3.1.bn2.bias
 (512)" fillcolor=lightblue]
	140342238705120 -> 140342364386976
	140342364386976 [label=AccumulateGrad]
	140342364386640 -> 140342364386496
	140342238705520 [label="layer3.1.conv3.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	140342238705520 -> 140342364386640
	140342364386640 [label=AccumulateGrad]
	140342364386448 -> 140342364386256
	140342238705600 [label="layer3.1.bn3.weight
 (1024)" fillcolor=lightblue]
	140342238705600 -> 140342364386448
	140342364386448 [label=AccumulateGrad]
	140342364386400 -> 140342364386256
	140342238705680 [label="layer3.1.bn3.bias
 (1024)" fillcolor=lightblue]
	140342238705680 -> 140342364386400
	140342364386400 [label=AccumulateGrad]
	140342364386016 -> 140342364386208
	140342364386112 -> 140342364385824
	140342238706080 [label="layer3.2.conv1.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	140342238706080 -> 140342364386112
	140342364386112 [label=AccumulateGrad]
	140342364385680 -> 140342364385776
	140342238706160 [label="layer3.2.bn1.weight
 (512)" fillcolor=lightblue]
	140342238706160 -> 140342364385680
	140342364385680 [label=AccumulateGrad]
	140342364385920 -> 140342364385776
	140342238706240 [label="layer3.2.bn1.bias
 (512)" fillcolor=lightblue]
	140342238706240 -> 140342364385920
	140342364385920 [label=AccumulateGrad]
	140342364385584 -> 140342364385392
	140342238706720 [label="layer3.2.conv2.weight
 (512, 16, 3, 3)" fillcolor=lightblue]
	140342238706720 -> 140342364385584
	140342364385584 [label=AccumulateGrad]
	140342364385344 -> 140342364368848
	140342238706640 [label="layer3.2.bn2.weight
 (512)" fillcolor=lightblue]
	140342238706640 -> 140342364385344
	140342364385344 [label=AccumulateGrad]
	140342364385440 -> 140342364368848
	140342238706800 [label="layer3.2.bn2.bias
 (512)" fillcolor=lightblue]
	140342238706800 -> 140342364385440
	140342364385440 [label=AccumulateGrad]
	140342364368656 -> 140342364368512
	140342238707200 [label="layer3.2.conv3.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	140342238707200 -> 140342364368656
	140342364368656 [label=AccumulateGrad]
	140342364368464 -> 140342364368272
	140342238707280 [label="layer3.2.bn3.weight
 (1024)" fillcolor=lightblue]
	140342238707280 -> 140342364368464
	140342364368464 [label=AccumulateGrad]
	140342364368416 -> 140342364368272
	140342238707360 [label="layer3.2.bn3.bias
 (1024)" fillcolor=lightblue]
	140342238707360 -> 140342364368416
	140342364368416 [label=AccumulateGrad]
	140342364368032 -> 140342364368224
	140342364368128 -> 140342364367840
	140342238814352 [label="layer3.3.conv1.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	140342238814352 -> 140342364368128
	140342364368128 [label=AccumulateGrad]
	140342364367696 -> 140342364367792
	140342238814432 [label="layer3.3.bn1.weight
 (512)" fillcolor=lightblue]
	140342238814432 -> 140342364367696
	140342364367696 [label=AccumulateGrad]
	140342364367936 -> 140342364367792
	140342238814512 [label="layer3.3.bn1.bias
 (512)" fillcolor=lightblue]
	140342238814512 -> 140342364367936
	140342364367936 [label=AccumulateGrad]
	140342364367600 -> 140342364367360
	140342238814992 [label="layer3.3.conv2.weight
 (512, 16, 3, 3)" fillcolor=lightblue]
	140342238814992 -> 140342364367600
	140342364367600 [label=AccumulateGrad]
	140342364367216 -> 140342364367312
	140342238814912 [label="layer3.3.bn2.weight
 (512)" fillcolor=lightblue]
	140342238814912 -> 140342364367216
	140342364367216 [label=AccumulateGrad]
	140342364367456 -> 140342364367312
	140342238815072 [label="layer3.3.bn2.bias
 (512)" fillcolor=lightblue]
	140342238815072 -> 140342364367456
	140342364367456 [label=AccumulateGrad]
	140342364367120 -> 140342364366976
	140342238815472 [label="layer3.3.conv3.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	140342238815472 -> 140342364367120
	140342364367120 [label=AccumulateGrad]
	140342364366928 -> 140342364366736
	140342238815552 [label="layer3.3.bn3.weight
 (1024)" fillcolor=lightblue]
	140342238815552 -> 140342364366928
	140342364366928 [label=AccumulateGrad]
	140342364366880 -> 140342364366736
	140342238815632 [label="layer3.3.bn3.bias
 (1024)" fillcolor=lightblue]
	140342238815632 -> 140342364366880
	140342364366880 [label=AccumulateGrad]
	140342364366496 -> 140342364366688
	140342364366592 -> 140342364366304
	140342238816032 [label="layer3.4.conv1.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	140342238816032 -> 140342364366592
	140342364366592 [label=AccumulateGrad]
	140342364366160 -> 140342364366256
	140342238816112 [label="layer3.4.bn1.weight
 (512)" fillcolor=lightblue]
	140342238816112 -> 140342364366160
	140342364366160 [label=AccumulateGrad]
	140342364366400 -> 140342364366256
	140342238816192 [label="layer3.4.bn1.bias
 (512)" fillcolor=lightblue]
	140342238816192 -> 140342364366400
	140342364366400 [label=AccumulateGrad]
	140342364366064 -> 140342364365824
	140342238816672 [label="layer3.4.conv2.weight
 (512, 16, 3, 3)" fillcolor=lightblue]
	140342238816672 -> 140342364366064
	140342364366064 [label=AccumulateGrad]
	140342364365680 -> 140342364365776
	140342238816592 [label="layer3.4.bn2.weight
 (512)" fillcolor=lightblue]
	140342238816592 -> 140342364365680
	140342364365680 [label=AccumulateGrad]
	140342364365920 -> 140342364365776
	140342238816752 [label="layer3.4.bn2.bias
 (512)" fillcolor=lightblue]
	140342238816752 -> 140342364365920
	140342364365920 [label=AccumulateGrad]
	140342364365584 -> 140342364365440
	140342238817152 [label="layer3.4.conv3.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	140342238817152 -> 140342364365584
	140342364365584 [label=AccumulateGrad]
	140342364365392 -> 140342364365200
	140342238817232 [label="layer3.4.bn3.weight
 (1024)" fillcolor=lightblue]
	140342238817232 -> 140342364365392
	140342364365392 [label=AccumulateGrad]
	140342364365344 -> 140342364365200
	140342238817312 [label="layer3.4.bn3.bias
 (1024)" fillcolor=lightblue]
	140342238817312 -> 140342364365344
	140342364365344 [label=AccumulateGrad]
	140342364364960 -> 140342364365152
	140342364365056 -> 140342364286880
	140342238817712 [label="layer3.5.conv1.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	140342238817712 -> 140342364365056
	140342364365056 [label=AccumulateGrad]
	140342364286736 -> 140342364286832
	140342238817792 [label="layer3.5.bn1.weight
 (512)" fillcolor=lightblue]
	140342238817792 -> 140342364286736
	140342364286736 [label=AccumulateGrad]
	140342364364864 -> 140342364286832
	140342238817872 [label="layer3.5.bn1.bias
 (512)" fillcolor=lightblue]
	140342238817872 -> 140342364364864
	140342364364864 [label=AccumulateGrad]
	140342364286640 -> 140342364286400
	140342895976592 [label="layer3.5.conv2.weight
 (512, 16, 3, 3)" fillcolor=lightblue]
	140342895976592 -> 140342364286640
	140342364286640 [label=AccumulateGrad]
	140342364286256 -> 140342364286352
	140342895976512 [label="layer3.5.bn2.weight
 (512)" fillcolor=lightblue]
	140342895976512 -> 140342364286256
	140342364286256 [label=AccumulateGrad]
	140342364286496 -> 140342364286352
	140342895976672 [label="layer3.5.bn2.bias
 (512)" fillcolor=lightblue]
	140342895976672 -> 140342364286496
	140342364286496 [label=AccumulateGrad]
	140342364286160 -> 140342364286016
	140342895977072 [label="layer3.5.conv3.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	140342895977072 -> 140342364286160
	140342364286160 [label=AccumulateGrad]
	140342364285968 -> 140342364285776
	140342895977152 [label="layer3.5.bn3.weight
 (1024)" fillcolor=lightblue]
	140342895977152 -> 140342364285968
	140342364285968 [label=AccumulateGrad]
	140342364285920 -> 140342364285776
	140342895977232 [label="layer3.5.bn3.bias
 (1024)" fillcolor=lightblue]
	140342895977232 -> 140342364285920
	140342364285920 [label=AccumulateGrad]
	140342364285632 -> 140342364285728
	140342364285536 -> 140342364285296
	140342895978192 [label="layer4.0.conv1.weight
 (1024, 1024, 1, 1)" fillcolor=lightblue]
	140342895978192 -> 140342364285536
	140342364285536 [label=AccumulateGrad]
	140342364285152 -> 140342364285248
	140342895978272 [label="layer4.0.bn1.weight
 (1024)" fillcolor=lightblue]
	140342895978272 -> 140342364285152
	140342364285152 [label=AccumulateGrad]
	140342364285392 -> 140342364285248
	140342895978352 [label="layer4.0.bn1.bias
 (1024)" fillcolor=lightblue]
	140342895978352 -> 140342364285392
	140342364285392 [label=AccumulateGrad]
	140342364285056 -> 140342364284816
	140342895978832 [label="layer4.0.conv2.weight
 (1024, 32, 3, 3)" fillcolor=lightblue]
	140342895978832 -> 140342364285056
	140342364285056 [label=AccumulateGrad]
	140342364284672 -> 140342364284768
	140342895978752 [label="layer4.0.bn2.weight
 (1024)" fillcolor=lightblue]
	140342895978752 -> 140342364284672
	140342364284672 [label=AccumulateGrad]
	140342364284912 -> 140342364284768
	140342895978912 [label="layer4.0.bn2.bias
 (1024)" fillcolor=lightblue]
	140342895978912 -> 140342364284912
	140342364284912 [label=AccumulateGrad]
	140342364284576 -> 140342364284432
	140342895979312 [label="layer4.0.conv3.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	140342895979312 -> 140342364284576
	140342364284576 [label=AccumulateGrad]
	140342364284384 -> 140342364284192
	140342895979392 [label="layer4.0.bn3.weight
 (2048)" fillcolor=lightblue]
	140342895979392 -> 140342364284384
	140342364284384 [label=AccumulateGrad]
	140342364284336 -> 140342364284192
	140342895979472 [label="layer4.0.bn3.bias
 (2048)" fillcolor=lightblue]
	140342895979472 -> 140342364284336
	140342364284336 [label=AccumulateGrad]
	140342364283952 -> 140342364284144
	140342364283952 [label=NativeBatchNormBackward0]
	140342364285008 -> 140342364283952
	140342364285008 [label=ConvolutionBackward0]
	140342364285584 -> 140342364285008
	140342364285440 -> 140342364285008
	140342895977632 [label="layer4.0.downsample.0.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	140342895977632 -> 140342364285440
	140342364285440 [label=AccumulateGrad]
	140342364284528 -> 140342364283952
	140342895977712 [label="layer4.0.downsample.1.weight
 (2048)" fillcolor=lightblue]
	140342895977712 -> 140342364284528
	140342364284528 [label=AccumulateGrad]
	140342364284480 -> 140342364283952
	140342895977792 [label="layer4.0.downsample.1.bias
 (2048)" fillcolor=lightblue]
	140342895977792 -> 140342364284480
	140342364284480 [label=AccumulateGrad]
	140342364284048 -> 140342364283760
	140342895979872 [label="layer4.1.conv1.weight
 (1024, 2048, 1, 1)" fillcolor=lightblue]
	140342895979872 -> 140342364284048
	140342364284048 [label=AccumulateGrad]
	140342364283616 -> 140342364283712
	140342895979952 [label="layer4.1.bn1.weight
 (1024)" fillcolor=lightblue]
	140342895979952 -> 140342364283616
	140342364283616 [label=AccumulateGrad]
	140342364283856 -> 140342364283712
	140342895980032 [label="layer4.1.bn1.bias
 (1024)" fillcolor=lightblue]
	140342895980032 -> 140342364283856
	140342364283856 [label=AccumulateGrad]
	140342364283520 -> 140342364283280
	140342896078912 [label="layer4.1.conv2.weight
 (1024, 32, 3, 3)" fillcolor=lightblue]
	140342896078912 -> 140342364283520
	140342364283520 [label=AccumulateGrad]
	140342364283136 -> 140342364283232
	140342895980432 [label="layer4.1.bn2.weight
 (1024)" fillcolor=lightblue]
	140342895980432 -> 140342364283136
	140342364283136 [label=AccumulateGrad]
	140342364283376 -> 140342364283232
	140342896078992 [label="layer4.1.bn2.bias
 (1024)" fillcolor=lightblue]
	140342896078992 -> 140342364283376
	140342364283376 [label=AccumulateGrad]
	140342364283040 -> 140342907232208
	140342896079392 [label="layer4.1.conv3.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	140342896079392 -> 140342364283040
	140342364283040 [label=AccumulateGrad]
	140342907232160 -> 140342907232064
	140342896079472 [label="layer4.1.bn3.weight
 (2048)" fillcolor=lightblue]
	140342896079472 -> 140342907232160
	140342907232160 [label=AccumulateGrad]
	140342907232112 -> 140342907232064
	140342896079552 [label="layer4.1.bn3.bias
 (2048)" fillcolor=lightblue]
	140342896079552 -> 140342907232112
	140342907232112 [label=AccumulateGrad]
	140342907231920 -> 140342907231872
	140342907231968 -> 140342907231824
	140342896079952 [label="layer4.2.conv1.weight
 (1024, 2048, 1, 1)" fillcolor=lightblue]
	140342896079952 -> 140342907231968
	140342907231968 [label=AccumulateGrad]
	140342907231728 -> 140342907230768
	140342896080032 [label="layer4.2.bn1.weight
 (1024)" fillcolor=lightblue]
	140342896080032 -> 140342907231728
	140342907231728 [label=AccumulateGrad]
	140342907231200 -> 140342907230768
	140342896080112 [label="layer4.2.bn1.bias
 (1024)" fillcolor=lightblue]
	140342896080112 -> 140342907231200
	140342907231200 [label=AccumulateGrad]
	140342907231392 -> 140342907231056
	140342896080592 [label="layer4.2.conv2.weight
 (1024, 32, 3, 3)" fillcolor=lightblue]
	140342896080592 -> 140342907231392
	140342907231392 [label=AccumulateGrad]
	140342907231008 -> 140342907231152
	140342896080512 [label="layer4.2.bn2.weight
 (1024)" fillcolor=lightblue]
	140342896080512 -> 140342907231008
	140342907231008 [label=AccumulateGrad]
	140342907230960 -> 140342907231152
	140342896080672 [label="layer4.2.bn2.bias
 (1024)" fillcolor=lightblue]
	140342896080672 -> 140342907230960
	140342907230960 [label=AccumulateGrad]
	140342907231488 -> 140342896132976
	140342896081072 [label="layer4.2.conv3.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	140342896081072 -> 140342907231488
	140342907231488 [label=AccumulateGrad]
	140342896133072 -> 140342896133264
	140342896081152 [label="layer4.2.bn3.weight
 (2048)" fillcolor=lightblue]
	140342896081152 -> 140342896133072
	140342896133072 [label=AccumulateGrad]
	140342896135664 -> 140342896133264
	140342896081232 [label="layer4.2.bn3.bias
 (2048)" fillcolor=lightblue]
	140342896081232 -> 140342896135664
	140342896135664 [label=AccumulateGrad]
	140342896134224 -> 140342896133312
	140342896134032 -> 140342896134080
	140342896134032 [label=TBackward0]
	140342896134128 -> 140342896134032
	140342896081552 [label="fc.weight
 (1000, 2048)" fillcolor=lightblue]
	140342896081552 -> 140342896134128
	140342896134128 [label=AccumulateGrad]
	140342907117920 -> 140342364274416
}
