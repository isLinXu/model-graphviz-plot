digraph {
	graph [size="112.05,112.05"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140302512260736 [label="
 (1, 1000)" fillcolor=darkolivegreen1]
	140301470932272 [label=ReshapeAliasBackward0]
	140301470932368 -> 140301470932272
	140301470932368 [label=ConvolutionBackward0]
	140301470931072 -> 140301470932368
	140301470931072 [label=MeanBackward1]
	140302512096448 -> 140301470931072
	140302512096448 [label=ReluBackward0]
	140302512096592 -> 140302512096448
	140302512096592 [label=NativeBatchNormBackward0]
	140302512096304 -> 140302512096592
	140302512096304 [label=ConvolutionBackward0]
	140302512096784 -> 140302512096304
	140302512096784 [label=CatBackward0]
	140302512096688 -> 140302512096784
	140302512096688 [label=ReluBackward0]
	140302512096736 -> 140302512096688
	140302512096736 [label=AddBackward0]
	140302512097024 -> 140302512096736
	140302512097024 [label=NativeBatchNormBackward0]
	140302512097120 -> 140302512097024
	140302512097120 [label=ConvolutionBackward0]
	140302512097312 -> 140302512097120
	140302512097312 [label=ReluBackward0]
	140302512097456 -> 140302512097312
	140302512097456 [label=NativeBatchNormBackward0]
	140302512097552 -> 140302512097456
	140302512097552 [label=ConvolutionBackward0]
	140302512095968 -> 140302512097552
	140302512095968 [label=ReluBackward0]
	140302512097840 -> 140302512095968
	140302512097840 [label=AddBackward0]
	140302512097936 -> 140302512097840
	140302512097936 [label=NativeBatchNormBackward0]
	140302512098080 -> 140302512097936
	140302512098080 [label=ConvolutionBackward0]
	140302512098272 -> 140302512098080
	140302512098272 [label=ReluBackward0]
	140302512098416 -> 140302512098272
	140302512098416 [label=NativeBatchNormBackward0]
	140302512098512 -> 140302512098416
	140302512098512 [label=ConvolutionBackward0]
	140302512098704 -> 140302512098512
	140302512098704 [label=ReluBackward0]
	140302512098848 -> 140302512098704
	140302512098848 [label=NativeBatchNormBackward0]
	140302512098944 -> 140302512098848
	140302512098944 [label=ConvolutionBackward0]
	140302512099136 -> 140302512098944
	140302512099136 [label=CatBackward0]
	140302512099280 -> 140302512099136
	140302512099280 [label=ReluBackward0]
	140301476987136 -> 140302512099280
	140301476987136 [label=AddBackward0]
	140301476987232 -> 140301476987136
	140301476987232 [label=NativeBatchNormBackward0]
	140301476987328 -> 140301476987232
	140301476987328 [label=ConvolutionBackward0]
	140301476987520 -> 140301476987328
	140301476987520 [label=ReluBackward0]
	140301476987664 -> 140301476987520
	140301476987664 [label=NativeBatchNormBackward0]
	140301476987760 -> 140301476987664
	140301476987760 [label=ConvolutionBackward0]
	140302512099232 -> 140301476987760
	140302512099232 [label=ReluBackward0]
	140301476988048 -> 140302512099232
	140301476988048 [label=AddBackward0]
	140301476988144 -> 140301476988048
	140301476988144 [label=NativeBatchNormBackward0]
	140301476988240 -> 140301476988144
	140301476988240 [label=ConvolutionBackward0]
	140301476988432 -> 140301476988240
	140301476988432 [label=ReluBackward0]
	140301476988576 -> 140301476988432
	140301476988576 [label=NativeBatchNormBackward0]
	140301476988672 -> 140301476988576
	140301476988672 [label=ConvolutionBackward0]
	140301476986944 -> 140301476988672
	140301476986944 [label=ReluBackward0]
	140301476988960 -> 140301476986944
	140301476988960 [label=NativeBatchNormBackward0]
	140301476989056 -> 140301476988960
	140301476989056 [label=ConvolutionBackward0]
	140301476989248 -> 140301476989056
	140301476989248 [label=CatBackward0]
	140301476989392 -> 140301476989248
	140301476989392 [label=ReluBackward0]
	140301476989536 -> 140301476989392
	140301476989536 [label=AddBackward0]
	140301476989632 -> 140301476989536
	140301476989632 [label=NativeBatchNormBackward0]
	140301476989728 -> 140301476989632
	140301476989728 [label=ConvolutionBackward0]
	140301476989920 -> 140301476989728
	140301476989920 [label=ReluBackward0]
	140301476990064 -> 140301476989920
	140301476990064 [label=NativeBatchNormBackward0]
	140301476990160 -> 140301476990064
	140301476990160 [label=ConvolutionBackward0]
	140301476989344 -> 140301476990160
	140301476989344 [label=ReluBackward0]
	140301476990448 -> 140301476989344
	140301476990448 [label=AddBackward0]
	140301476990544 -> 140301476990448
	140301476990544 [label=NativeBatchNormBackward0]
	140301476990688 -> 140301476990544
	140301476990688 [label=ConvolutionBackward0]
	140301476990880 -> 140301476990688
	140301476990880 [label=ReluBackward0]
	140301476990928 -> 140301476990880
	140301476990928 [label=NativeBatchNormBackward0]
	140301477003472 -> 140301476990928
	140301477003472 [label=ConvolutionBackward0]
	140301477003664 -> 140301477003472
	140301477003664 [label=ReluBackward0]
	140301477003808 -> 140301477003664
	140301477003808 [label=NativeBatchNormBackward0]
	140301477003856 -> 140301477003808
	140301477003856 [label=ConvolutionBackward0]
	140301477004144 -> 140301477003856
	140301477004144 [label=CatBackward0]
	140301477004288 -> 140301477004144
	140301477004288 [label=ReluBackward0]
	140301477004528 -> 140301477004288
	140301477004528 [label=AddBackward0]
	140301477004576 -> 140301477004528
	140301477004576 [label=NativeBatchNormBackward0]
	140301477004768 -> 140301477004576
	140301477004768 [label=ConvolutionBackward0]
	140301477004960 -> 140301477004768
	140301477004960 [label=ReluBackward0]
	140301477005104 -> 140301477004960
	140301477005104 [label=NativeBatchNormBackward0]
	140301477005152 -> 140301477005104
	140301477005152 [label=ConvolutionBackward0]
	140301477004240 -> 140301477005152
	140301477004240 [label=ReluBackward0]
	140301477005536 -> 140301477004240
	140301477005536 [label=AddBackward0]
	140301477005584 -> 140301477005536
	140301477005584 [label=NativeBatchNormBackward0]
	140301477005776 -> 140301477005584
	140301477005776 [label=ConvolutionBackward0]
	140301477005968 -> 140301477005776
	140301477005968 [label=ReluBackward0]
	140301477006112 -> 140301477005968
	140301477006112 [label=NativeBatchNormBackward0]
	140301477006160 -> 140301477006112
	140301477006160 [label=ConvolutionBackward0]
	140301477004336 -> 140301477006160
	140301477004336 [label=ReluBackward0]
	140301477006544 -> 140301477004336
	140301477006544 [label=NativeBatchNormBackward0]
	140301477006592 -> 140301477006544
	140301477006592 [label=ConvolutionBackward0]
	140301477006880 -> 140301477006592
	140301477006880 [label=CatBackward0]
	140301477007024 -> 140301477006880
	140301477007024 [label=ReluBackward0]
	140301477007168 -> 140301477007024
	140301477007168 [label=AddBackward0]
	140301477007216 -> 140301477007168
	140301477007216 [label=NativeBatchNormBackward0]
	140301477007312 -> 140301477007216
	140301477007312 [label=ConvolutionBackward0]
	140301477015856 -> 140301477007312
	140301477015856 [label=ReluBackward0]
	140301477016000 -> 140301477015856
	140301477016000 [label=NativeBatchNormBackward0]
	140301477016048 -> 140301477016000
	140301477016048 [label=ConvolutionBackward0]
	140301477006976 -> 140301477016048
	140301477006976 [label=ReluBackward0]
	140301477016432 -> 140301477006976
	140301477016432 [label=AddBackward0]
	140301477016480 -> 140301477016432
	140301477016480 [label=NativeBatchNormBackward0]
	140301477016720 -> 140301477016480
	140301477016720 [label=ConvolutionBackward0]
	140301477016912 -> 140301477016720
	140301477016912 [label=ReluBackward0]
	140301477017056 -> 140301477016912
	140301477017056 [label=NativeBatchNormBackward0]
	140301477017104 -> 140301477017056
	140301477017104 [label=ConvolutionBackward0]
	140301477017392 -> 140301477017104
	140301477017392 [label=ReluBackward0]
	140301477017536 -> 140301477017392
	140301477017536 [label=NativeBatchNormBackward0]
	140301477017584 -> 140301477017536
	140301477017584 [label=ConvolutionBackward0]
	140301477017872 -> 140301477017584
	140301477017872 [label=CatBackward0]
	140301477018016 -> 140301477017872
	140301477018016 [label=ReluBackward0]
	140301477018160 -> 140301477018016
	140301477018160 [label=AddBackward0]
	140301477018208 -> 140301477018160
	140301477018208 [label=NativeBatchNormBackward0]
	140301477018400 -> 140301477018208
	140301477018400 [label=ConvolutionBackward0]
	140301477018592 -> 140301477018400
	140301477018592 [label=ReluBackward0]
	140301477018736 -> 140301477018592
	140301477018736 [label=NativeBatchNormBackward0]
	140301477018784 -> 140301477018736
	140301477018784 [label=ConvolutionBackward0]
	140301477017968 -> 140301477018784
	140301477017968 [label=ReluBackward0]
	140301477019168 -> 140301477017968
	140301477019168 [label=AddBackward0]
	140301477019216 -> 140301477019168
	140301477019216 [label=NativeBatchNormBackward0]
	140301477019456 -> 140301477019216
	140301477019456 [label=ConvolutionBackward0]
	140301477019600 -> 140301477019456
	140301477019600 [label=ReluBackward0]
	140301477028048 -> 140301477019600
	140301477028048 [label=NativeBatchNormBackward0]
	140301477028096 -> 140301477028048
	140301477028096 [label=ConvolutionBackward0]
	140301477028384 -> 140301477028096
	140301477028384 [label=ReluBackward0]
	140301477028528 -> 140301477028384
	140301477028528 [label=NativeBatchNormBackward0]
	140301477028576 -> 140301477028528
	140301477028576 [label=ConvolutionBackward0]
	140301477028864 -> 140301477028576
	140301477028864 [label=ReluBackward0]
	140301477029008 -> 140301477028864
	140301477029008 [label=NativeBatchNormBackward0]
	140301477029056 -> 140301477029008
	140301477029056 [label=ConvolutionBackward0]
	140301477029344 -> 140301477029056
	140301477029344 [label=ReluBackward0]
	140301477029488 -> 140301477029344
	140301477029488 [label=NativeBatchNormBackward0]
	140301477029536 -> 140301477029488
	140301477029536 [label=ConvolutionBackward0]
	140301477029824 -> 140301477029536
	140301468762976 [label="base_layer.0.weight
 (16, 3, 7, 7)" fillcolor=lightblue]
	140301468762976 -> 140301477029824
	140301477029824 [label=AccumulateGrad]
	140301477029392 -> 140301477029488
	140301468763056 [label="base_layer.1.weight
 (16)" fillcolor=lightblue]
	140301468763056 -> 140301477029392
	140301477029392 [label=AccumulateGrad]
	140301477029632 -> 140301477029488
	140301468763136 [label="base_layer.1.bias
 (16)" fillcolor=lightblue]
	140301468763136 -> 140301477029632
	140301477029632 [label=AccumulateGrad]
	140301477029296 -> 140301477029056
	140301468763696 [label="level0.0.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140301468763696 -> 140301477029296
	140301477029296 [label=AccumulateGrad]
	140301477028912 -> 140301477029008
	140301468763776 [label="level0.1.weight
 (16)" fillcolor=lightblue]
	140301468763776 -> 140301477028912
	140301477028912 [label=AccumulateGrad]
	140301477029152 -> 140301477029008
	140301468763856 [label="level0.1.bias
 (16)" fillcolor=lightblue]
	140301468763856 -> 140301477029152
	140301477029152 [label=AccumulateGrad]
	140301477028816 -> 140301477028576
	140301468764256 [label="level1.0.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140301468764256 -> 140301477028816
	140301477028816 [label=AccumulateGrad]
	140301477028432 -> 140301477028528
	140301468764336 [label="level1.1.weight
 (32)" fillcolor=lightblue]
	140301468764336 -> 140301477028432
	140301477028432 [label=AccumulateGrad]
	140301477028672 -> 140301477028528
	140301468764416 [label="level1.1.bias
 (32)" fillcolor=lightblue]
	140301468764416 -> 140301477028672
	140301477028672 [label=AccumulateGrad]
	140301477028336 -> 140301477028096
	140301468764896 [label="level2.tree1.conv1.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140301468764896 -> 140301477028336
	140301477028336 [label=AccumulateGrad]
	140301477027952 -> 140301477028048
	140301468764976 [label="level2.tree1.bn1.weight
 (64)" fillcolor=lightblue]
	140301468764976 -> 140301477027952
	140301477027952 [label=AccumulateGrad]
	140301477028192 -> 140301477028048
	140301468765056 [label="level2.tree1.bn1.bias
 (64)" fillcolor=lightblue]
	140301468765056 -> 140301477028192
	140301477028192 [label=AccumulateGrad]
	140301477019552 -> 140301477019456
	140301468765456 [label="level2.tree1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140301468765456 -> 140301477019552
	140301477019552 [label=AccumulateGrad]
	140301477019408 -> 140301477019216
	140301468765536 [label="level2.tree1.bn2.weight
 (64)" fillcolor=lightblue]
	140301468765536 -> 140301477019408
	140301477019408 [label=AccumulateGrad]
	140301477019360 -> 140301477019216
	140301468765616 [label="level2.tree1.bn2.bias
 (64)" fillcolor=lightblue]
	140301468765616 -> 140301477019360
	140301477019360 [label=AccumulateGrad]
	140301477018976 -> 140301477019168
	140301477018976 [label=NativeBatchNormBackward0]
	140301477019504 -> 140301477018976
	140301477019504 [label=ConvolutionBackward0]
	140301477028720 -> 140301477019504
	140301477028720 [label=MaxPool2DWithIndicesBackward0]
	140301477028384 -> 140301477028720
	140301477028768 -> 140301477019504
	140301969458176 [label="level2.project.0.weight
 (64, 32, 1, 1)" fillcolor=lightblue]
	140301969458176 -> 140301477028768
	140301477028768 [label=AccumulateGrad]
	140301477028288 -> 140301477018976
	140301969458256 [label="level2.project.1.weight
 (64)" fillcolor=lightblue]
	140301969458256 -> 140301477028288
	140301477028288 [label=AccumulateGrad]
	140301477027904 -> 140301477018976
	140301969458336 [label="level2.project.1.bias
 (64)" fillcolor=lightblue]
	140301969458336 -> 140301477027904
	140301477027904 [label=AccumulateGrad]
	140301477019072 -> 140301477018784
	140301468766016 [label="level2.tree2.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140301468766016 -> 140301477019072
	140301477019072 [label=AccumulateGrad]
	140301477018640 -> 140301477018736
	140301468766096 [label="level2.tree2.bn1.weight
 (64)" fillcolor=lightblue]
	140301468766096 -> 140301477018640
	140301477018640 [label=AccumulateGrad]
	140301477018880 -> 140301477018736
	140301969457216 [label="level2.tree2.bn1.bias
 (64)" fillcolor=lightblue]
	140301969457216 -> 140301477018880
	140301477018880 [label=AccumulateGrad]
	140301477018544 -> 140301477018400
	140301969457616 [label="level2.tree2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140301969457616 -> 140301477018544
	140301477018544 [label=AccumulateGrad]
	140301477018352 -> 140301477018208
	140301969457696 [label="level2.tree2.bn2.weight
 (64)" fillcolor=lightblue]
	140301969457696 -> 140301477018352
	140301477018352 [label=AccumulateGrad]
	140301477018304 -> 140301477018208
	140301969457776 [label="level2.tree2.bn2.bias
 (64)" fillcolor=lightblue]
	140301969457776 -> 140301477018304
	140301477018304 [label=AccumulateGrad]
	140301477017968 -> 140301477018160
	140301477017968 -> 140301477017872
	140301477017824 -> 140301477017584
	140301969458736 [label="level2.root.conv.weight
 (64, 128, 1, 1)" fillcolor=lightblue]
	140301969458736 -> 140301477017824
	140301477017824 [label=AccumulateGrad]
	140301477017440 -> 140301477017536
	140301969458816 [label="level2.root.bn.weight
 (64)" fillcolor=lightblue]
	140301969458816 -> 140301477017440
	140301477017440 [label=AccumulateGrad]
	140301477017680 -> 140301477017536
	140301969458896 [label="level2.root.bn.bias
 (64)" fillcolor=lightblue]
	140301969458896 -> 140301477017680
	140301477017680 [label=AccumulateGrad]
	140301477017344 -> 140301477017104
	140301969459376 [label="level3.tree1.tree1.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	140301969459376 -> 140301477017344
	140301477017344 [label=AccumulateGrad]
	140301477016960 -> 140301477017056
	140301969459456 [label="level3.tree1.tree1.bn1.weight
 (128)" fillcolor=lightblue]
	140301969459456 -> 140301477016960
	140301477016960 [label=AccumulateGrad]
	140301477017200 -> 140301477017056
	140301969459536 [label="level3.tree1.tree1.bn1.bias
 (128)" fillcolor=lightblue]
	140301969459536 -> 140301477017200
	140301477017200 [label=AccumulateGrad]
	140301477016864 -> 140301477016720
	140301969459936 [label="level3.tree1.tree1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140301969459936 -> 140301477016864
	140301477016864 [label=AccumulateGrad]
	140301477016672 -> 140301477016480
	140301969460016 [label="level3.tree1.tree1.bn2.weight
 (128)" fillcolor=lightblue]
	140301969460016 -> 140301477016672
	140301477016672 [label=AccumulateGrad]
	140301477016624 -> 140301477016480
	140301969460096 [label="level3.tree1.tree1.bn2.bias
 (128)" fillcolor=lightblue]
	140301969460096 -> 140301477016624
	140301477016624 [label=AccumulateGrad]
	140301477016240 -> 140301477016432
	140301477016240 [label=NativeBatchNormBackward0]
	140301477017296 -> 140301477016240
	140301477017296 [label=ConvolutionBackward0]
	140301477017728 -> 140301477017296
	140301477017728 [label=MaxPool2DWithIndicesBackward0]
	140301477017392 -> 140301477017728
	140301477017776 -> 140301477017296
	140301969564112 [label="level3.tree1.project.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	140301969564112 -> 140301477017776
	140301477017776 [label=AccumulateGrad]
	140301477016816 -> 140301477016240
	140301969564192 [label="level3.tree1.project.1.weight
 (128)" fillcolor=lightblue]
	140301969564192 -> 140301477016816
	140301477016816 [label=AccumulateGrad]
	140301477016768 -> 140301477016240
	140301969564272 [label="level3.tree1.project.1.bias
 (128)" fillcolor=lightblue]
	140301969564272 -> 140301477016768
	140301477016768 [label=AccumulateGrad]
	140301477016336 -> 140301477016048
	140301969460496 [label="level3.tree1.tree2.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140301969460496 -> 140301477016336
	140301477016336 [label=AccumulateGrad]
	140301477015904 -> 140301477016000
	140301969460576 [label="level3.tree1.tree2.bn1.weight
 (128)" fillcolor=lightblue]
	140301969460576 -> 140301477015904
	140301477015904 [label=AccumulateGrad]
	140301477016144 -> 140301477016000
	140301969460656 [label="level3.tree1.tree2.bn1.bias
 (128)" fillcolor=lightblue]
	140301969460656 -> 140301477016144
	140301477016144 [label=AccumulateGrad]
	140301477015808 -> 140301477007312
	140301969461056 [label="level3.tree1.tree2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140301969461056 -> 140301477015808
	140301477015808 [label=AccumulateGrad]
	140301477015664 -> 140301477007216
	140301969461136 [label="level3.tree1.tree2.bn2.weight
 (128)" fillcolor=lightblue]
	140301969461136 -> 140301477015664
	140301477015664 [label=AccumulateGrad]
	140301477015616 -> 140301477007216
	140301969563712 [label="level3.tree1.tree2.bn2.bias
 (128)" fillcolor=lightblue]
	140301969563712 -> 140301477015616
	140301477015616 [label=AccumulateGrad]
	140301477006976 -> 140301477007168
	140301477006976 -> 140301477006880
	140301477006832 -> 140301477006592
	140301969564672 [label="level3.tree1.root.conv.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	140301969564672 -> 140301477006832
	140301477006832 [label=AccumulateGrad]
	140301477006352 -> 140301477006544
	140301969564752 [label="level3.tree1.root.bn.weight
 (128)" fillcolor=lightblue]
	140301969564752 -> 140301477006352
	140301477006352 [label=AccumulateGrad]
	140301477006688 -> 140301477006544
	140301969564832 [label="level3.tree1.root.bn.bias
 (128)" fillcolor=lightblue]
	140301969564832 -> 140301477006688
	140301477006688 [label=AccumulateGrad]
	140301477006448 -> 140301477006160
	140301969565232 [label="level3.tree2.tree1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140301969565232 -> 140301477006448
	140301477006448 [label=AccumulateGrad]
	140301477006016 -> 140301477006112
	140301969565312 [label="level3.tree2.tree1.bn1.weight
 (128)" fillcolor=lightblue]
	140301969565312 -> 140301477006016
	140301477006016 [label=AccumulateGrad]
	140301477006256 -> 140301477006112
	140301969565392 [label="level3.tree2.tree1.bn1.bias
 (128)" fillcolor=lightblue]
	140301969565392 -> 140301477006256
	140301477006256 [label=AccumulateGrad]
	140301477005920 -> 140301477005776
	140301969565792 [label="level3.tree2.tree1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140301969565792 -> 140301477005920
	140301477005920 [label=AccumulateGrad]
	140301477005728 -> 140301477005584
	140301969565872 [label="level3.tree2.tree1.bn2.weight
 (128)" fillcolor=lightblue]
	140301969565872 -> 140301477005728
	140301477005728 [label=AccumulateGrad]
	140301477005680 -> 140301477005584
	140301969565952 [label="level3.tree2.tree1.bn2.bias
 (128)" fillcolor=lightblue]
	140301969565952 -> 140301477005680
	140301477005680 [label=AccumulateGrad]
	140301477004336 -> 140301477005536
	140301477005440 -> 140301477005152
	140301969566352 [label="level3.tree2.tree2.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140301969566352 -> 140301477005440
	140301477005440 [label=AccumulateGrad]
	140301477005008 -> 140301477005104
	140301969566432 [label="level3.tree2.tree2.bn1.weight
 (128)" fillcolor=lightblue]
	140301969566432 -> 140301477005008
	140301477005008 [label=AccumulateGrad]
	140301477005248 -> 140301477005104
	140301969566512 [label="level3.tree2.tree2.bn1.bias
 (128)" fillcolor=lightblue]
	140301969566512 -> 140301477005248
	140301477005248 [label=AccumulateGrad]
	140301477004912 -> 140301477004768
	140301969566912 [label="level3.tree2.tree2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140301969566912 -> 140301477004912
	140301477004912 [label=AccumulateGrad]
	140301477004720 -> 140301477004576
	140301969566992 [label="level3.tree2.tree2.bn2.weight
 (128)" fillcolor=lightblue]
	140301969566992 -> 140301477004720
	140301477004720 [label=AccumulateGrad]
	140301477004672 -> 140301477004576
	140301969567072 [label="level3.tree2.tree2.bn2.bias
 (128)" fillcolor=lightblue]
	140301969567072 -> 140301477004672
	140301477004672 [label=AccumulateGrad]
	140301477004240 -> 140301477004528
	140301477004240 -> 140301477004144
	140301477004192 -> 140301477004144
	140301477004192 [label=MaxPool2DWithIndicesBackward0]
	140301477017392 -> 140301477004192
	140301477004336 -> 140301477004144
	140301477004096 -> 140301477003856
	140301969567552 [label="level3.tree2.root.conv.weight
 (128, 448, 1, 1)" fillcolor=lightblue]
	140301969567552 -> 140301477004096
	140301477004096 [label=AccumulateGrad]
	140301477003712 -> 140301477003808
	140301969567632 [label="level3.tree2.root.bn.weight
 (128)" fillcolor=lightblue]
	140301969567632 -> 140301477003712
	140301477003712 [label=AccumulateGrad]
	140301477003952 -> 140301477003808
	140301470793792 [label="level3.tree2.root.bn.bias
 (128)" fillcolor=lightblue]
	140301470793792 -> 140301477003952
	140301477003952 [label=AccumulateGrad]
	140301477003616 -> 140301477003472
	140301470794192 [label="level4.tree1.tree1.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	140301470794192 -> 140301477003616
	140301477003616 [label=AccumulateGrad]
	140301477003424 -> 140301476990928
	140301470794272 [label="level4.tree1.tree1.bn1.weight
 (256)" fillcolor=lightblue]
	140301470794272 -> 140301477003424
	140301477003424 [label=AccumulateGrad]
	140301477003328 -> 140301476990928
	140301470794352 [label="level4.tree1.tree1.bn1.bias
 (256)" fillcolor=lightblue]
	140301470794352 -> 140301477003328
	140301477003328 [label=AccumulateGrad]
	140301476990832 -> 140301476990688
	140301470794752 [label="level4.tree1.tree1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140301470794752 -> 140301476990832
	140301476990832 [label=AccumulateGrad]
	140301476990640 -> 140301476990544
	140301470794832 [label="level4.tree1.tree1.bn2.weight
 (256)" fillcolor=lightblue]
	140301470794832 -> 140301476990640
	140301476990640 [label=AccumulateGrad]
	140301476990592 -> 140301476990544
	140301470794912 [label="level4.tree1.tree1.bn2.bias
 (256)" fillcolor=lightblue]
	140301470794912 -> 140301476990592
	140301476990592 [label=AccumulateGrad]
	140301476990496 -> 140301476990448
	140301476990496 [label=NativeBatchNormBackward0]
	140301476990784 -> 140301476990496
	140301476990784 [label=ConvolutionBackward0]
	140301477004000 -> 140301476990784
	140301477004000 [label=MaxPool2DWithIndicesBackward0]
	140301477003664 -> 140301477004000
	140301477004048 -> 140301476990784
	140301470796432 [label="level4.tree1.project.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	140301470796432 -> 140301477004048
	140301477004048 [label=AccumulateGrad]
	140301476990736 -> 140301476990496
	140301470796512 [label="level4.tree1.project.1.weight
 (256)" fillcolor=lightblue]
	140301470796512 -> 140301476990736
	140301476990736 [label=AccumulateGrad]
	140301477003568 -> 140301476990496
	140301470796592 [label="level4.tree1.project.1.bias
 (256)" fillcolor=lightblue]
	140301470796592 -> 140301477003568
	140301477003568 [label=AccumulateGrad]
	140301476990352 -> 140301476990160
	140301470795312 [label="level4.tree1.tree2.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140301470795312 -> 140301476990352
	140301476990352 [label=AccumulateGrad]
	140301476990112 -> 140301476990064
	140301470795392 [label="level4.tree1.tree2.bn1.weight
 (256)" fillcolor=lightblue]
	140301470795392 -> 140301476990112
	140301476990112 [label=AccumulateGrad]
	140301476989968 -> 140301476990064
	140301470795472 [label="level4.tree1.tree2.bn1.bias
 (256)" fillcolor=lightblue]
	140301470795472 -> 140301476989968
	140301476989968 [label=AccumulateGrad]
	140301476989872 -> 140301476989728
	140301470795872 [label="level4.tree1.tree2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140301470795872 -> 140301476989872
	140301476989872 [label=AccumulateGrad]
	140301476989680 -> 140301476989632
	140301470795952 [label="level4.tree1.tree2.bn2.weight
 (256)" fillcolor=lightblue]
	140301470795952 -> 140301476989680
	140301476989680 [label=AccumulateGrad]
	140301476989440 -> 140301476989632
	140301470796032 [label="level4.tree1.tree2.bn2.bias
 (256)" fillcolor=lightblue]
	140301470796032 -> 140301476989440
	140301476989440 [label=AccumulateGrad]
	140301476989344 -> 140301476989536
	140301476989344 -> 140301476989248
	140301476989200 -> 140301476989056
	140301470796992 [label="level4.tree1.root.conv.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	140301470796992 -> 140301476989200
	140301476989200 [label=AccumulateGrad]
	140301476989008 -> 140301476988960
	140301470797072 [label="level4.tree1.root.bn.weight
 (256)" fillcolor=lightblue]
	140301470797072 -> 140301476989008
	140301476989008 [label=AccumulateGrad]
	140301476988768 -> 140301476988960
	140301470797152 [label="level4.tree1.root.bn.bias
 (256)" fillcolor=lightblue]
	140301470797152 -> 140301476988768
	140301476988768 [label=AccumulateGrad]
	140301476988864 -> 140301476988672
	140301470797552 [label="level4.tree2.tree1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140301470797552 -> 140301476988864
	140301476988864 [label=AccumulateGrad]
	140301476988624 -> 140301476988576
	140301470797632 [label="level4.tree2.tree1.bn1.weight
 (256)" fillcolor=lightblue]
	140301470797632 -> 140301476988624
	140301476988624 [label=AccumulateGrad]
	140301476988480 -> 140301476988576
	140301470797712 [label="level4.tree2.tree1.bn1.bias
 (256)" fillcolor=lightblue]
	140301470797712 -> 140301476988480
	140301476988480 [label=AccumulateGrad]
	140301476988384 -> 140301476988240
	140301470908800 [label="level4.tree2.tree1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140301470908800 -> 140301476988384
	140301476988384 [label=AccumulateGrad]
	140301476988192 -> 140301476988144
	140301470908880 [label="level4.tree2.tree1.bn2.weight
 (256)" fillcolor=lightblue]
	140301470908880 -> 140301476988192
	140301476988192 [label=AccumulateGrad]
	140301476987856 -> 140301476988144
	140301470908960 [label="level4.tree2.tree1.bn2.bias
 (256)" fillcolor=lightblue]
	140301470908960 -> 140301476987856
	140301476987856 [label=AccumulateGrad]
	140301476986944 -> 140301476988048
	140301476987952 -> 140301476987760
	140301470909360 [label="level4.tree2.tree2.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140301470909360 -> 140301476987952
	140301476987952 [label=AccumulateGrad]
	140301476987712 -> 140301476987664
	140301470909440 [label="level4.tree2.tree2.bn1.weight
 (256)" fillcolor=lightblue]
	140301470909440 -> 140301476987712
	140301476987712 [label=AccumulateGrad]
	140301476987568 -> 140301476987664
	140301470909520 [label="level4.tree2.tree2.bn1.bias
 (256)" fillcolor=lightblue]
	140301470909520 -> 140301476987568
	140301476987568 [label=AccumulateGrad]
	140301476987472 -> 140301476987328
	140301470909920 [label="level4.tree2.tree2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140301470909920 -> 140301476987472
	140301476987472 [label=AccumulateGrad]
	140301476987280 -> 140301476987232
	140301470910000 [label="level4.tree2.tree2.bn2.weight
 (256)" fillcolor=lightblue]
	140301470910000 -> 140301476987280
	140301476987280 [label=AccumulateGrad]
	140301476987040 -> 140301476987232
	140301470910080 [label="level4.tree2.tree2.bn2.bias
 (256)" fillcolor=lightblue]
	140301470910080 -> 140301476987040
	140301476987040 [label=AccumulateGrad]
	140302512099232 -> 140301476987136
	140302512099232 -> 140302512099136
	140302512099184 -> 140302512099136
	140302512099184 [label=MaxPool2DWithIndicesBackward0]
	140301477003664 -> 140302512099184
	140301476986944 -> 140302512099136
	140302512099088 -> 140302512098944
	140301470910480 [label="level4.tree2.root.conv.weight
 (256, 896, 1, 1)" fillcolor=lightblue]
	140301470910480 -> 140302512099088
	140302512099088 [label=AccumulateGrad]
	140302512098896 -> 140302512098848
	140301470910560 [label="level4.tree2.root.bn.weight
 (256)" fillcolor=lightblue]
	140301470910560 -> 140302512098896
	140302512098896 [label=AccumulateGrad]
	140302512098752 -> 140302512098848
	140301470910640 [label="level4.tree2.root.bn.bias
 (256)" fillcolor=lightblue]
	140301470910640 -> 140302512098752
	140302512098752 [label=AccumulateGrad]
	140302512098656 -> 140302512098512
	140301470911040 [label="level5.tree1.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	140301470911040 -> 140302512098656
	140302512098656 [label=AccumulateGrad]
	140302512098464 -> 140302512098416
	140301470911120 [label="level5.tree1.bn1.weight
 (512)" fillcolor=lightblue]
	140301470911120 -> 140302512098464
	140302512098464 [label=AccumulateGrad]
	140302512098320 -> 140302512098416
	140301470911200 [label="level5.tree1.bn1.bias
 (512)" fillcolor=lightblue]
	140301470911200 -> 140302512098320
	140302512098320 [label=AccumulateGrad]
	140302512098224 -> 140302512098080
	140301470911600 [label="level5.tree1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140301470911600 -> 140302512098224
	140302512098224 [label=AccumulateGrad]
	140302512098032 -> 140302512097936
	140301470911680 [label="level5.tree1.bn2.weight
 (512)" fillcolor=lightblue]
	140301470911680 -> 140302512098032
	140302512098032 [label=AccumulateGrad]
	140302512097984 -> 140302512097936
	140301470911760 [label="level5.tree1.bn2.bias
 (512)" fillcolor=lightblue]
	140301470911760 -> 140302512097984
	140302512097984 [label=AccumulateGrad]
	140302512097888 -> 140302512097840
	140302512097888 [label=NativeBatchNormBackward0]
	140302512098608 -> 140302512097888
	140302512098608 [label=ConvolutionBackward0]
	140302512096928 -> 140302512098608
	140302512096928 [label=MaxPool2DWithIndicesBackward0]
	140302512098704 -> 140302512096928
	140302512098992 -> 140302512098608
	140301470995296 [label="level5.project.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	140301470995296 -> 140302512098992
	140302512098992 [label=AccumulateGrad]
	140302512098176 -> 140302512097888
	140301470995376 [label="level5.project.1.weight
 (512)" fillcolor=lightblue]
	140301470995376 -> 140302512098176
	140302512098176 [label=AccumulateGrad]
	140302512098128 -> 140302512097888
	140301470995456 [label="level5.project.1.bias
 (512)" fillcolor=lightblue]
	140301470995456 -> 140302512098128
	140302512098128 [label=AccumulateGrad]
	140302512097744 -> 140302512097552
	140301470912160 [label="level5.tree2.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140301470912160 -> 140302512097744
	140302512097744 [label=AccumulateGrad]
	140302512097504 -> 140302512097456
	140301470912240 [label="level5.tree2.bn1.weight
 (512)" fillcolor=lightblue]
	140301470912240 -> 140302512097504
	140302512097504 [label=AccumulateGrad]
	140302512097360 -> 140302512097456
	140301470912320 [label="level5.tree2.bn1.bias
 (512)" fillcolor=lightblue]
	140301470912320 -> 140302512097360
	140302512097360 [label=AccumulateGrad]
	140302512097264 -> 140302512097120
	140301470994736 [label="level5.tree2.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140301470994736 -> 140302512097264
	140302512097264 [label=AccumulateGrad]
	140302512097072 -> 140302512097024
	140301470994816 [label="level5.tree2.bn2.weight
 (512)" fillcolor=lightblue]
	140301470994816 -> 140302512097072
	140302512097072 [label=AccumulateGrad]
	140302512096976 -> 140302512097024
	140301470994896 [label="level5.tree2.bn2.bias
 (512)" fillcolor=lightblue]
	140301470994896 -> 140302512096976
	140302512096976 [label=AccumulateGrad]
	140302512095968 -> 140302512096736
	140302512095968 -> 140302512096784
	140302512096928 -> 140302512096784
	140302512096832 -> 140302512096304
	140301470995856 [label="level5.root.conv.weight
 (512, 1280, 1, 1)" fillcolor=lightblue]
	140301470995856 -> 140302512096832
	140302512096832 [label=AccumulateGrad]
	140302512096544 -> 140302512096592
	140301470995936 [label="level5.root.bn.weight
 (512)" fillcolor=lightblue]
	140301470995936 -> 140302512096544
	140302512096544 [label=AccumulateGrad]
	140302512096352 -> 140302512096592
	140301470996016 [label="level5.root.bn.bias
 (512)" fillcolor=lightblue]
	140301470996016 -> 140302512096352
	140302512096352 [label=AccumulateGrad]
	140301470932320 -> 140301470932368
	140301470996336 [label="fc.weight
 (1000, 512, 1, 1)" fillcolor=lightblue]
	140301470996336 -> 140301470932320
	140301470932320 [label=AccumulateGrad]
	140301470932080 -> 140301470932368
	140301470996416 [label="fc.bias
 (1000)" fillcolor=lightblue]
	140301470996416 -> 140301470932080
	140301470932080 [label=AccumulateGrad]
	140301470932272 -> 140302512260736
	140302512260176 [label="
 (1, 1000, 1, 1)" fillcolor=darkolivegreen3]
	140301470932368 -> 140302512260176
	140302512260176 -> 140302512260736 [style=dotted]
}
