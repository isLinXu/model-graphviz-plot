digraph {
	graph [size="959.0999999999999,959.0999999999999"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140310156952176 [label="
 (1, 1000)" fillcolor=darkolivegreen1]
	140309353857520 [label=AddmmBackward0]
	140309353860256 -> 140309353857520
	140309353717248 [label="classifier.bias
 (1000)" fillcolor=lightblue]
	140309353717248 -> 140309353860256
	140309353860256 [label=AccumulateGrad]
	140309353860784 -> 140309353857520
	140309353860784 [label=ReshapeAliasBackward0]
	140309353858336 -> 140309353860784
	140309353858336 [label=MeanBackward1]
	140309353859728 -> 140309353858336
	140309353859728 [label=ReluBackward0]
	140309353859872 -> 140309353859728
	140309353859872 [label=NativeBatchNormBackward0]
	140309353857184 -> 140309353859872
	140309353857184 [label=ConvolutionBackward0]
	140310156634672 -> 140309353857184
	140310156634672 [label=AddBackward0]
	140310156634336 -> 140310156634672
	140310156634336 [label=ReluBackward0]
	140310156634720 -> 140310156634336
	140310156634720 [label=AddBackward0]
	140310156634576 -> 140310156634720
	140310156634576 [label=NativeBatchNormBackward0]
	140310156634432 -> 140310156634576
	140310156634432 [label=ConvolutionBackward0]
	140310156634528 -> 140310156634432
	140310156634528 [label=ReluBackward0]
	140310156635056 -> 140310156634528
	140310156635056 [label=NativeBatchNormBackward0]
	140310156635200 -> 140310156635056
	140310156635200 [label=ConvolutionBackward0]
	140310156635344 -> 140310156635200
	140310156635344 [label=ReluBackward0]
	140310156635488 -> 140310156635344
	140310156635488 [label=NativeBatchNormBackward0]
	140310156635584 -> 140310156635488
	140310156635584 [label=ConvolutionBackward0]
	140310156635776 -> 140310156635584
	140310156635776 [label=ReluBackward0]
	140310156635920 -> 140310156635776
	140310156635920 [label=AddBackward0]
	140310156636016 -> 140310156635920
	140310156636016 [label=AddBackward0]
	140310156636112 -> 140310156636016
	140310156636112 [label=AddBackward0]
	140309917479120 -> 140310156636112
	140309917479120 [label=NativeBatchNormBackward0]
	140309917479264 -> 140309917479120
	140309917479264 [label=ConvolutionBackward0]
	140309917479456 -> 140309917479264
	140309917479456 [label=ReluBackward0]
	140309917479600 -> 140309917479456
	140309917479600 [label=NativeBatchNormBackward0]
	140309917479696 -> 140309917479600
	140309917479696 [label=ConvolutionBackward0]
	140309917479888 -> 140309917479696
	140309917479888 [label=ReluBackward0]
	140309917480032 -> 140309917479888
	140309917480032 [label=NativeBatchNormBackward0]
	140309917480128 -> 140309917480032
	140309917480128 [label=ConvolutionBackward0]
	140309917480320 -> 140309917480128
	140309917480320 [label=ReluBackward0]
	140309917480464 -> 140309917480320
	140309917480464 [label=AddBackward0]
	140309917480512 -> 140309917480464
	140309917480512 [label=NativeBatchNormBackward0]
	140309917480752 -> 140309917480512
	140309917480752 [label=ConvolutionBackward0]
	140309917480944 -> 140309917480752
	140309917480944 [label=ReluBackward0]
	140309917481088 -> 140309917480944
	140309917481088 [label=NativeBatchNormBackward0]
	140309917481136 -> 140309917481088
	140309917481136 [label=ConvolutionBackward0]
	140309917480368 -> 140309917481136
	140309917480368 [label=ReluBackward0]
	140309917481520 -> 140309917480368
	140309917481520 [label=AddBackward0]
	140309917481568 -> 140309917481520
	140309917481568 [label=NativeBatchNormBackward0]
	140309917481808 -> 140309917481568
	140309917481808 [label=ConvolutionBackward0]
	140309917482000 -> 140309917481808
	140309917482000 [label=ReluBackward0]
	140309917482144 -> 140309917482000
	140309917482144 [label=NativeBatchNormBackward0]
	140309917482192 -> 140309917482144
	140309917482192 [label=ConvolutionBackward0]
	140309917481328 -> 140309917482192
	140309917481328 [label=ReluBackward0]
	140309917482576 -> 140309917481328
	140309917482576 [label=AddBackward0]
	140309917482624 -> 140309917482576
	140309917482624 [label=NativeBatchNormBackward0]
	140309917482864 -> 140309917482624
	140309917482864 [label=ConvolutionBackward0]
	140309917482960 -> 140309917482864
	140309917482960 [label=ReluBackward0]
	140309917454592 -> 140309917482960
	140309917454592 [label=NativeBatchNormBackward0]
	140309917454640 -> 140309917454592
	140309917454640 [label=ConvolutionBackward0]
	140309917482384 -> 140309917454640
	140309917482384 [label=ReluBackward0]
	140309917455024 -> 140309917482384
	140309917455024 [label=AddBackward0]
	140309917455072 -> 140309917455024
	140309917455072 [label=NativeBatchNormBackward0]
	140309917455312 -> 140309917455072
	140309917455312 [label=ConvolutionBackward0]
	140309917455504 -> 140309917455312
	140309917455504 [label=ReluBackward0]
	140309917455648 -> 140309917455504
	140309917455648 [label=NativeBatchNormBackward0]
	140309917455696 -> 140309917455648
	140309917455696 [label=ConvolutionBackward0]
	140309917454832 -> 140309917455696
	140309917454832 [label=ReluBackward0]
	140309917456080 -> 140309917454832
	140309917456080 [label=AddBackward0]
	140309917456128 -> 140309917456080
	140309917456128 [label=AddBackward0]
	140309917456368 -> 140309917456128
	140309917456368 [label=AddBackward0]
	140309917456512 -> 140309917456368
	140309917456512 [label=ReluBackward0]
	140309917456656 -> 140309917456512
	140309917456656 [label=AddBackward0]
	140309917456704 -> 140309917456656
	140309917456704 [label=NativeBatchNormBackward0]
	140309917456944 -> 140309917456704
	140309917456944 [label=ConvolutionBackward0]
	140309917457136 -> 140309917456944
	140309917457136 [label=ReluBackward0]
	140309917457280 -> 140309917457136
	140309917457280 [label=NativeBatchNormBackward0]
	140309917457328 -> 140309917457280
	140309917457328 [label=ConvolutionBackward0]
	140309917456560 -> 140309917457328
	140309917456560 [label=ReluBackward0]
	140309917457712 -> 140309917456560
	140309917457712 [label=AddBackward0]
	140309917457760 -> 140309917457712
	140309917457760 [label=NativeBatchNormBackward0]
	140309917458000 -> 140309917457760
	140309917458000 [label=ConvolutionBackward0]
	140309917458192 -> 140309917458000
	140309917458192 [label=ReluBackward0]
	140309917458336 -> 140309917458192
	140309917458336 [label=NativeBatchNormBackward0]
	140309917458240 -> 140309917458336
	140309917458240 [label=ConvolutionBackward0]
	140309917457520 -> 140309917458240
	140309917457520 [label=ReluBackward0]
	140309917442448 -> 140309917457520
	140309917442448 [label=AddBackward0]
	140309917442496 -> 140309917442448
	140309917442496 [label=NativeBatchNormBackward0]
	140309917442736 -> 140309917442496
	140309917442736 [label=ConvolutionBackward0]
	140309917442928 -> 140309917442736
	140309917442928 [label=ReluBackward0]
	140309917443072 -> 140309917442928
	140309917443072 [label=NativeBatchNormBackward0]
	140309917443120 -> 140309917443072
	140309917443120 [label=ConvolutionBackward0]
	140309917442256 -> 140309917443120
	140309917442256 [label=ReluBackward0]
	140309917443504 -> 140309917442256
	140309917443504 [label=AddBackward0]
	140309917443552 -> 140309917443504
	140309917443552 [label=NativeBatchNormBackward0]
	140309917443792 -> 140309917443552
	140309917443792 [label=ConvolutionBackward0]
	140309917443984 -> 140309917443792
	140309917443984 [label=ReluBackward0]
	140309917444128 -> 140309917443984
	140309917444128 [label=NativeBatchNormBackward0]
	140309917444176 -> 140309917444128
	140309917444176 [label=ConvolutionBackward0]
	140309917443312 -> 140309917444176
	140309917443312 [label=ReluBackward0]
	140309917444560 -> 140309917443312
	140309917444560 [label=AddBackward0]
	140309917444608 -> 140309917444560
	140309917444608 [label=AddBackward0]
	140309917444848 -> 140309917444608
	140309917444848 [label=AddBackward0]
	140309917444992 -> 140309917444848
	140309917444992 [label=ReluBackward0]
	140309917445136 -> 140309917444992
	140309917445136 [label=AddBackward0]
	140309917445184 -> 140309917445136
	140309917445184 [label=NativeBatchNormBackward0]
	140309917445424 -> 140309917445184
	140309917445424 [label=ConvolutionBackward0]
	140309917445616 -> 140309917445424
	140309917445616 [label=ReluBackward0]
	140309917445760 -> 140309917445616
	140309917445760 [label=NativeBatchNormBackward0]
	140309917445808 -> 140309917445760
	140309917445808 [label=ConvolutionBackward0]
	140309917445040 -> 140309917445808
	140309917445040 [label=ReluBackward0]
	140309917446000 -> 140309917445040
	140309917446000 [label=AddBackward0]
	140309917434016 -> 140309917446000
	140309917434016 [label=NativeBatchNormBackward0]
	140309917434256 -> 140309917434016
	140309917434256 [label=ConvolutionBackward0]
	140309917434448 -> 140309917434256
	140309917434448 [label=ReluBackward0]
	140309917434592 -> 140309917434448
	140309917434592 [label=NativeBatchNormBackward0]
	140309917434640 -> 140309917434592
	140309917434640 [label=ConvolutionBackward0]
	140309917433920 -> 140309917434640
	140309917433920 [label=ReluBackward0]
	140309917435024 -> 140309917433920
	140309917435024 [label=AddBackward0]
	140309917435072 -> 140309917435024
	140309917435072 [label=NativeBatchNormBackward0]
	140309917435312 -> 140309917435072
	140309917435312 [label=ConvolutionBackward0]
	140309917435504 -> 140309917435312
	140309917435504 [label=ReluBackward0]
	140309917435648 -> 140309917435504
	140309917435648 [label=NativeBatchNormBackward0]
	140309917435696 -> 140309917435648
	140309917435696 [label=ConvolutionBackward0]
	140309917434832 -> 140309917435696
	140309917434832 [label=ReluBackward0]
	140309917436080 -> 140309917434832
	140309917436080 [label=AddBackward0]
	140309917436128 -> 140309917436080
	140309917436128 [label=NativeBatchNormBackward0]
	140309917436368 -> 140309917436128
	140309917436368 [label=ConvolutionBackward0]
	140309917436560 -> 140309917436368
	140309917436560 [label=ReluBackward0]
	140309917436704 -> 140309917436560
	140309917436704 [label=NativeBatchNormBackward0]
	140309917436752 -> 140309917436704
	140309917436752 [label=ConvolutionBackward0]
	140309917435888 -> 140309917436752
	140309917435888 [label=ReluBackward0]
	140309917437136 -> 140309917435888
	140309917437136 [label=AddBackward0]
	140309917437184 -> 140309917437136
	140309917437184 [label=AddBackward0]
	140309917437424 -> 140309917437184
	140309917437424 [label=ReluBackward0]
	140309917437568 -> 140309917437424
	140309917437568 [label=AddBackward0]
	140309917437616 -> 140309917437568
	140309917437616 [label=NativeBatchNormBackward0]
	140309917437856 -> 140309917437616
	140309917437856 [label=ConvolutionBackward0]
	140309917417632 -> 140309917437856
	140309917417632 [label=ReluBackward0]
	140309917417776 -> 140309917417632
	140309917417776 [label=NativeBatchNormBackward0]
	140309917417824 -> 140309917417776
	140309917417824 [label=ConvolutionBackward0]
	140309917437472 -> 140309917417824
	140309917437472 [label=ReluBackward0]
	140309917418208 -> 140309917437472
	140309917418208 [label=AddBackward0]
	140309917418256 -> 140309917418208
	140309917418256 [label=NativeBatchNormBackward0]
	140309917418496 -> 140309917418256
	140309917418496 [label=ConvolutionBackward0]
	140309917418688 -> 140309917418496
	140309917418688 [label=ReluBackward0]
	140309917418832 -> 140309917418688
	140309917418832 [label=NativeBatchNormBackward0]
	140309917418880 -> 140309917418832
	140309917418880 [label=ConvolutionBackward0]
	140309917418016 -> 140309917418880
	140309917418016 [label=ReluBackward0]
	140309917419264 -> 140309917418016
	140309917419264 [label=AddBackward0]
	140309917419312 -> 140309917419264
	140309917419312 [label=NativeBatchNormBackward0]
	140309917419552 -> 140309917419312
	140309917419552 [label=ConvolutionBackward0]
	140309917419744 -> 140309917419552
	140309917419744 [label=ReluBackward0]
	140309917419888 -> 140309917419744
	140309917419888 [label=NativeBatchNormBackward0]
	140309917419936 -> 140309917419888
	140309917419936 [label=ConvolutionBackward0]
	140309917419072 -> 140309917419936
	140309917419072 [label=ReluBackward0]
	140309917420320 -> 140309917419072
	140309917420320 [label=AddBackward0]
	140309917420368 -> 140309917420320
	140309917420368 [label=NativeBatchNormBackward0]
	140309917420608 -> 140309917420368
	140309917420608 [label=ConvolutionBackward0]
	140309917420800 -> 140309917420608
	140309917420800 [label=ReluBackward0]
	140309917420944 -> 140309917420800
	140309917420944 [label=NativeBatchNormBackward0]
	140309917420992 -> 140309917420944
	140309917420992 [label=ConvolutionBackward0]
	140309917420128 -> 140309917420992
	140309917420128 [label=ReluBackward0]
	140309917421376 -> 140309917420128
	140309917421376 [label=AddBackward0]
	140309917421424 -> 140309917421376
	140309917421424 [label=AddBackward0]
	140309917405344 -> 140309917421424
	140309917405344 [label=ReluBackward0]
	140309917405488 -> 140309917405344
	140309917405488 [label=AddBackward0]
	140309917405536 -> 140309917405488
	140309917405536 [label=NativeBatchNormBackward0]
	140309917405776 -> 140309917405536
	140309917405776 [label=ConvolutionBackward0]
	140309917405968 -> 140309917405776
	140309917405968 [label=ReluBackward0]
	140309917406112 -> 140309917405968
	140309917406112 [label=NativeBatchNormBackward0]
	140309917406160 -> 140309917406112
	140309917406160 [label=ConvolutionBackward0]
	140309917405392 -> 140309917406160
	140309917405392 [label=ReluBackward0]
	140309917406544 -> 140309917405392
	140309917406544 [label=AddBackward0]
	140309917406592 -> 140309917406544
	140309917406592 [label=NativeBatchNormBackward0]
	140309917406832 -> 140309917406592
	140309917406832 [label=ConvolutionBackward0]
	140309917407024 -> 140309917406832
	140309917407024 [label=ReluBackward0]
	140309917407168 -> 140309917407024
	140309917407168 [label=NativeBatchNormBackward0]
	140309917407216 -> 140309917407168
	140309917407216 [label=ConvolutionBackward0]
	140309917406352 -> 140309917407216
	140309917406352 [label=ReluBackward0]
	140309917407600 -> 140309917406352
	140309917407600 [label=AddBackward0]
	140309917407648 -> 140309917407600
	140309917407648 [label=NativeBatchNormBackward0]
	140309917407888 -> 140309917407648
	140309917407888 [label=ConvolutionBackward0]
	140309917408080 -> 140309917407888
	140309917408080 [label=ReluBackward0]
	140309917408224 -> 140309917408080
	140309917408224 [label=NativeBatchNormBackward0]
	140309917408272 -> 140309917408224
	140309917408272 [label=ConvolutionBackward0]
	140309917407408 -> 140309917408272
	140309917407408 [label=ReluBackward0]
	140309917408656 -> 140309917407408
	140309917408656 [label=AddBackward0]
	140309917408704 -> 140309917408656
	140309917408704 [label=NativeBatchNormBackward0]
	140309917408944 -> 140309917408704
	140309917408944 [label=ConvolutionBackward0]
	140309917409136 -> 140309917408944
	140309917409136 [label=ReluBackward0]
	140309917409232 -> 140309917409136
	140309917409232 [label=NativeBatchNormBackward0]
	140309917388912 -> 140309917409232
	140309917388912 [label=ConvolutionBackward0]
	140309917408464 -> 140309917388912
	140309917408464 [label=ReluBackward0]
	140309917389296 -> 140309917408464
	140309917389296 [label=AddBackward0]
	140309917389344 -> 140309917389296
	140309917389344 [label=AddBackward0]
	140309917389584 -> 140309917389344
	140309917389584 [label=ReluBackward0]
	140309917389728 -> 140309917389584
	140309917389728 [label=AddBackward0]
	140309917389776 -> 140309917389728
	140309917389776 [label=NativeBatchNormBackward0]
	140309917390016 -> 140309917389776
	140309917390016 [label=ConvolutionBackward0]
	140309917390208 -> 140309917390016
	140309917390208 [label=ReluBackward0]
	140309917390352 -> 140309917390208
	140309917390352 [label=NativeBatchNormBackward0]
	140309917390400 -> 140309917390352
	140309917390400 [label=ConvolutionBackward0]
	140309917389632 -> 140309917390400
	140309917389632 [label=ReluBackward0]
	140309917390784 -> 140309917389632
	140309917390784 [label=AddBackward0]
	140309917390832 -> 140309917390784
	140309917390832 [label=NativeBatchNormBackward0]
	140309917391072 -> 140309917390832
	140309917391072 [label=ConvolutionBackward0]
	140309917391264 -> 140309917391072
	140309917391264 [label=ReluBackward0]
	140309917391408 -> 140309917391264
	140309917391408 [label=NativeBatchNormBackward0]
	140309917391456 -> 140309917391408
	140309917391456 [label=ConvolutionBackward0]
	140309917390592 -> 140309917391456
	140309917390592 [label=ReluBackward0]
	140309917391840 -> 140309917390592
	140309917391840 [label=AddBackward0]
	140309917391888 -> 140309917391840
	140309917391888 [label=NativeBatchNormBackward0]
	140309917392128 -> 140309917391888
	140309917392128 [label=ConvolutionBackward0]
	140309917392320 -> 140309917392128
	140309917392320 [label=ReluBackward0]
	140309917392464 -> 140309917392320
	140309917392464 [label=NativeBatchNormBackward0]
	140309917392512 -> 140309917392464
	140309917392512 [label=ConvolutionBackward0]
	140309917391648 -> 140309917392512
	140309917391648 [label=ReluBackward0]
	140309917392848 -> 140309917391648
	140309917392848 [label=AddBackward0]
	140309917376624 -> 140309917392848
	140309917376624 [label=NativeBatchNormBackward0]
	140309917376864 -> 140309917376624
	140309917376864 [label=ConvolutionBackward0]
	140309917377056 -> 140309917376864
	140309917377056 [label=ReluBackward0]
	140309917377200 -> 140309917377056
	140309917377200 [label=NativeBatchNormBackward0]
	140309917377248 -> 140309917377200
	140309917377248 [label=ConvolutionBackward0]
	140309917376576 -> 140309917377248
	140309917376576 [label=ReluBackward0]
	140309917377632 -> 140309917376576
	140309917377632 [label=AddBackward0]
	140309917377680 -> 140309917377632
	140309917377680 [label=AddBackward0]
	140309917377920 -> 140309917377680
	140309917377920 [label=ReluBackward0]
	140309917378064 -> 140309917377920
	140309917378064 [label=AddBackward0]
	140309917378112 -> 140309917378064
	140309917378112 [label=NativeBatchNormBackward0]
	140309917378352 -> 140309917378112
	140309917378352 [label=ConvolutionBackward0]
	140309917378544 -> 140309917378352
	140309917378544 [label=ReluBackward0]
	140309917378688 -> 140309917378544
	140309917378688 [label=NativeBatchNormBackward0]
	140309917378736 -> 140309917378688
	140309917378736 [label=ConvolutionBackward0]
	140309917377968 -> 140309917378736
	140309917377968 [label=ReluBackward0]
	140309917379120 -> 140309917377968
	140309917379120 [label=AddBackward0]
	140309917379168 -> 140309917379120
	140309917379168 [label=NativeBatchNormBackward0]
	140309917379408 -> 140309917379168
	140309917379408 [label=ConvolutionBackward0]
	140309917379600 -> 140309917379408
	140309917379600 [label=ReluBackward0]
	140309917379744 -> 140309917379600
	140309917379744 [label=NativeBatchNormBackward0]
	140309917379792 -> 140309917379744
	140309917379792 [label=ConvolutionBackward0]
	140309917378928 -> 140309917379792
	140309917378928 [label=ReluBackward0]
	140309917380176 -> 140309917378928
	140309917380176 [label=AddBackward0]
	140309917380224 -> 140309917380176
	140309917380224 [label=NativeBatchNormBackward0]
	140309917380464 -> 140309917380224
	140309917380464 [label=ConvolutionBackward0]
	140309917380560 -> 140309917380464
	140309917380560 [label=ReluBackward0]
	140309915443456 -> 140309917380560
	140309915443456 [label=NativeBatchNormBackward0]
	140309915443504 -> 140309915443456
	140309915443504 [label=ConvolutionBackward0]
	140309917379984 -> 140309915443504
	140309917379984 [label=ReluBackward0]
	140309915443888 -> 140309917379984
	140309915443888 [label=AddBackward0]
	140309915443936 -> 140309915443888
	140309915443936 [label=NativeBatchNormBackward0]
	140309915444176 -> 140309915443936
	140309915444176 [label=ConvolutionBackward0]
	140309915444368 -> 140309915444176
	140309915444368 [label=ReluBackward0]
	140309915444512 -> 140309915444368
	140309915444512 [label=NativeBatchNormBackward0]
	140309915444560 -> 140309915444512
	140309915444560 [label=ConvolutionBackward0]
	140309915443696 -> 140309915444560
	140309915443696 [label=ReluBackward0]
	140309915444944 -> 140309915443696
	140309915444944 [label=AddBackward0]
	140309915444992 -> 140309915444944
	140309915444992 [label=ReluBackward0]
	140309915445232 -> 140309915444992
	140309915445232 [label=AddBackward0]
	140309915445280 -> 140309915445232
	140309915445280 [label=NativeBatchNormBackward0]
	140309915445520 -> 140309915445280
	140309915445520 [label=ConvolutionBackward0]
	140309915445712 -> 140309915445520
	140309915445712 [label=ReluBackward0]
	140309915445856 -> 140309915445712
	140309915445856 [label=NativeBatchNormBackward0]
	140309915445760 -> 140309915445856
	140309915445760 [label=ConvolutionBackward0]
	140309915445136 -> 140309915445760
	140309915445136 [label=ReluBackward0]
	140309915446336 -> 140309915445136
	140309915446336 [label=AddBackward0]
	140309915446384 -> 140309915446336
	140309915446384 [label=NativeBatchNormBackward0]
	140309915446624 -> 140309915446384
	140309915446624 [label=ConvolutionBackward0]
	140309915446816 -> 140309915446624
	140309915446816 [label=ReluBackward0]
	140309915446960 -> 140309915446816
	140309915446960 [label=NativeBatchNormBackward0]
	140309915447008 -> 140309915446960
	140309915447008 [label=ConvolutionBackward0]
	140309915446144 -> 140309915447008
	140309915446144 [label=ReluBackward0]
	140309915431072 -> 140309915446144
	140309915431072 [label=AddBackward0]
	140309915431120 -> 140309915431072
	140309915431120 [label=NativeBatchNormBackward0]
	140309915431360 -> 140309915431120
	140309915431360 [label=ConvolutionBackward0]
	140309915431552 -> 140309915431360
	140309915431552 [label=ReluBackward0]
	140309915431696 -> 140309915431552
	140309915431696 [label=NativeBatchNormBackward0]
	140309915431744 -> 140309915431696
	140309915431744 [label=ConvolutionBackward0]
	140309915430976 -> 140309915431744
	140309915430976 [label=ReluBackward0]
	140309915432128 -> 140309915430976
	140309915432128 [label=AddBackward0]
	140309915432176 -> 140309915432128
	140309915432176 [label=NativeBatchNormBackward0]
	140309915432416 -> 140309915432176
	140309915432416 [label=ConvolutionBackward0]
	140309915432608 -> 140309915432416
	140309915432608 [label=ReluBackward0]
	140309915432752 -> 140309915432608
	140309915432752 [label=NativeBatchNormBackward0]
	140309915432800 -> 140309915432752
	140309915432800 [label=ConvolutionBackward0]
	140309915431936 -> 140309915432800
	140309915431936 [label=ReluBackward0]
	140309915433184 -> 140309915431936
	140309915433184 [label=NativeBatchNormBackward0]
	140309915433232 -> 140309915433184
	140309915433232 [label=ConvolutionBackward0]
	140309915433520 -> 140309915433232
	140309915433520 [label=ReluBackward0]
	140309915433664 -> 140309915433520
	140309915433664 [label=AddBackward0]
	140309915433712 -> 140309915433664
	140309915433712 [label=NativeBatchNormBackward0]
	140309915433952 -> 140309915433712
	140309915433952 [label=ConvolutionBackward0]
	140309915434144 -> 140309915433952
	140309915434144 [label=ReluBackward0]
	140309915434288 -> 140309915434144
	140309915434288 [label=NativeBatchNormBackward0]
	140309915434336 -> 140309915434288
	140309915434336 [label=ConvolutionBackward0]
	140309915434624 -> 140309915434336
	140309915434624 [label=ReluBackward0]
	140309915434768 -> 140309915434624
	140309915434768 [label=NativeBatchNormBackward0]
	140309915434816 -> 140309915434768
	140309915434816 [label=ConvolutionBackward0]
	140309915433568 -> 140309915434816
	140309915433568 [label=ReluBackward0]
	140309915422976 -> 140309915433568
	140309915422976 [label=AddBackward0]
	140309915423024 -> 140309915422976
	140309915423024 [label=NativeBatchNormBackward0]
	140309915423264 -> 140309915423024
	140309915423264 [label=ConvolutionBackward0]
	140309915423456 -> 140309915423264
	140309915423456 [label=ReluBackward0]
	140309915423600 -> 140309915423456
	140309915423600 [label=NativeBatchNormBackward0]
	140309915423648 -> 140309915423600
	140309915423648 [label=ConvolutionBackward0]
	140309915423936 -> 140309915423648
	140309915423936 [label=ReluBackward0]
	140309915424080 -> 140309915423936
	140309915424080 [label=NativeBatchNormBackward0]
	140309915424128 -> 140309915424080
	140309915424128 [label=ConvolutionBackward0]
	140309915422880 -> 140309915424128
	140309915422880 [label=ReluBackward0]
	140309915424512 -> 140309915422880
	140309915424512 [label=AddBackward0]
	140309915424560 -> 140309915424512
	140309915424560 [label=NativeBatchNormBackward0]
	140309915424800 -> 140309915424560
	140309915424800 [label=ConvolutionBackward0]
	140309915424992 -> 140309915424800
	140309915424992 [label=ReluBackward0]
	140309915425136 -> 140309915424992
	140309915425136 [label=NativeBatchNormBackward0]
	140309915425184 -> 140309915425136
	140309915425184 [label=ConvolutionBackward0]
	140309915425472 -> 140309915425184
	140309915425472 [label=ReluBackward0]
	140309915425616 -> 140309915425472
	140309915425616 [label=NativeBatchNormBackward0]
	140309915425664 -> 140309915425616
	140309915425664 [label=ConvolutionBackward0]
	140309915424320 -> 140309915425664
	140309915424320 [label=ReluBackward0]
	140309915426048 -> 140309915424320
	140309915426048 [label=AddBackward0]
	140309915426096 -> 140309915426048
	140309915426096 [label=NativeBatchNormBackward0]
	140309915426336 -> 140309915426096
	140309915426336 [label=ConvolutionBackward0]
	140309915426528 -> 140309915426336
	140309915426528 [label=ReluBackward0]
	140309915426672 -> 140309915426528
	140309915426672 [label=NativeBatchNormBackward0]
	140309915426720 -> 140309915426672
	140309915426720 [label=ConvolutionBackward0]
	140309915275520 -> 140309915426720
	140309915275520 [label=ReluBackward0]
	140309915275664 -> 140309915275520
	140309915275664 [label=NativeBatchNormBackward0]
	140309915275712 -> 140309915275664
	140309915275712 [label=ConvolutionBackward0]
	140309915276000 -> 140309915275712
	140309915276000 [label=ReluBackward0]
	140309915276144 -> 140309915276000
	140309915276144 [label=NativeBatchNormBackward0]
	140309915276192 -> 140309915276144
	140309915276192 [label=ConvolutionBackward0]
	140309915276480 -> 140309915276192
	140309915276480 [label=ReluBackward0]
	140309915276624 -> 140309915276480
	140309915276624 [label=NativeBatchNormBackward0]
	140309915276672 -> 140309915276624
	140309915276672 [label=ConvolutionBackward0]
	140309915276960 -> 140309915276672
	140309915010048 [label="conv1.weight
 (64, 3, 3, 3)" fillcolor=lightblue]
	140309915010048 -> 140309915276960
	140309915276960 [label=AccumulateGrad]
	140309915276528 -> 140309915276624
	140309915010128 [label="bn1.weight
 (64)" fillcolor=lightblue]
	140309915010128 -> 140309915276528
	140309915276528 [label=AccumulateGrad]
	140309915276768 -> 140309915276624
	140309915010208 [label="bn1.bias
 (64)" fillcolor=lightblue]
	140309915010208 -> 140309915276768
	140309915276768 [label=AccumulateGrad]
	140309915276432 -> 140309915276192
	140309915010768 [label="conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140309915010768 -> 140309915276432
	140309915276432 [label=AccumulateGrad]
	140309915276048 -> 140309915276144
	140309915010848 [label="bn2.weight
 (64)" fillcolor=lightblue]
	140309915010848 -> 140309915276048
	140309915276048 [label=AccumulateGrad]
	140309915276288 -> 140309915276144
	140309915010928 [label="bn2.bias
 (64)" fillcolor=lightblue]
	140309915010928 -> 140309915276288
	140309915276288 [label=AccumulateGrad]
	140309915275952 -> 140309915275712
	140309915011888 [label="layer1.0.conv1.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	140309915011888 -> 140309915275952
	140309915275952 [label=AccumulateGrad]
	140309915275568 -> 140309915275664
	140309915011968 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	140309915011968 -> 140309915275568
	140309915275568 [label=AccumulateGrad]
	140309915275808 -> 140309915275664
	140309915012048 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	140309915012048 -> 140309915275808
	140309915275808 [label=AccumulateGrad]
	140309915275472 -> 140309915426720
	140309915012528 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140309915012528 -> 140309915275472
	140309915275472 [label=AccumulateGrad]
	140309915426576 -> 140309915426672
	140309915012448 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	140309915012448 -> 140309915426576
	140309915426576 [label=AccumulateGrad]
	140309915275328 -> 140309915426672
	140309915012608 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	140309915012608 -> 140309915275328
	140309915275328 [label=AccumulateGrad]
	140309915426480 -> 140309915426336
	140309915013008 [label="layer1.0.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140309915013008 -> 140309915426480
	140309915426480 [label=AccumulateGrad]
	140309915426288 -> 140309915426096
	140310420213824 [label="layer1.0.bn3.weight
 (256)" fillcolor=lightblue]
	140310420213824 -> 140309915426288
	140309915426288 [label=AccumulateGrad]
	140309915426240 -> 140309915426096
	140310420213904 [label="layer1.0.bn3.bias
 (256)" fillcolor=lightblue]
	140310420213904 -> 140309915426240
	140309915426240 [label=AccumulateGrad]
	140309915425856 -> 140309915426048
	140309915425856 [label=NativeBatchNormBackward0]
	140309915426624 -> 140309915425856
	140309915426624 [label=ConvolutionBackward0]
	140309915276000 -> 140309915426624
	140309915275856 -> 140309915426624
	140309915011328 [label="layer1.0.downsample.0.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140309915011328 -> 140309915275856
	140309915275856 [label=AccumulateGrad]
	140309915426432 -> 140309915425856
	140309915011408 [label="layer1.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	140309915011408 -> 140309915426432
	140309915426432 [label=AccumulateGrad]
	140309915426384 -> 140309915425856
	140309915011488 [label="layer1.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	140309915011488 -> 140309915426384
	140309915426384 [label=AccumulateGrad]
	140309915425952 -> 140309915425664
	140310420214304 [label="layer1.1.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	140310420214304 -> 140309915425952
	140309915425952 [label=AccumulateGrad]
	140309915425520 -> 140309915425616
	140310420214384 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	140310420214384 -> 140309915425520
	140309915425520 [label=AccumulateGrad]
	140309915425760 -> 140309915425616
	140310420214464 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	140310420214464 -> 140309915425760
	140309915425760 [label=AccumulateGrad]
	140309915425424 -> 140309915425184
	140310420214944 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140310420214944 -> 140309915425424
	140309915425424 [label=AccumulateGrad]
	140309915425040 -> 140309915425136
	140310420214864 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	140310420214864 -> 140309915425040
	140309915425040 [label=AccumulateGrad]
	140309915425280 -> 140309915425136
	140310420215024 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	140310420215024 -> 140309915425280
	140309915425280 [label=AccumulateGrad]
	140309915424944 -> 140309915424800
	140310420215424 [label="layer1.1.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140310420215424 -> 140309915424944
	140309915424944 [label=AccumulateGrad]
	140309915424752 -> 140309915424560
	140310420215504 [label="layer1.1.bn3.weight
 (256)" fillcolor=lightblue]
	140310420215504 -> 140309915424752
	140309915424752 [label=AccumulateGrad]
	140309915424704 -> 140309915424560
	140310420215584 [label="layer1.1.bn3.bias
 (256)" fillcolor=lightblue]
	140310420215584 -> 140309915424704
	140309915424704 [label=AccumulateGrad]
	140309915424320 -> 140309915424512
	140309915424416 -> 140309915424128
	140310420215984 [label="layer1.2.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	140310420215984 -> 140309915424416
	140309915424416 [label=AccumulateGrad]
	140309915423984 -> 140309915424080
	140310420216064 [label="layer1.2.bn1.weight
 (64)" fillcolor=lightblue]
	140310420216064 -> 140309915423984
	140309915423984 [label=AccumulateGrad]
	140309915424224 -> 140309915424080
	140310420216144 [label="layer1.2.bn1.bias
 (64)" fillcolor=lightblue]
	140310420216144 -> 140309915424224
	140309915424224 [label=AccumulateGrad]
	140309915423888 -> 140309915423648
	140310420216624 [label="layer1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140310420216624 -> 140309915423888
	140309915423888 [label=AccumulateGrad]
	140309915423504 -> 140309915423600
	140310420216544 [label="layer1.2.bn2.weight
 (64)" fillcolor=lightblue]
	140310420216544 -> 140309915423504
	140309915423504 [label=AccumulateGrad]
	140309915423744 -> 140309915423600
	140310420216704 [label="layer1.2.bn2.bias
 (64)" fillcolor=lightblue]
	140310420216704 -> 140309915423744
	140309915423744 [label=AccumulateGrad]
	140309915423408 -> 140309915423264
	140310420217104 [label="layer1.2.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140310420217104 -> 140309915423408
	140309915423408 [label=AccumulateGrad]
	140309915423216 -> 140309915423024
	140310420217184 [label="layer1.2.bn3.weight
 (256)" fillcolor=lightblue]
	140310420217184 -> 140309915423216
	140309915423216 [label=AccumulateGrad]
	140309915423168 -> 140309915423024
	140310420217264 [label="layer1.2.bn3.bias
 (256)" fillcolor=lightblue]
	140310420217264 -> 140309915423168
	140309915423168 [label=AccumulateGrad]
	140309915422880 -> 140309915422976
	140309915422784 -> 140309915434816
	140310420217664 [label="layer1.3.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	140310420217664 -> 140309915422784
	140309915422784 [label=AccumulateGrad]
	140309915434672 -> 140309915434768
	140310420217744 [label="layer1.3.bn1.weight
 (64)" fillcolor=lightblue]
	140310420217744 -> 140309915434672
	140309915434672 [label=AccumulateGrad]
	140309915434912 -> 140309915434768
	140310420320320 [label="layer1.3.bn1.bias
 (64)" fillcolor=lightblue]
	140310420320320 -> 140309915434912
	140309915434912 [label=AccumulateGrad]
	140309915434576 -> 140309915434336
	140310420320800 [label="layer1.3.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140310420320800 -> 140309915434576
	140309915434576 [label=AccumulateGrad]
	140309915434192 -> 140309915434288
	140310420320720 [label="layer1.3.bn2.weight
 (64)" fillcolor=lightblue]
	140310420320720 -> 140309915434192
	140309915434192 [label=AccumulateGrad]
	140309915434432 -> 140309915434288
	140310420320880 [label="layer1.3.bn2.bias
 (64)" fillcolor=lightblue]
	140310420320880 -> 140309915434432
	140309915434432 [label=AccumulateGrad]
	140309915434096 -> 140309915433952
	140310420321280 [label="layer1.3.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140310420321280 -> 140309915434096
	140309915434096 [label=AccumulateGrad]
	140309915433904 -> 140309915433712
	140310420321360 [label="layer1.3.bn3.weight
 (256)" fillcolor=lightblue]
	140310420321360 -> 140309915433904
	140309915433904 [label=AccumulateGrad]
	140309915433856 -> 140309915433712
	140310420321440 [label="layer1.3.bn3.bias
 (256)" fillcolor=lightblue]
	140310420321440 -> 140309915433856
	140309915433856 [label=AccumulateGrad]
	140309915433568 -> 140309915433664
	140309915433472 -> 140309915433232
	140310420321840 [label="transition1.0.0.weight
 (18, 256, 3, 3)" fillcolor=lightblue]
	140310420321840 -> 140309915433472
	140309915433472 [label=AccumulateGrad]
	140309915432992 -> 140309915433184
	140310420321920 [label="transition1.0.1.weight
 (18)" fillcolor=lightblue]
	140310420321920 -> 140309915432992
	140309915432992 [label=AccumulateGrad]
	140309915433328 -> 140309915433184
	140310420322000 [label="transition1.0.1.bias
 (18)" fillcolor=lightblue]
	140310420322000 -> 140309915433328
	140309915433328 [label=AccumulateGrad]
	140309915433088 -> 140309915432800
	140310420322960 [label="stage2.0.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310420322960 -> 140309915433088
	140309915433088 [label=AccumulateGrad]
	140309915432656 -> 140309915432752
	140310420323040 [label="stage2.0.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140310420323040 -> 140309915432656
	140309915432656 [label=AccumulateGrad]
	140309915432896 -> 140309915432752
	140310420323120 [label="stage2.0.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140310420323120 -> 140309915432896
	140309915432896 [label=AccumulateGrad]
	140309915432560 -> 140309915432416
	140310420323520 [label="stage2.0.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310420323520 -> 140309915432560
	140309915432560 [label=AccumulateGrad]
	140309915432368 -> 140309915432176
	140310420323600 [label="stage2.0.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140310420323600 -> 140309915432368
	140309915432368 [label=AccumulateGrad]
	140309915432320 -> 140309915432176
	140310420323680 [label="stage2.0.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140310420323680 -> 140309915432320
	140309915432320 [label=AccumulateGrad]
	140309915431936 -> 140309915432128
	140309915432032 -> 140309915431744
	140310420324080 [label="stage2.0.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310420324080 -> 140309915432032
	140309915432032 [label=AccumulateGrad]
	140309915431600 -> 140309915431696
	140310420324160 [label="stage2.0.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140310420324160 -> 140309915431600
	140309915431600 [label=AccumulateGrad]
	140309915431840 -> 140309915431696
	140310420324240 [label="stage2.0.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140310420324240 -> 140309915431840
	140309915431840 [label=AccumulateGrad]
	140309915431504 -> 140309915431360
	140310422049152 [label="stage2.0.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310422049152 -> 140309915431504
	140309915431504 [label=AccumulateGrad]
	140309915431312 -> 140309915431120
	140310422049232 [label="stage2.0.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140310422049232 -> 140309915431312
	140309915431312 [label=AccumulateGrad]
	140309915431264 -> 140309915431120
	140310422049312 [label="stage2.0.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140310422049312 -> 140309915431264
	140309915431264 [label=AccumulateGrad]
	140309915430976 -> 140309915431072
	140309915447248 -> 140309915447008
	140310422049712 [label="stage2.0.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310422049712 -> 140309915447248
	140309915447248 [label=AccumulateGrad]
	140309915446864 -> 140309915446960
	140310422049792 [label="stage2.0.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140310422049792 -> 140309915446864
	140309915446864 [label=AccumulateGrad]
	140309915447104 -> 140309915446960
	140310422049872 [label="stage2.0.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140310422049872 -> 140309915447104
	140309915447104 [label=AccumulateGrad]
	140309915446768 -> 140309915446624
	140310422050272 [label="stage2.0.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310422050272 -> 140309915446768
	140309915446768 [label=AccumulateGrad]
	140309915446576 -> 140309915446384
	140310422050352 [label="stage2.0.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140310422050352 -> 140309915446576
	140309915446576 [label=AccumulateGrad]
	140309915446528 -> 140309915446384
	140310422050432 [label="stage2.0.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140310422050432 -> 140309915446528
	140309915446528 [label=AccumulateGrad]
	140309915446144 -> 140309915446336
	140309915446240 -> 140309915445760
	140310422050832 [label="stage2.0.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310422050832 -> 140309915446240
	140309915446240 [label=AccumulateGrad]
	140309915446000 -> 140309915445856
	140310422050912 [label="stage2.0.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140310422050912 -> 140309915446000
	140309915446000 [label=AccumulateGrad]
	140309915446048 -> 140309915445856
	140310422050992 [label="stage2.0.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140310422050992 -> 140309915446048
	140309915446048 [label=AccumulateGrad]
	140309915445664 -> 140309915445520
	140310422051392 [label="stage2.0.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310422051392 -> 140309915445664
	140309915445664 [label=AccumulateGrad]
	140309915445472 -> 140309915445280
	140310422051472 [label="stage2.0.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140310422051472 -> 140309915445472
	140309915445472 [label=AccumulateGrad]
	140309915445424 -> 140309915445280
	140310422051552 [label="stage2.0.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140310422051552 -> 140309915445424
	140309915445424 [label=AccumulateGrad]
	140309915445136 -> 140309915445232
	140309915444752 -> 140309915444944
	140309915444752 [label=UpsampleNearest2DBackward1]
	140309915445568 -> 140309915444752
	140309915445568 [label=NativeBatchNormBackward0]
	140309915446192 -> 140309915445568
	140309915446192 [label=ConvolutionBackward0]
	140309915446480 -> 140309915446192
	140309915446480 [label=ReluBackward0]
	140309915447200 -> 140309915446480
	140309915447200 [label=AddBackward0]
	140309915446912 -> 140309915447200
	140309915446912 [label=NativeBatchNormBackward0]
	140309915431024 -> 140309915446912
	140309915431024 [label=ConvolutionBackward0]
	140309915431648 -> 140309915431024
	140309915431648 [label=ReluBackward0]
	140309915432080 -> 140309915431648
	140309915432080 [label=NativeBatchNormBackward0]
	140309915433040 -> 140309915432080
	140309915433040 [label=ConvolutionBackward0]
	140309915447152 -> 140309915433040
	140309915447152 [label=ReluBackward0]
	140309915434000 -> 140309915447152
	140309915434000 [label=AddBackward0]
	140309915433616 -> 140309915434000
	140309915433616 [label=NativeBatchNormBackward0]
	140309915434480 -> 140309915433616
	140309915434480 [label=ConvolutionBackward0]
	140309915434720 -> 140309915434480
	140309915434720 [label=ReluBackward0]
	140309915422928 -> 140309915434720
	140309915422928 [label=NativeBatchNormBackward0]
	140309915423840 -> 140309915422928
	140309915423840 [label=ConvolutionBackward0]
	140309915433808 -> 140309915423840
	140309915433808 [label=ReluBackward0]
	140309915424848 -> 140309915433808
	140309915424848 [label=AddBackward0]
	140309915424464 -> 140309915424848
	140309915424464 [label=NativeBatchNormBackward0]
	140309915425328 -> 140309915424464
	140309915425328 [label=ConvolutionBackward0]
	140309915425568 -> 140309915425328
	140309915425568 [label=ReluBackward0]
	140309915426000 -> 140309915425568
	140309915426000 [label=NativeBatchNormBackward0]
	140309915276384 -> 140309915426000
	140309915276384 [label=ConvolutionBackward0]
	140309915424656 -> 140309915276384
	140309915424656 [label=ReluBackward0]
	140309915276816 -> 140309915424656
	140309915276816 [label=AddBackward0]
	140309915277200 -> 140309915276816
	140309915277200 [label=NativeBatchNormBackward0]
	140309915277248 -> 140309915277200
	140309915277248 [label=ConvolutionBackward0]
	140309915277440 -> 140309915277248
	140309915277440 [label=ReluBackward0]
	140309915277584 -> 140309915277440
	140309915277584 [label=NativeBatchNormBackward0]
	140309915277680 -> 140309915277584
	140309915277680 [label=ConvolutionBackward0]
	140309915276576 -> 140309915277680
	140309915276576 [label=ReluBackward0]
	140309915277968 -> 140309915276576
	140309915277968 [label=NativeBatchNormBackward0]
	140309915278112 -> 140309915277968
	140309915278112 [label=ConvolutionBackward0]
	140309915433520 -> 140309915278112
	140309915278304 -> 140309915278112
	140310420322400 [label="transition1.1.0.0.weight
 (36, 256, 3, 3)" fillcolor=lightblue]
	140310420322400 -> 140309915278304
	140309915278304 [label=AccumulateGrad]
	140309915278064 -> 140309915277968
	140310420322480 [label="transition1.1.0.1.weight
 (36)" fillcolor=lightblue]
	140310420322480 -> 140309915278064
	140309915278064 [label=AccumulateGrad]
	140309915278016 -> 140309915277968
	140310420322560 [label="transition1.1.0.1.bias
 (36)" fillcolor=lightblue]
	140310420322560 -> 140309915278016
	140309915278016 [label=AccumulateGrad]
	140309915277872 -> 140309915277680
	140310422051952 [label="stage2.0.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310422051952 -> 140309915277872
	140309915277872 [label=AccumulateGrad]
	140309915277632 -> 140309915277584
	140310422052032 [label="stage2.0.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140310422052032 -> 140309915277632
	140309915277632 [label=AccumulateGrad]
	140309915277488 -> 140309915277584
	140310422052112 [label="stage2.0.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140310422052112 -> 140309915277488
	140309915277488 [label=AccumulateGrad]
	140309915277392 -> 140309915277248
	140310422052512 [label="stage2.0.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310422052512 -> 140309915277392
	140309915277392 [label=AccumulateGrad]
	140309915277104 -> 140309915277200
	140310422052592 [label="stage2.0.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140310422052592 -> 140309915277104
	140309915277104 [label=AccumulateGrad]
	140309915277152 -> 140309915277200
	140310422052672 [label="stage2.0.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140310422052672 -> 140309915277152
	140309915277152 [label=AccumulateGrad]
	140309915276576 -> 140309915276816
	140309915276096 -> 140309915276384
	140310422180144 [label="stage2.0.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310422180144 -> 140309915276096
	140309915276096 [label=AccumulateGrad]
	140309915275904 -> 140309915426000
	140310422180224 [label="stage2.0.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140310422180224 -> 140309915275904
	140309915275904 [label=AccumulateGrad]
	140309915275424 -> 140309915426000
	140310422180304 [label="stage2.0.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140310422180304 -> 140309915275424
	140309915275424 [label=AccumulateGrad]
	140309915425808 -> 140309915425328
	140310422180704 [label="stage2.0.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310422180704 -> 140309915425808
	140309915425808 [label=AccumulateGrad]
	140309915425376 -> 140309915424464
	140310422180784 [label="stage2.0.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140310422180784 -> 140309915425376
	140309915425376 [label=AccumulateGrad]
	140309915424896 -> 140309915424464
	140310422180864 [label="stage2.0.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140310422180864 -> 140309915424896
	140309915424896 [label=AccumulateGrad]
	140309915424656 -> 140309915424848
	140309915424272 -> 140309915423840
	140310422181264 [label="stage2.0.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310422181264 -> 140309915424272
	140309915424272 [label=AccumulateGrad]
	140309915423360 -> 140309915422928
	140310422181344 [label="stage2.0.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140310422181344 -> 140309915423360
	140309915423360 [label=AccumulateGrad]
	140309915423312 -> 140309915422928
	140310422181424 [label="stage2.0.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140310422181424 -> 140309915423312
	140309915423312 [label=AccumulateGrad]
	140309915434960 -> 140309915434480
	140310422181824 [label="stage2.0.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310422181824 -> 140309915434960
	140309915434960 [label=AccumulateGrad]
	140309915434528 -> 140309915433616
	140310422181904 [label="stage2.0.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140310422181904 -> 140309915434528
	140309915434528 [label=AccumulateGrad]
	140309915434048 -> 140309915433616
	140310422181984 [label="stage2.0.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140310422181984 -> 140309915434048
	140309915434048 [label=AccumulateGrad]
	140309915433808 -> 140309915434000
	140309915433376 -> 140309915433040
	140310422182384 [label="stage2.0.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310422182384 -> 140309915433376
	140309915433376 [label=AccumulateGrad]
	140309915432512 -> 140309915432080
	140310422182464 [label="stage2.0.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140310422182464 -> 140309915432512
	140309915432512 [label=AccumulateGrad]
	140309915432464 -> 140309915432080
	140310422182544 [label="stage2.0.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140310422182544 -> 140309915432464
	140309915432464 [label=AccumulateGrad]
	140309915431888 -> 140309915431024
	140310422182944 [label="stage2.0.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310422182944 -> 140309915431888
	140309915431888 [label=AccumulateGrad]
	140309915431216 -> 140309915446912
	140310422183024 [label="stage2.0.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140310422183024 -> 140309915431216
	140309915431216 [label=AccumulateGrad]
	140309915431408 -> 140309915446912
	140310422183104 [label="stage2.0.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140310422183104 -> 140309915431408
	140309915431408 [label=AccumulateGrad]
	140309915447152 -> 140309915447200
	140309915446672 -> 140309915446192
	140310422183504 [label="stage2.0.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140310422183504 -> 140309915446672
	140309915446672 [label=AccumulateGrad]
	140309915445616 -> 140309915445568
	140310422183584 [label="stage2.0.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140310422183584 -> 140309915445616
	140309915445616 [label=AccumulateGrad]
	140309915445184 -> 140309915445568
	140310422183664 [label="stage2.0.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140310422183664 -> 140309915445184
	140309915445184 [label=AccumulateGrad]
	140309915444848 -> 140309915444560
	140310422836544 [label="stage3.0.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310422836544 -> 140309915444848
	140309915444848 [label=AccumulateGrad]
	140309915444416 -> 140309915444512
	140310422836624 [label="stage3.0.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140310422836624 -> 140309915444416
	140309915444416 [label=AccumulateGrad]
	140309915444656 -> 140309915444512
	140310422836704 [label="stage3.0.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140310422836704 -> 140309915444656
	140309915444656 [label=AccumulateGrad]
	140309915444320 -> 140309915444176
	140310422837104 [label="stage3.0.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310422837104 -> 140309915444320
	140309915444320 [label=AccumulateGrad]
	140309915444128 -> 140309915443936
	140310422837184 [label="stage3.0.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140310422837184 -> 140309915444128
	140309915444128 [label=AccumulateGrad]
	140309915444080 -> 140309915443936
	140310422837264 [label="stage3.0.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140310422837264 -> 140309915444080
	140309915444080 [label=AccumulateGrad]
	140309915443696 -> 140309915443888
	140309915443792 -> 140309915443504
	140310422837664 [label="stage3.0.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310422837664 -> 140309915443792
	140309915443792 [label=AccumulateGrad]
	140309915443360 -> 140309915443456
	140310422837744 [label="stage3.0.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140310422837744 -> 140309915443360
	140309915443360 [label=AccumulateGrad]
	140309915443600 -> 140309915443456
	140310422837824 [label="stage3.0.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140310422837824 -> 140309915443600
	140309915443600 [label=AccumulateGrad]
	140309915443312 -> 140309917380464
	140310422838224 [label="stage3.0.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310422838224 -> 140309915443312
	140309915443312 [label=AccumulateGrad]
	140309917380416 -> 140309917380224
	140310422838304 [label="stage3.0.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140310422838304 -> 140309917380416
	140309917380416 [label=AccumulateGrad]
	140309917380368 -> 140309917380224
	140310422838384 [label="stage3.0.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140310422838384 -> 140309917380368
	140309917380368 [label=AccumulateGrad]
	140309917379984 -> 140309917380176
	140309917380080 -> 140309917379792
	140310422838784 [label="stage3.0.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310422838784 -> 140309917380080
	140309917380080 [label=AccumulateGrad]
	140309917379648 -> 140309917379744
	140310422838864 [label="stage3.0.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140310422838864 -> 140309917379648
	140309917379648 [label=AccumulateGrad]
	140309917379888 -> 140309917379744
	140310422838944 [label="stage3.0.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140310422838944 -> 140309917379888
	140309917379888 [label=AccumulateGrad]
	140309917379552 -> 140309917379408
	140310422990992 [label="stage3.0.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310422990992 -> 140309917379552
	140309917379552 [label=AccumulateGrad]
	140309917379360 -> 140309917379168
	140310422991072 [label="stage3.0.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140310422991072 -> 140309917379360
	140309917379360 [label=AccumulateGrad]
	140309917379312 -> 140309917379168
	140310422991152 [label="stage3.0.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140310422991152 -> 140309917379312
	140309917379312 [label=AccumulateGrad]
	140309917378928 -> 140309917379120
	140309917379024 -> 140309917378736
	140310422991552 [label="stage3.0.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310422991552 -> 140309917379024
	140309917379024 [label=AccumulateGrad]
	140309917378592 -> 140309917378688
	140310422991632 [label="stage3.0.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140310422991632 -> 140309917378592
	140309917378592 [label=AccumulateGrad]
	140309917378832 -> 140309917378688
	140310422991712 [label="stage3.0.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140310422991712 -> 140309917378832
	140309917378832 [label=AccumulateGrad]
	140309917378496 -> 140309917378352
	140310422992112 [label="stage3.0.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310422992112 -> 140309917378496
	140309917378496 [label=AccumulateGrad]
	140309917378304 -> 140309917378112
	140310422992192 [label="stage3.0.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140310422992192 -> 140309917378304
	140309917378304 [label=AccumulateGrad]
	140309917378256 -> 140309917378112
	140310422992272 [label="stage3.0.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140310422992272 -> 140309917378256
	140309917378256 [label=AccumulateGrad]
	140309917377968 -> 140309917378064
	140309917377872 -> 140309917377680
	140309917377872 [label=UpsampleNearest2DBackward1]
	140309917378400 -> 140309917377872
	140309917378400 [label=NativeBatchNormBackward0]
	140309917378976 -> 140309917378400
	140309917378976 [label=ConvolutionBackward0]
	140309917379264 -> 140309917378976
	140309917379264 [label=ReluBackward0]
	140309917380032 -> 140309917379264
	140309917380032 [label=AddBackward0]
	140309917379696 -> 140309917380032
	140309917379696 [label=NativeBatchNormBackward0]
	140309917380128 -> 140309917379696
	140309917380128 [label=ConvolutionBackward0]
	140309915443408 -> 140309917380128
	140309915443408 [label=ReluBackward0]
	140309915443840 -> 140309915443408
	140309915443840 [label=NativeBatchNormBackward0]
	140309915444800 -> 140309915443840
	140309915444800 [label=ConvolutionBackward0]
	140309917379936 -> 140309915444800
	140309917379936 [label=ReluBackward0]
	140309915446096 -> 140309917379936
	140309915446096 [label=AddBackward0]
	140309915446288 -> 140309915446096
	140309915446288 [label=NativeBatchNormBackward0]
	140309915446720 -> 140309915446288
	140309915446720 [label=ConvolutionBackward0]
	140309915434240 -> 140309915446720
	140309915434240 [label=ReluBackward0]
	140309915433136 -> 140309915434240
	140309915433136 [label=NativeBatchNormBackward0]
	140309915423792 -> 140309915433136
	140309915423792 [label=ConvolutionBackward0]
	140309915445808 -> 140309915423792
	140309915445808 [label=ReluBackward0]
	140309915426192 -> 140309915445808
	140309915426192 [label=AddBackward0]
	140309915425088 -> 140309915426192
	140309915425088 [label=NativeBatchNormBackward0]
	140309915276912 -> 140309915425088
	140309915276912 [label=ConvolutionBackward0]
	140309915277536 -> 140309915276912
	140309915277536 [label=ReluBackward0]
	140309915277920 -> 140309915277536
	140309915277920 [label=NativeBatchNormBackward0]
	140309915278352 -> 140309915277920
	140309915278352 [label=ConvolutionBackward0]
	140309915275616 -> 140309915278352
	140309915275616 [label=ReluBackward0]
	140309915278640 -> 140309915275616
	140309915278640 [label=AddBackward0]
	140309915278736 -> 140309915278640
	140309915278736 [label=NativeBatchNormBackward0]
	140309915278880 -> 140309915278736
	140309915278880 [label=ConvolutionBackward0]
	140309915279072 -> 140309915278880
	140309915279072 [label=ReluBackward0]
	140309915279216 -> 140309915279072
	140309915279216 [label=NativeBatchNormBackward0]
	140309915279312 -> 140309915279216
	140309915279312 [label=ConvolutionBackward0]
	140309915278688 -> 140309915279312
	140309915278688 [label=ReluBackward0]
	140309915341104 -> 140309915278688
	140309915341104 [label=AddBackward0]
	140309915341200 -> 140309915341104
	140309915341200 [label=NativeBatchNormBackward0]
	140309915341296 -> 140309915341200
	140309915341296 [label=ConvolutionBackward0]
	140309915444992 -> 140309915341296
	140309915341488 -> 140309915341296
	140310422835424 [label="stage2.0.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140310422835424 -> 140309915341488
	140309915341488 [label=AccumulateGrad]
	140309915341248 -> 140309915341200
	140310422835504 [label="stage2.0.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140310422835504 -> 140309915341248
	140309915341248 [label=AccumulateGrad]
	140309915340912 -> 140309915341200
	140310422835584 [label="stage2.0.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140310422835584 -> 140309915340912
	140309915340912 [label=AccumulateGrad]
	140309915446480 -> 140309915341104
	140309915341008 -> 140309915279312
	140310422992672 [label="stage3.0.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310422992672 -> 140309915341008
	140309915341008 [label=AccumulateGrad]
	140309915279264 -> 140309915279216
	140310422992752 [label="stage3.0.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140310422992752 -> 140309915279264
	140309915279264 [label=AccumulateGrad]
	140309915279120 -> 140309915279216
	140310422992832 [label="stage3.0.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140310422992832 -> 140309915279120
	140309915279120 [label=AccumulateGrad]
	140309915279024 -> 140309915278880
	140310422993232 [label="stage3.0.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310422993232 -> 140309915279024
	140309915279024 [label=AccumulateGrad]
	140309915278832 -> 140309915278736
	140310422993312 [label="stage3.0.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140310422993312 -> 140309915278832
	140309915278832 [label=AccumulateGrad]
	140309915278784 -> 140309915278736
	140310422993392 [label="stage3.0.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140310422993392 -> 140309915278784
	140309915278784 [label=AccumulateGrad]
	140309915278688 -> 140309915278640
	140309915278544 -> 140309915278352
	140310422993792 [label="stage3.0.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310422993792 -> 140309915278544
	140309915278544 [label=AccumulateGrad]
	140309915278400 -> 140309915277920
	140310422993872 [label="stage3.0.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140310422993872 -> 140309915278400
	140309915278400 [label=AccumulateGrad]
	140309915278256 -> 140309915277920
	140310422993952 [label="stage3.0.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140310422993952 -> 140309915278256
	140309915278256 [label=AccumulateGrad]
	140309915277728 -> 140309915276912
	140310422994352 [label="stage3.0.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310422994352 -> 140309915277728
	140309915277728 [label=AccumulateGrad]
	140309915275376 -> 140309915425088
	140310422994432 [label="stage3.0.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140310422994432 -> 140309915275376
	140309915275376 [label=AccumulateGrad]
	140309915277296 -> 140309915425088
	140310422994512 [label="stage3.0.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140310422994512 -> 140309915277296
	140309915277296 [label=AccumulateGrad]
	140309915275616 -> 140309915426192
	140309915424032 -> 140309915423792
	140309606461504 [label="stage3.0.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309606461504 -> 140309915424032
	140309915424032 [label=AccumulateGrad]
	140309915424368 -> 140309915433136
	140309606461584 [label="stage3.0.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140309606461584 -> 140309915424368
	140309915424368 [label=AccumulateGrad]
	140309915422832 -> 140309915433136
	140309606461664 [label="stage3.0.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140309606461664 -> 140309915422832
	140309915422832 [label=AccumulateGrad]
	140309915432272 -> 140309915446720
	140309606462064 [label="stage3.0.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309606462064 -> 140309915432272
	140309915432272 [label=AccumulateGrad]
	140309915431984 -> 140309915446288
	140309606462144 [label="stage3.0.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140309606462144 -> 140309915431984
	140309915431984 [label=AccumulateGrad]
	140309915431456 -> 140309915446288
	140309606462224 [label="stage3.0.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140309606462224 -> 140309915431456
	140309915431456 [label=AccumulateGrad]
	140309915445808 -> 140309915446096
	140309915445088 -> 140309915444800
	140309606462624 [label="stage3.0.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309606462624 -> 140309915445088
	140309915445088 [label=AccumulateGrad]
	140309915444272 -> 140309915443840
	140309606462704 [label="stage3.0.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140309606462704 -> 140309915444272
	140309915444272 [label=AccumulateGrad]
	140309915444224 -> 140309915443840
	140309606462784 [label="stage3.0.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140309606462784 -> 140309915444224
	140309915444224 [label=AccumulateGrad]
	140309915443648 -> 140309917380128
	140309606463184 [label="stage3.0.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309606463184 -> 140309915443648
	140309915443648 [label=AccumulateGrad]
	140309917380320 -> 140309917379696
	140309606463264 [label="stage3.0.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140309606463264 -> 140309917380320
	140309917380320 [label=AccumulateGrad]
	140309917380512 -> 140309917379696
	140309606463344 [label="stage3.0.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140309606463344 -> 140309917380512
	140309917380512 [label=AccumulateGrad]
	140309917379936 -> 140309917380032
	140309917379456 -> 140309917378976
	140309606587104 [label="stage3.0.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140309606587104 -> 140309917379456
	140309917379456 [label=AccumulateGrad]
	140309917378448 -> 140309917378400
	140309606587184 [label="stage3.0.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140309606587184 -> 140309917378448
	140309917378448 [label=AccumulateGrad]
	140309917378016 -> 140309917378400
	140309606587264 [label="stage3.0.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140309606587264 -> 140309917378016
	140309917378016 [label=AccumulateGrad]
	140309917377440 -> 140309917377632
	140309917377440 [label=UpsampleNearest2DBackward1]
	140309917378880 -> 140309917377440
	140309917378880 [label=NativeBatchNormBackward0]
	140309917379072 -> 140309917378880
	140309917379072 [label=ConvolutionBackward0]
	140309915445376 -> 140309917379072
	140309915445376 [label=ReluBackward0]
	140309915444464 -> 140309915445376
	140309915444464 [label=AddBackward0]
	140309915444896 -> 140309915444464
	140309915444896 [label=NativeBatchNormBackward0]
	140309915432704 -> 140309915444896
	140309915432704 [label=ConvolutionBackward0]
	140309915425904 -> 140309915432704
	140309915425904 [label=ReluBackward0]
	140309915278208 -> 140309915425904
	140309915278208 [label=NativeBatchNormBackward0]
	140309915278928 -> 140309915278208
	140309915278928 [label=ConvolutionBackward0]
	140309915444704 -> 140309915278928
	140309915444704 [label=ReluBackward0]
	140309915278592 -> 140309915444704
	140309915278592 [label=AddBackward0]
	140309915341152 -> 140309915278592
	140309915341152 [label=NativeBatchNormBackward0]
	140309915341584 -> 140309915341152
	140309915341584 [label=ConvolutionBackward0]
	140309915341680 -> 140309915341584
	140309915341680 [label=ReluBackward0]
	140309915341824 -> 140309915341680
	140309915341824 [label=NativeBatchNormBackward0]
	140309915341920 -> 140309915341824
	140309915341920 [label=ConvolutionBackward0]
	140309915341344 -> 140309915341920
	140309915341344 [label=ReluBackward0]
	140309915342208 -> 140309915341344
	140309915342208 [label=AddBackward0]
	140309915342304 -> 140309915342208
	140309915342304 [label=NativeBatchNormBackward0]
	140309915342448 -> 140309915342304
	140309915342448 [label=ConvolutionBackward0]
	140309915342640 -> 140309915342448
	140309915342640 [label=ReluBackward0]
	140309915342784 -> 140309915342640
	140309915342784 [label=NativeBatchNormBackward0]
	140309915342880 -> 140309915342784
	140309915342880 [label=ConvolutionBackward0]
	140309915342256 -> 140309915342880
	140309915342256 [label=ReluBackward0]
	140309915343168 -> 140309915342256
	140309915343168 [label=AddBackward0]
	140309915343264 -> 140309915343168
	140309915343264 [label=NativeBatchNormBackward0]
	140309915343408 -> 140309915343264
	140309915343408 [label=ConvolutionBackward0]
	140309915343600 -> 140309915343408
	140309915343600 [label=ReluBackward0]
	140309915343744 -> 140309915343600
	140309915343744 [label=NativeBatchNormBackward0]
	140309915343840 -> 140309915343744
	140309915343840 [label=ConvolutionBackward0]
	140309915343216 -> 140309915343840
	140309915343216 [label=ReluBackward0]
	140309915344128 -> 140309915343216
	140309915344128 [label=NativeBatchNormBackward0]
	140309915344224 -> 140309915344128
	140309915344224 [label=ConvolutionBackward0]
	140309915278688 -> 140309915344224
	140309915344416 -> 140309915344224
	140310422835984 [label="transition2.2.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140310422835984 -> 140309915344416
	140309915344416 [label=AccumulateGrad]
	140309915344176 -> 140309915344128
	140310422836064 [label="transition2.2.0.1.weight
 (72)" fillcolor=lightblue]
	140310422836064 -> 140309915344176
	140309915344176 [label=AccumulateGrad]
	140309915343936 -> 140309915344128
	140310422836144 [label="transition2.2.0.1.bias
 (72)" fillcolor=lightblue]
	140310422836144 -> 140309915343936
	140309915343936 [label=AccumulateGrad]
	140309915344032 -> 140309915343840
	140309606463744 [label="stage3.0.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309606463744 -> 140309915344032
	140309915344032 [label=AccumulateGrad]
	140309915343792 -> 140309915343744
	140309606463824 [label="stage3.0.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140309606463824 -> 140309915343792
	140309915343792 [label=AccumulateGrad]
	140309915343648 -> 140309915343744
	140309606463904 [label="stage3.0.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140309606463904 -> 140309915343648
	140309915343648 [label=AccumulateGrad]
	140309915343552 -> 140309915343408
	140309606464304 [label="stage3.0.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309606464304 -> 140309915343552
	140309915343552 [label=AccumulateGrad]
	140309915343360 -> 140309915343264
	140309606464384 [label="stage3.0.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140309606464384 -> 140309915343360
	140309915343360 [label=AccumulateGrad]
	140309915343312 -> 140309915343264
	140309606464464 [label="stage3.0.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140309606464464 -> 140309915343312
	140309915343312 [label=AccumulateGrad]
	140309915343216 -> 140309915343168
	140309915343072 -> 140309915342880
	140309606464864 [label="stage3.0.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309606464864 -> 140309915343072
	140309915343072 [label=AccumulateGrad]
	140309915342832 -> 140309915342784
	140309606464944 [label="stage3.0.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140309606464944 -> 140309915342832
	140309915342832 [label=AccumulateGrad]
	140309915342688 -> 140309915342784
	140309606465024 [label="stage3.0.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140309606465024 -> 140309915342688
	140309915342688 [label=AccumulateGrad]
	140309915342592 -> 140309915342448
	140309606465424 [label="stage3.0.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309606465424 -> 140309915342592
	140309915342592 [label=AccumulateGrad]
	140309915342400 -> 140309915342304
	140309606584384 [label="stage3.0.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140309606584384 -> 140309915342400
	140309915342400 [label=AccumulateGrad]
	140309915342352 -> 140309915342304
	140309606584464 [label="stage3.0.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140309606584464 -> 140309915342352
	140309915342352 [label=AccumulateGrad]
	140309915342256 -> 140309915342208
	140309915342112 -> 140309915341920
	140309606584864 [label="stage3.0.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309606584864 -> 140309915342112
	140309915342112 [label=AccumulateGrad]
	140309915341872 -> 140309915341824
	140309606584944 [label="stage3.0.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140309606584944 -> 140309915341872
	140309915341872 [label=AccumulateGrad]
	140309915341728 -> 140309915341824
	140309606585024 [label="stage3.0.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140309606585024 -> 140309915341728
	140309915341728 [label=AccumulateGrad]
	140309915341632 -> 140309915341584
	140309606585424 [label="stage3.0.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309606585424 -> 140309915341632
	140309915341632 [label=AccumulateGrad]
	140309915341440 -> 140309915341152
	140309606585504 [label="stage3.0.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140309606585504 -> 140309915341440
	140309915341440 [label=AccumulateGrad]
	140309915341056 -> 140309915341152
	140309606585584 [label="stage3.0.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140309606585584 -> 140309915341056
	140309915341056 [label=AccumulateGrad]
	140309915341344 -> 140309915278592
	140309915279168 -> 140309915278928
	140309606585984 [label="stage3.0.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309606585984 -> 140309915279168
	140309915279168 [label=AccumulateGrad]
	140309915278160 -> 140309915278208
	140309606586064 [label="stage3.0.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140309606586064 -> 140309915278160
	140309915278160 [label=AccumulateGrad]
	140309915277824 -> 140309915278208
	140309606586144 [label="stage3.0.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140309606586144 -> 140309915277824
	140309915277824 [label=AccumulateGrad]
	140309915276336 -> 140309915432704
	140309606586544 [label="stage3.0.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309606586544 -> 140309915276336
	140309915276336 [label=AccumulateGrad]
	140309915432944 -> 140309915444896
	140309606586624 [label="stage3.0.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140309606586624 -> 140309915432944
	140309915432944 [label=AccumulateGrad]
	140309915423552 -> 140309915444896
	140309606586704 [label="stage3.0.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140309606586704 -> 140309915423552
	140309915423552 [label=AccumulateGrad]
	140309915444704 -> 140309915444464
	140309915443744 -> 140309917379072
	140309606587664 [label="stage3.0.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140309606587664 -> 140309915443744
	140309915443744 [label=AccumulateGrad]
	140309917378640 -> 140309917378880
	140309606587744 [label="stage3.0.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140309606587744 -> 140309917378640
	140309917378640 [label=AccumulateGrad]
	140309917377824 -> 140309917378880
	140309606587824 [label="stage3.0.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140309606587824 -> 140309917377824
	140309917377824 [label=AccumulateGrad]
	140309917377536 -> 140309917377248
	140310153943776 [label="stage3.1.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310153943776 -> 140309917377536
	140309917377536 [label=AccumulateGrad]
	140309917377104 -> 140309917377200
	140310153943856 [label="stage3.1.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140310153943856 -> 140309917377104
	140309917377104 [label=AccumulateGrad]
	140309917377344 -> 140309917377200
	140310153943936 [label="stage3.1.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140310153943936 -> 140309917377344
	140309917377344 [label=AccumulateGrad]
	140309917377008 -> 140309917376864
	140310153944336 [label="stage3.1.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310153944336 -> 140309917377008
	140309917377008 [label=AccumulateGrad]
	140309917376816 -> 140309917376624
	140310153944416 [label="stage3.1.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140310153944416 -> 140309917376816
	140309917376816 [label=AccumulateGrad]
	140309917376768 -> 140309917376624
	140310153944496 [label="stage3.1.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140310153944496 -> 140309917376768
	140309917376768 [label=AccumulateGrad]
	140309917376576 -> 140309917392848
	140309917392800 -> 140309917392512
	140310153944896 [label="stage3.1.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310153944896 -> 140309917392800
	140309917392800 [label=AccumulateGrad]
	140309917392368 -> 140309917392464
	140310153944976 [label="stage3.1.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140310153944976 -> 140309917392368
	140309917392368 [label=AccumulateGrad]
	140309917392608 -> 140309917392464
	140310154076224 [label="stage3.1.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140310154076224 -> 140309917392608
	140309917392608 [label=AccumulateGrad]
	140309917392272 -> 140309917392128
	140310154076624 [label="stage3.1.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310154076624 -> 140309917392272
	140309917392272 [label=AccumulateGrad]
	140309917392080 -> 140309917391888
	140310154076704 [label="stage3.1.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140310154076704 -> 140309917392080
	140309917392080 [label=AccumulateGrad]
	140309917392032 -> 140309917391888
	140310154076784 [label="stage3.1.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140310154076784 -> 140309917392032
	140309917392032 [label=AccumulateGrad]
	140309917391648 -> 140309917391840
	140309917391744 -> 140309917391456
	140310154077184 [label="stage3.1.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310154077184 -> 140309917391744
	140309917391744 [label=AccumulateGrad]
	140309917391312 -> 140309917391408
	140310154077264 [label="stage3.1.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140310154077264 -> 140309917391312
	140309917391312 [label=AccumulateGrad]
	140309917391552 -> 140309917391408
	140310154077344 [label="stage3.1.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140310154077344 -> 140309917391552
	140309917391552 [label=AccumulateGrad]
	140309917391216 -> 140309917391072
	140310154077744 [label="stage3.1.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310154077744 -> 140309917391216
	140309917391216 [label=AccumulateGrad]
	140309917391024 -> 140309917390832
	140310154077824 [label="stage3.1.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140310154077824 -> 140309917391024
	140309917391024 [label=AccumulateGrad]
	140309917390976 -> 140309917390832
	140310154077904 [label="stage3.1.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140310154077904 -> 140309917390976
	140309917390976 [label=AccumulateGrad]
	140309917390592 -> 140309917390784
	140309917390688 -> 140309917390400
	140310154078304 [label="stage3.1.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310154078304 -> 140309917390688
	140309917390688 [label=AccumulateGrad]
	140309917390256 -> 140309917390352
	140310154078384 [label="stage3.1.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140310154078384 -> 140309917390256
	140309917390256 [label=AccumulateGrad]
	140309917390496 -> 140309917390352
	140310154078464 [label="stage3.1.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140310154078464 -> 140309917390496
	140309917390496 [label=AccumulateGrad]
	140309917390160 -> 140309917390016
	140310154078864 [label="stage3.1.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310154078864 -> 140309917390160
	140309917390160 [label=AccumulateGrad]
	140309917389968 -> 140309917389776
	140310154078944 [label="stage3.1.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140310154078944 -> 140309917389968
	140309917389968 [label=AccumulateGrad]
	140309917389920 -> 140309917389776
	140310154079024 [label="stage3.1.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140310154079024 -> 140309917389920
	140309917389920 [label=AccumulateGrad]
	140309917389632 -> 140309917389728
	140309917389536 -> 140309917389344
	140309917389536 [label=UpsampleNearest2DBackward1]
	140309917390064 -> 140309917389536
	140309917390064 [label=NativeBatchNormBackward0]
	140309917390640 -> 140309917390064
	140309917390640 [label=ConvolutionBackward0]
	140309917390928 -> 140309917390640
	140309917390928 [label=ReluBackward0]
	140309917391696 -> 140309917390928
	140309917391696 [label=AddBackward0]
	140309917391360 -> 140309917391696
	140309917391360 [label=NativeBatchNormBackward0]
	140309917391792 -> 140309917391360
	140309917391792 [label=ConvolutionBackward0]
	140309917392416 -> 140309917391792
	140309917392416 [label=ReluBackward0]
	140309917392704 -> 140309917392416
	140309917392704 [label=NativeBatchNormBackward0]
	140309917377488 -> 140309917392704
	140309917377488 [label=ConvolutionBackward0]
	140309917391600 -> 140309917377488
	140309917391600 [label=ReluBackward0]
	140309917379504 -> 140309917391600
	140309917379504 [label=AddBackward0]
	140309915433424 -> 140309917379504
	140309915433424 [label=NativeBatchNormBackward0]
	140309915444032 -> 140309915433424
	140309915444032 [label=ConvolutionBackward0]
	140309915278496 -> 140309915444032
	140309915278496 [label=ReluBackward0]
	140309915341392 -> 140309915278496
	140309915341392 [label=NativeBatchNormBackward0]
	140309915341968 -> 140309915341392
	140309915341968 [label=ConvolutionBackward0]
	140309915423120 -> 140309915341968
	140309915423120 [label=ReluBackward0]
	140309915343024 -> 140309915423120
	140309915343024 [label=AddBackward0]
	140309915342736 -> 140309915343024
	140309915342736 [label=NativeBatchNormBackward0]
	140309915343120 -> 140309915342736
	140309915343120 [label=ConvolutionBackward0]
	140309915343696 -> 140309915343120
	140309915343696 [label=ReluBackward0]
	140309915344080 -> 140309915343696
	140309915344080 [label=NativeBatchNormBackward0]
	140309915344464 -> 140309915344080
	140309915344464 [label=ConvolutionBackward0]
	140309915342928 -> 140309915344464
	140309915342928 [label=ReluBackward0]
	140309915344752 -> 140309915342928
	140309915344752 [label=AddBackward0]
	140309915344848 -> 140309915344752
	140309915344848 [label=NativeBatchNormBackward0]
	140309915283616 -> 140309915344848
	140309915283616 [label=ConvolutionBackward0]
	140309915283808 -> 140309915283616
	140309915283808 [label=ReluBackward0]
	140309915283952 -> 140309915283808
	140309915283952 [label=NativeBatchNormBackward0]
	140309915284048 -> 140309915283952
	140309915284048 [label=ConvolutionBackward0]
	140309915344800 -> 140309915284048
	140309915344800 [label=ReluBackward0]
	140309915284336 -> 140309915344800
	140309915284336 [label=AddBackward0]
	140309915284432 -> 140309915284336
	140309915284432 [label=AddBackward0]
	140309915284576 -> 140309915284432
	140309915284576 [label=NativeBatchNormBackward0]
	140309915284672 -> 140309915284576
	140309915284672 [label=ConvolutionBackward0]
	140309917377920 -> 140309915284672
	140309915284864 -> 140309915284672
	140309606588224 [label="stage3.0.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140309606588224 -> 140309915284864
	140309915284864 [label=AccumulateGrad]
	140309915284624 -> 140309915284576
	140309606588304 [label="stage3.0.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140309606588304 -> 140309915284624
	140309915284624 [label=AccumulateGrad]
	140309915284480 -> 140309915284576
	140310153941056 [label="stage3.0.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140310153941056 -> 140309915284480
	140309915284480 [label=AccumulateGrad]
	140309917379264 -> 140309915284432
	140309915284384 -> 140309915284336
	140309915284384 [label=UpsampleNearest2DBackward1]
	140309915284816 -> 140309915284384
	140309915284816 [label=NativeBatchNormBackward0]
	140309915284912 -> 140309915284816
	140309915284912 [label=ConvolutionBackward0]
	140309915445376 -> 140309915284912
	140309915285104 -> 140309915284912
	140310153941456 [label="stage3.0.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140310153941456 -> 140309915285104
	140309915285104 [label=AccumulateGrad]
	140309915284960 -> 140309915284816
	140310153941536 [label="stage3.0.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140310153941536 -> 140309915284960
	140309915284960 [label=AccumulateGrad]
	140309915284528 -> 140309915284816
	140310153941616 [label="stage3.0.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140310153941616 -> 140309915284528
	140309915284528 [label=AccumulateGrad]
	140309915284240 -> 140309915284048
	140310154079424 [label="stage3.1.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310154079424 -> 140309915284240
	140309915284240 [label=AccumulateGrad]
	140309915284000 -> 140309915283952
	140310154079504 [label="stage3.1.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140310154079504 -> 140309915284000
	140309915284000 [label=AccumulateGrad]
	140309915283856 -> 140309915283952
	140310154079584 [label="stage3.1.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140310154079584 -> 140309915283856
	140309915283856 [label=AccumulateGrad]
	140309915283760 -> 140309915283616
	140310154079984 [label="stage3.1.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310154079984 -> 140309915283760
	140309915283760 [label=AccumulateGrad]
	140309915283568 -> 140309915344848
	140310154080064 [label="stage3.1.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140310154080064 -> 140309915283568
	140309915283568 [label=AccumulateGrad]
	140309915283520 -> 140309915344848
	140310154080144 [label="stage3.1.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140310154080144 -> 140309915283520
	140309915283520 [label=AccumulateGrad]
	140309915344800 -> 140309915344752
	140309915344656 -> 140309915344464
	140310154285440 [label="stage3.1.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310154285440 -> 140309915344656
	140309915344656 [label=AccumulateGrad]
	140309915344512 -> 140309915344080
	140310154285520 [label="stage3.1.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140310154285520 -> 140309915344512
	140309915344512 [label=AccumulateGrad]
	140309915344368 -> 140309915344080
	140310154285600 [label="stage3.1.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140310154285600 -> 140309915344368
	140309915344368 [label=AccumulateGrad]
	140309915343888 -> 140309915343120
	140310154286000 [label="stage3.1.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310154286000 -> 140309915343888
	140309915343888 [label=AccumulateGrad]
	140309915342976 -> 140309915342736
	140310154286080 [label="stage3.1.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140310154286080 -> 140309915342976
	140309915342976 [label=AccumulateGrad]
	140309915343456 -> 140309915342736
	140310154286160 [label="stage3.1.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140310154286160 -> 140309915343456
	140309915343456 [label=AccumulateGrad]
	140309915342928 -> 140309915343024
	140309915342160 -> 140309915341968
	140310154286560 [label="stage3.1.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310154286560 -> 140309915342160
	140309915342160 [label=AccumulateGrad]
	140309915342064 -> 140309915341392
	140310154286640 [label="stage3.1.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140310154286640 -> 140309915342064
	140309915342064 [label=AccumulateGrad]
	140309915340960 -> 140309915341392
	140310154286720 [label="stage3.1.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140310154286720 -> 140309915340960
	140309915340960 [label=AccumulateGrad]
	140309915278448 -> 140309915444032
	140310154287120 [label="stage3.1.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310154287120 -> 140309915278448
	140309915278448 [label=AccumulateGrad]
	140309915443264 -> 140309915433424
	140310154287200 [label="stage3.1.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140310154287200 -> 140309915443264
	140309915443264 [label=AccumulateGrad]
	140309915277344 -> 140309915433424
	140310154287280 [label="stage3.1.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140310154287280 -> 140309915277344
	140309915277344 [label=AccumulateGrad]
	140309915423120 -> 140309917379504
	140309917377776 -> 140309917377488
	140310154287680 [label="stage3.1.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310154287680 -> 140309917377776
	140309917377776 [label=AccumulateGrad]
	140309917376960 -> 140309917392704
	140310154287760 [label="stage3.1.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140310154287760 -> 140309917376960
	140309917376960 [label=AccumulateGrad]
	140309917376912 -> 140309917392704
	140310154287840 [label="stage3.1.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140310154287840 -> 140309917376912
	140309917376912 [label=AccumulateGrad]
	140309917392656 -> 140309917391792
	140310154288240 [label="stage3.1.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310154288240 -> 140309917392656
	140309917392656 [label=AccumulateGrad]
	140309917391984 -> 140309917391360
	140310154288320 [label="stage3.1.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140310154288320 -> 140309917391984
	140309917391984 [label=AccumulateGrad]
	140309917392176 -> 140309917391360
	140310154288400 [label="stage3.1.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140310154288400 -> 140309917392176
	140309917392176 [label=AccumulateGrad]
	140309917391600 -> 140309917391696
	140309917391120 -> 140309917390640
	140310681133280 [label="stage3.1.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140310681133280 -> 140309917391120
	140309917391120 [label=AccumulateGrad]
	140309917390112 -> 140309917390064
	140310681133360 [label="stage3.1.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140310681133360 -> 140309917390112
	140309917390112 [label=AccumulateGrad]
	140309917389680 -> 140309917390064
	140310681133440 [label="stage3.1.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140310681133440 -> 140309917389680
	140309917389680 [label=AccumulateGrad]
	140309917389104 -> 140309917389296
	140309917389104 [label=UpsampleNearest2DBackward1]
	140309917390544 -> 140309917389104
	140309917390544 [label=NativeBatchNormBackward0]
	140309917392224 -> 140309917390544
	140309917392224 [label=ConvolutionBackward0]
	140309915278976 -> 140309917392224
	140309915278976 [label=ReluBackward0]
	140309917378208 -> 140309915278976
	140309917378208 [label=AddBackward0]
	140309917377584 -> 140309917378208
	140309917377584 [label=NativeBatchNormBackward0]
	140309915341776 -> 140309917377584
	140309915341776 [label=ConvolutionBackward0]
	140309915342544 -> 140309915341776
	140309915342544 [label=ReluBackward0]
	140309915344320 -> 140309915342544
	140309915344320 [label=NativeBatchNormBackward0]
	140309915344560 -> 140309915344320
	140309915344560 [label=ConvolutionBackward0]
	140309917377152 -> 140309915344560
	140309917377152 [label=ReluBackward0]
	140309915283904 -> 140309917377152
	140309915283904 [label=AddBackward0]
	140309915284144 -> 140309915283904
	140309915284144 [label=NativeBatchNormBackward0]
	140309915285056 -> 140309915284144
	140309915285056 [label=ConvolutionBackward0]
	140309915285248 -> 140309915285056
	140309915285248 [label=ReluBackward0]
	140309915285392 -> 140309915285248
	140309915285392 [label=NativeBatchNormBackward0]
	140309915285488 -> 140309915285392
	140309915285488 [label=ConvolutionBackward0]
	140309915284720 -> 140309915285488
	140309915284720 [label=ReluBackward0]
	140309915285776 -> 140309915284720
	140309915285776 [label=AddBackward0]
	140309915285872 -> 140309915285776
	140309915285872 [label=NativeBatchNormBackward0]
	140309915286016 -> 140309915285872
	140309915286016 [label=ConvolutionBackward0]
	140309915286208 -> 140309915286016
	140309915286208 [label=ReluBackward0]
	140309915286352 -> 140309915286208
	140309915286352 [label=NativeBatchNormBackward0]
	140309915286448 -> 140309915286352
	140309915286448 [label=ConvolutionBackward0]
	140309915285824 -> 140309915286448
	140309915285824 [label=ReluBackward0]
	140309915286736 -> 140309915285824
	140309915286736 [label=AddBackward0]
	140309915286832 -> 140309915286736
	140309915286832 [label=NativeBatchNormBackward0]
	140309915286976 -> 140309915286832
	140309915286976 [label=ConvolutionBackward0]
	140309915287168 -> 140309915286976
	140309915287168 [label=ReluBackward0]
	140309915287312 -> 140309915287168
	140309915287312 [label=NativeBatchNormBackward0]
	140309915287408 -> 140309915287312
	140309915287408 [label=ConvolutionBackward0]
	140309915286784 -> 140309915287408
	140309915286784 [label=ReluBackward0]
	140309915472080 -> 140309915286784
	140309915472080 [label=AddBackward0]
	140309915472176 -> 140309915472080
	140309915472176 [label=AddBackward0]
	140309915472272 -> 140309915472176
	140309915472272 [label=NativeBatchNormBackward0]
	140309915472416 -> 140309915472272
	140309915472416 [label=ConvolutionBackward0]
	140309915472608 -> 140309915472416
	140309915472608 [label=ReluBackward0]
	140309915472752 -> 140309915472608
	140309915472752 [label=NativeBatchNormBackward0]
	140309915472848 -> 140309915472752
	140309915472848 [label=ConvolutionBackward0]
	140309917377920 -> 140309915472848
	140309915473040 -> 140309915472848
	140310153942016 [label="stage3.0.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310153942016 -> 140309915473040
	140309915473040 [label=AccumulateGrad]
	140309915472800 -> 140309915472752
	140310153942096 [label="stage3.0.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140310153942096 -> 140309915472800
	140309915472800 [label=AccumulateGrad]
	140309915472656 -> 140309915472752
	140310153942176 [label="stage3.0.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140310153942176 -> 140309915472656
	140309915472656 [label=AccumulateGrad]
	140309915472560 -> 140309915472416
	140310153942576 [label="stage3.0.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140310153942576 -> 140309915472560
	140309915472560 [label=AccumulateGrad]
	140309915472368 -> 140309915472272
	140310153942656 [label="stage3.0.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140310153942656 -> 140309915472368
	140309915472368 [label=AccumulateGrad]
	140309915472320 -> 140309915472272
	140310153942736 [label="stage3.0.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140310153942736 -> 140309915472320
	140309915472320 [label=AccumulateGrad]
	140309915472224 -> 140309915472176
	140309915472224 [label=NativeBatchNormBackward0]
	140309915472992 -> 140309915472224
	140309915472992 [label=ConvolutionBackward0]
	140309917379264 -> 140309915472992
	140309915473088 -> 140309915472992
	140310153943136 [label="stage3.0.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140310153943136 -> 140309915473088
	140309915473088 [label=AccumulateGrad]
	140309915472512 -> 140309915472224
	140310153943216 [label="stage3.0.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140310153943216 -> 140309915472512
	140309915472512 [label=AccumulateGrad]
	140309915472464 -> 140309915472224
	140310153943296 [label="stage3.0.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140310153943296 -> 140309915472464
	140309915472464 [label=AccumulateGrad]
	140309915445376 -> 140309915472080
	140309915287504 -> 140309915287408
	140310154288800 [label="stage3.1.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140310154288800 -> 140309915287504
	140309915287504 [label=AccumulateGrad]
	140309915287360 -> 140309915287312
	140310154288880 [label="stage3.1.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140310154288880 -> 140309915287360
	140309915287360 [label=AccumulateGrad]
	140309915287216 -> 140309915287312
	140310154288960 [label="stage3.1.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140310154288960 -> 140309915287216
	140309915287216 [label=AccumulateGrad]
	140309915287120 -> 140309915286976
	140310154416432 [label="stage3.1.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140310154416432 -> 140309915287120
	140309915287120 [label=AccumulateGrad]
	140309915286928 -> 140309915286832
	140310154416512 [label="stage3.1.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140310154416512 -> 140309915286928
	140309915286928 [label=AccumulateGrad]
	140309915286880 -> 140309915286832
	140310154416592 [label="stage3.1.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140310154416592 -> 140309915286880
	140309915286880 [label=AccumulateGrad]
	140309915286784 -> 140309915286736
	140309915286640 -> 140309915286448
	140310154416992 [label="stage3.1.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140310154416992 -> 140309915286640
	140309915286640 [label=AccumulateGrad]
	140309915286400 -> 140309915286352
	140310154417072 [label="stage3.1.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140310154417072 -> 140309915286400
	140309915286400 [label=AccumulateGrad]
	140309915286256 -> 140309915286352
	140310154417152 [label="stage3.1.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140310154417152 -> 140309915286256
	140309915286256 [label=AccumulateGrad]
	140309915286160 -> 140309915286016
	140310154417552 [label="stage3.1.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140310154417552 -> 140309915286160
	140309915286160 [label=AccumulateGrad]
	140309915285968 -> 140309915285872
	140310154417632 [label="stage3.1.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140310154417632 -> 140309915285968
	140309915285968 [label=AccumulateGrad]
	140309915285920 -> 140309915285872
	140310154417712 [label="stage3.1.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140310154417712 -> 140309915285920
	140309915285920 [label=AccumulateGrad]
	140309915285824 -> 140309915285776
	140309915285680 -> 140309915285488
	140310154418112 [label="stage3.1.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140310154418112 -> 140309915285680
	140309915285680 [label=AccumulateGrad]
	140309915285440 -> 140309915285392
	140310154418192 [label="stage3.1.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140310154418192 -> 140309915285440
	140309915285440 [label=AccumulateGrad]
	140309915285296 -> 140309915285392
	140310154418272 [label="stage3.1.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140310154418272 -> 140309915285296
	140309915285296 [label=AccumulateGrad]
	140309915285008 -> 140309915285056
	140310154418672 [label="stage3.1.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140310154418672 -> 140309915285008
	140309915285008 [label=AccumulateGrad]
	140309915284768 -> 140309915284144
	140310154418752 [label="stage3.1.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140310154418752 -> 140309915284768
	140309915284768 [label=AccumulateGrad]
	140309915284288 -> 140309915284144
	140310154418832 [label="stage3.1.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140310154418832 -> 140309915284288
	140309915284288 [label=AccumulateGrad]
	140309915284720 -> 140309915283904
	140309915284192 -> 140309915344560
	140310154419232 [label="stage3.1.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140310154419232 -> 140309915284192
	140309915284192 [label=AccumulateGrad]
	140309915344272 -> 140309915344320
	140310154419312 [label="stage3.1.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140310154419312 -> 140309915344272
	140309915344272 [label=AccumulateGrad]
	140309915343984 -> 140309915344320
	140310154419392 [label="stage3.1.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140310154419392 -> 140309915343984
	140309915343984 [label=AccumulateGrad]
	140309915342496 -> 140309915341776
	140310154419792 [label="stage3.1.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140310154419792 -> 140309915342496
	140309915342496 [label=AccumulateGrad]
	140309915342016 -> 140309917377584
	140310154419872 [label="stage3.1.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140310154419872 -> 140309915342016
	140309915342016 [label=AccumulateGrad]
	140309915341536 -> 140309917377584
	140310154419952 [label="stage3.1.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140310154419952 -> 140309915341536
	140309915341536 [label=AccumulateGrad]
	140309917377152 -> 140309917378208
	140309917392752 -> 140309917392224
	140310681133840 [label="stage3.1.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140310681133840 -> 140309917392752
	140309917392752 [label=AccumulateGrad]
	140309917390304 -> 140309917390544
	140310681133920 [label="stage3.1.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140310681133920 -> 140309917390304
	140309917390304 [label=AccumulateGrad]
	140309917389488 -> 140309917390544
	140310681134000 [label="stage3.1.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140310681134000 -> 140309917389488
	140309917389488 [label=AccumulateGrad]
	140309917389200 -> 140309917388912
	140310681264272 [label="stage3.2.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310681264272 -> 140309917389200
	140309917389200 [label=AccumulateGrad]
	140309917388864 -> 140309917409232
	140310681264352 [label="stage3.2.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140310681264352 -> 140309917388864
	140309917388864 [label=AccumulateGrad]
	140309917389008 -> 140309917409232
	140310681264432 [label="stage3.2.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140310681264432 -> 140309917389008
	140309917389008 [label=AccumulateGrad]
	140309917409088 -> 140309917408944
	140310681264832 [label="stage3.2.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310681264832 -> 140309917409088
	140309917409088 [label=AccumulateGrad]
	140309917408896 -> 140309917408704
	140310681264912 [label="stage3.2.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140310681264912 -> 140309917408896
	140309917408896 [label=AccumulateGrad]
	140309917408848 -> 140309917408704
	140310681264992 [label="stage3.2.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140310681264992 -> 140309917408848
	140309917408848 [label=AccumulateGrad]
	140309917408464 -> 140309917408656
	140309917408560 -> 140309917408272
	140310681265392 [label="stage3.2.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310681265392 -> 140309917408560
	140309917408560 [label=AccumulateGrad]
	140309917408128 -> 140309917408224
	140310681265472 [label="stage3.2.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140310681265472 -> 140309917408128
	140309917408128 [label=AccumulateGrad]
	140309917408368 -> 140309917408224
	140310681265552 [label="stage3.2.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140310681265552 -> 140309917408368
	140309917408368 [label=AccumulateGrad]
	140309917408032 -> 140309917407888
	140310681265952 [label="stage3.2.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310681265952 -> 140309917408032
	140309917408032 [label=AccumulateGrad]
	140309917407840 -> 140309917407648
	140310681266032 [label="stage3.2.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140310681266032 -> 140309917407840
	140309917407840 [label=AccumulateGrad]
	140309917407792 -> 140309917407648
	140310681266112 [label="stage3.2.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140310681266112 -> 140309917407792
	140309917407792 [label=AccumulateGrad]
	140309917407408 -> 140309917407600
	140309917407504 -> 140309917407216
	140310681266512 [label="stage3.2.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310681266512 -> 140309917407504
	140309917407504 [label=AccumulateGrad]
	140309917407072 -> 140309917407168
	140310681266592 [label="stage3.2.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140310681266592 -> 140309917407072
	140309917407072 [label=AccumulateGrad]
	140309917407312 -> 140309917407168
	140310681266672 [label="stage3.2.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140310681266672 -> 140309917407312
	140309917407312 [label=AccumulateGrad]
	140309917406976 -> 140309917406832
	140310681267072 [label="stage3.2.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310681267072 -> 140309917406976
	140309917406976 [label=AccumulateGrad]
	140309917406784 -> 140309917406592
	140310681267152 [label="stage3.2.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140310681267152 -> 140309917406784
	140309917406784 [label=AccumulateGrad]
	140309917406736 -> 140309917406592
	140310681267232 [label="stage3.2.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140310681267232 -> 140309917406736
	140309917406736 [label=AccumulateGrad]
	140309917406352 -> 140309917406544
	140309917406448 -> 140309917406160
	140310681267632 [label="stage3.2.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310681267632 -> 140309917406448
	140309917406448 [label=AccumulateGrad]
	140309917406016 -> 140309917406112
	140310681267712 [label="stage3.2.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140310681267712 -> 140309917406016
	140309917406016 [label=AccumulateGrad]
	140309917406256 -> 140309917406112
	140310681267792 [label="stage3.2.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140310681267792 -> 140309917406256
	140309917406256 [label=AccumulateGrad]
	140309917405920 -> 140309917405776
	140309200797760 [label="stage3.2.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309200797760 -> 140309917405920
	140309917405920 [label=AccumulateGrad]
	140309917405728 -> 140309917405536
	140309200797840 [label="stage3.2.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140309200797840 -> 140309917405728
	140309917405728 [label=AccumulateGrad]
	140309917405680 -> 140309917405536
	140309200797920 [label="stage3.2.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140309200797920 -> 140309917405680
	140309917405680 [label=AccumulateGrad]
	140309917405392 -> 140309917405488
	140309917405296 -> 140309917421424
	140309917405296 [label=UpsampleNearest2DBackward1]
	140309917405824 -> 140309917405296
	140309917405824 [label=NativeBatchNormBackward0]
	140309917406400 -> 140309917405824
	140309917406400 [label=ConvolutionBackward0]
	140309917406688 -> 140309917406400
	140309917406688 [label=ReluBackward0]
	140309917407456 -> 140309917406688
	140309917407456 [label=AddBackward0]
	140309917407120 -> 140309917407456
	140309917407120 [label=NativeBatchNormBackward0]
	140309917407552 -> 140309917407120
	140309917407552 [label=ConvolutionBackward0]
	140309917408176 -> 140309917407552
	140309917408176 [label=ReluBackward0]
	140309917408608 -> 140309917408176
	140309917408608 [label=NativeBatchNormBackward0]
	140309917409184 -> 140309917408608
	140309917409184 [label=ConvolutionBackward0]
	140309917407360 -> 140309917409184
	140309917407360 [label=ReluBackward0]
	140309917390736 -> 140309917407360
	140309917390736 [label=AddBackward0]
	140309917391168 -> 140309917390736
	140309917391168 [label=NativeBatchNormBackward0]
	140309917376720 -> 140309917391168
	140309917376720 [label=ConvolutionBackward0]
	140309915344608 -> 140309917376720
	140309915344608 [label=ReluBackward0]
	140309915285152 -> 140309915344608
	140309915285152 [label=NativeBatchNormBackward0]
	140309915285536 -> 140309915285152
	140309915285536 [label=ConvolutionBackward0]
	140309917389056 -> 140309915285536
	140309917389056 [label=ReluBackward0]
	140309915286592 -> 140309917389056
	140309915286592 [label=AddBackward0]
	140309915286304 -> 140309915286592
	140309915286304 [label=NativeBatchNormBackward0]
	140309915286688 -> 140309915286304
	140309915286688 [label=ConvolutionBackward0]
	140309915287264 -> 140309915286688
	140309915287264 [label=ReluBackward0]
	140309915472032 -> 140309915287264
	140309915472032 [label=NativeBatchNormBackward0]
	140309915473136 -> 140309915472032
	140309915473136 [label=ConvolutionBackward0]
	140309915286496 -> 140309915473136
	140309915286496 [label=ReluBackward0]
	140309915473328 -> 140309915286496
	140309915473328 [label=AddBackward0]
	140309915473424 -> 140309915473328
	140309915473424 [label=NativeBatchNormBackward0]
	140309915473568 -> 140309915473424
	140309915473568 [label=ConvolutionBackward0]
	140309915473760 -> 140309915473568
	140309915473760 [label=ReluBackward0]
	140309915473904 -> 140309915473760
	140309915473904 [label=NativeBatchNormBackward0]
	140309915474000 -> 140309915473904
	140309915474000 [label=ConvolutionBackward0]
	140309915473376 -> 140309915474000
	140309915473376 [label=ReluBackward0]
	140309915474288 -> 140309915473376
	140309915474288 [label=AddBackward0]
	140309915474384 -> 140309915474288
	140309915474384 [label=AddBackward0]
	140309915474528 -> 140309915474384
	140309915474528 [label=NativeBatchNormBackward0]
	140309915474624 -> 140309915474528
	140309915474624 [label=ConvolutionBackward0]
	140309917389584 -> 140309915474624
	140309915474816 -> 140309915474624
	140310681134400 [label="stage3.1.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140310681134400 -> 140309915474816
	140309915474816 [label=AccumulateGrad]
	140309915474576 -> 140309915474528
	140310681134480 [label="stage3.1.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140310681134480 -> 140309915474576
	140309915474576 [label=AccumulateGrad]
	140309915474432 -> 140309915474528
	140310681134560 [label="stage3.1.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140310681134560 -> 140309915474432
	140309915474432 [label=AccumulateGrad]
	140309917390928 -> 140309915474384
	140309915474336 -> 140309915474288
	140309915474336 [label=UpsampleNearest2DBackward1]
	140309915474768 -> 140309915474336
	140309915474768 [label=NativeBatchNormBackward0]
	140309915474864 -> 140309915474768
	140309915474864 [label=ConvolutionBackward0]
	140309915278976 -> 140309915474864
	140309915475056 -> 140309915474864
	140310681134960 [label="stage3.1.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140310681134960 -> 140309915475056
	140309915475056 [label=AccumulateGrad]
	140309915474912 -> 140309915474768
	140310681135040 [label="stage3.1.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140310681135040 -> 140309915474912
	140309915474912 [label=AccumulateGrad]
	140309915474480 -> 140309915474768
	140310681135120 [label="stage3.1.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140310681135120 -> 140309915474480
	140309915474480 [label=AccumulateGrad]
	140309915474192 -> 140309915474000
	140309200798320 [label="stage3.2.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309200798320 -> 140309915474192
	140309915474192 [label=AccumulateGrad]
	140309915473952 -> 140309915473904
	140309200798400 [label="stage3.2.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140309200798400 -> 140309915473952
	140309915473952 [label=AccumulateGrad]
	140309915473808 -> 140309915473904
	140309200798480 [label="stage3.2.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140309200798480 -> 140309915473808
	140309915473808 [label=AccumulateGrad]
	140309915473712 -> 140309915473568
	140309200798880 [label="stage3.2.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309200798880 -> 140309915473712
	140309915473712 [label=AccumulateGrad]
	140309915473520 -> 140309915473424
	140309200798960 [label="stage3.2.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140309200798960 -> 140309915473520
	140309915473520 [label=AccumulateGrad]
	140309915473472 -> 140309915473424
	140309200799040 [label="stage3.2.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140309200799040 -> 140309915473472
	140309915473472 [label=AccumulateGrad]
	140309915473376 -> 140309915473328
	140309915473232 -> 140309915473136
	140309200799440 [label="stage3.2.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309200799440 -> 140309915473232
	140309915473232 [label=AccumulateGrad]
	140309915472896 -> 140309915472032
	140309200799520 [label="stage3.2.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140309200799520 -> 140309915472896
	140309915472896 [label=AccumulateGrad]
	140309915471936 -> 140309915472032
	140309200799600 [label="stage3.2.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140309200799600 -> 140309915471936
	140309915471936 [label=AccumulateGrad]
	140309915287456 -> 140309915286688
	140309200800000 [label="stage3.2.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309200800000 -> 140309915287456
	140309915287456 [label=AccumulateGrad]
	140309915286544 -> 140309915286304
	140309200800080 [label="stage3.2.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140309200800080 -> 140309915286544
	140309915286544 [label=AccumulateGrad]
	140309915287024 -> 140309915286304
	140309200800160 [label="stage3.2.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140309200800160 -> 140309915287024
	140309915287024 [label=AccumulateGrad]
	140309915286496 -> 140309915286592
	140309915285728 -> 140309915285536
	140309200800560 [label="stage3.2.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309200800560 -> 140309915285728
	140309915285728 [label=AccumulateGrad]
	140309915285632 -> 140309915285152
	140309200800640 [label="stage3.2.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140309200800640 -> 140309915285632
	140309915285632 [label=AccumulateGrad]
	140309915283664 -> 140309915285152
	140309200800720 [label="stage3.2.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140309200800720 -> 140309915283664
	140309915283664 [label=AccumulateGrad]
	140309915285200 -> 140309917376720
	140309200801120 [label="stage3.2.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309200801120 -> 140309915285200
	140309915285200 [label=AccumulateGrad]
	140309915343504 -> 140309917391168
	140309200801200 [label="stage3.2.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140309200801200 -> 140309915343504
	140309915343504 [label=AccumulateGrad]
	140309915340864 -> 140309917391168
	140309200801280 [label="stage3.2.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140309200801280 -> 140309915340864
	140309915340864 [label=AccumulateGrad]
	140309917389056 -> 140309917390736
	140309917389440 -> 140309917409184
	140309200801680 [label="stage3.2.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309200801680 -> 140309917389440
	140309917389440 [label=AccumulateGrad]
	140309917409040 -> 140309917408608
	140309200916544 [label="stage3.2.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140309200916544 -> 140309917409040
	140309917409040 [label=AccumulateGrad]
	140309917408992 -> 140309917408608
	140309200916624 [label="stage3.2.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140309200916624 -> 140309917408992
	140309917408992 [label=AccumulateGrad]
	140309917408416 -> 140309917407552
	140309200917024 [label="stage3.2.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309200917024 -> 140309917408416
	140309917408416 [label=AccumulateGrad]
	140309917407744 -> 140309917407120
	140309200917104 [label="stage3.2.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140309200917104 -> 140309917407744
	140309917407744 [label=AccumulateGrad]
	140309917407936 -> 140309917407120
	140309200917184 [label="stage3.2.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140309200917184 -> 140309917407936
	140309917407936 [label=AccumulateGrad]
	140309917407360 -> 140309917407456
	140309917406880 -> 140309917406400
	140309201045040 [label="stage3.2.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140309201045040 -> 140309917406880
	140309917406880 [label=AccumulateGrad]
	140309917405872 -> 140309917405824
	140309201045120 [label="stage3.2.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140309201045120 -> 140309917405872
	140309917405872 [label=AccumulateGrad]
	140309917405440 -> 140309917405824
	140309201045200 [label="stage3.2.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140309201045200 -> 140309917405440
	140309917405440 [label=AccumulateGrad]
	140309917421184 -> 140309917421376
	140309917421184 [label=UpsampleNearest2DBackward1]
	140309917377392 -> 140309917421184
	140309917377392 [label=NativeBatchNormBackward0]
	140309917406304 -> 140309917377392
	140309917406304 [label=ConvolutionBackward0]
	140309917407984 -> 140309917406304
	140309917407984 [label=ReluBackward0]
	140309917408800 -> 140309917407984
	140309917408800 [label=AddBackward0]
	140309917389248 -> 140309917408800
	140309917389248 [label=NativeBatchNormBackward0]
	140309915285344 -> 140309917389248
	140309915285344 [label=ConvolutionBackward0]
	140309915286112 -> 140309915285344
	140309915286112 [label=ReluBackward0]
	140309915473184 -> 140309915286112
	140309915473184 [label=NativeBatchNormBackward0]
	140309915473616 -> 140309915473184
	140309915473616 [label=ConvolutionBackward0]
	140309917389872 -> 140309915473616
	140309917389872 [label=ReluBackward0]
	140309915473856 -> 140309917389872
	140309915473856 [label=AddBackward0]
	140309915474096 -> 140309915473856
	140309915474096 [label=NativeBatchNormBackward0]
	140309915475008 -> 140309915474096
	140309915475008 [label=ConvolutionBackward0]
	140309915475200 -> 140309915475008
	140309915475200 [label=ReluBackward0]
	140309915475344 -> 140309915475200
	140309915475344 [label=NativeBatchNormBackward0]
	140309915475440 -> 140309915475344
	140309915475440 [label=ConvolutionBackward0]
	140309915474672 -> 140309915475440
	140309915474672 [label=ReluBackward0]
	140309915475728 -> 140309915474672
	140309915475728 [label=AddBackward0]
	140309915475824 -> 140309915475728
	140309915475824 [label=NativeBatchNormBackward0]
	140309915475920 -> 140309915475824
	140309915475920 [label=ConvolutionBackward0]
	140310157144320 -> 140309915475920
	140310157144320 [label=ReluBackward0]
	140310157144464 -> 140310157144320
	140310157144464 [label=NativeBatchNormBackward0]
	140310157144560 -> 140310157144464
	140310157144560 [label=ConvolutionBackward0]
	140309915475776 -> 140310157144560
	140309915475776 [label=ReluBackward0]
	140310157144848 -> 140309915475776
	140310157144848 [label=AddBackward0]
	140310157144944 -> 140310157144848
	140310157144944 [label=NativeBatchNormBackward0]
	140310157145088 -> 140310157144944
	140310157145088 [label=ConvolutionBackward0]
	140310157145280 -> 140310157145088
	140310157145280 [label=ReluBackward0]
	140310157145424 -> 140310157145280
	140310157145424 [label=NativeBatchNormBackward0]
	140310157145520 -> 140310157145424
	140310157145520 [label=ConvolutionBackward0]
	140310157144896 -> 140310157145520
	140310157144896 [label=ReluBackward0]
	140310157145808 -> 140310157144896
	140310157145808 [label=AddBackward0]
	140310157145904 -> 140310157145808
	140310157145904 [label=AddBackward0]
	140310157146000 -> 140310157145904
	140310157146000 [label=NativeBatchNormBackward0]
	140310157146144 -> 140310157146000
	140310157146144 [label=ConvolutionBackward0]
	140310157146336 -> 140310157146144
	140310157146336 [label=ReluBackward0]
	140310157146480 -> 140310157146336
	140310157146480 [label=NativeBatchNormBackward0]
	140310157146576 -> 140310157146480
	140310157146576 [label=ConvolutionBackward0]
	140309917389584 -> 140310157146576
	140310157146768 -> 140310157146576
	140310681135520 [label="stage3.1.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310681135520 -> 140310157146768
	140310157146768 [label=AccumulateGrad]
	140310157146528 -> 140310157146480
	140310681135600 [label="stage3.1.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140310681135600 -> 140310157146528
	140310157146528 [label=AccumulateGrad]
	140310157146384 -> 140310157146480
	140310681135680 [label="stage3.1.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140310681135680 -> 140310157146384
	140310157146384 [label=AccumulateGrad]
	140310157146288 -> 140310157146144
	140310681136080 [label="stage3.1.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140310681136080 -> 140310157146288
	140310157146288 [label=AccumulateGrad]
	140310157146096 -> 140310157146000
	140310681136160 [label="stage3.1.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140310681136160 -> 140310157146096
	140310157146096 [label=AccumulateGrad]
	140310157146048 -> 140310157146000
	140310681136240 [label="stage3.1.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140310681136240 -> 140310157146048
	140310157146048 [label=AccumulateGrad]
	140310157145952 -> 140310157145904
	140310157145952 [label=NativeBatchNormBackward0]
	140310157146720 -> 140310157145952
	140310157146720 [label=ConvolutionBackward0]
	140309917390928 -> 140310157146720
	140310157146816 -> 140310157146720
	140310681136640 [label="stage3.1.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140310681136640 -> 140310157146816
	140310157146816 [label=AccumulateGrad]
	140310157146240 -> 140310157145952
	140310681136720 [label="stage3.1.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140310681136720 -> 140310157146240
	140310157146240 [label=AccumulateGrad]
	140310157146192 -> 140310157145952
	140310681136800 [label="stage3.1.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140310681136800 -> 140310157146192
	140310157146192 [label=AccumulateGrad]
	140309915278976 -> 140310157145808
	140310157145712 -> 140310157145520
	140309200917584 [label="stage3.2.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309200917584 -> 140310157145712
	140310157145712 [label=AccumulateGrad]
	140310157145472 -> 140310157145424
	140309200917664 [label="stage3.2.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140309200917664 -> 140310157145472
	140310157145472 [label=AccumulateGrad]
	140310157145328 -> 140310157145424
	140309200917744 [label="stage3.2.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140309200917744 -> 140310157145328
	140310157145328 [label=AccumulateGrad]
	140310157145232 -> 140310157145088
	140309200918144 [label="stage3.2.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309200918144 -> 140310157145232
	140310157145232 [label=AccumulateGrad]
	140310157145040 -> 140310157144944
	140309200918224 [label="stage3.2.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140309200918224 -> 140310157145040
	140310157145040 [label=AccumulateGrad]
	140310157144992 -> 140310157144944
	140309200918304 [label="stage3.2.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140309200918304 -> 140310157144992
	140310157144992 [label=AccumulateGrad]
	140310157144896 -> 140310157144848
	140310157144752 -> 140310157144560
	140309200918704 [label="stage3.2.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309200918704 -> 140310157144752
	140310157144752 [label=AccumulateGrad]
	140310157144512 -> 140310157144464
	140309200918784 [label="stage3.2.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140309200918784 -> 140310157144512
	140310157144512 [label=AccumulateGrad]
	140310157144368 -> 140310157144464
	140309200918864 [label="stage3.2.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140309200918864 -> 140310157144368
	140310157144368 [label=AccumulateGrad]
	140310157144272 -> 140309915475920
	140309200919264 [label="stage3.2.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309200919264 -> 140310157144272
	140310157144272 [label=AccumulateGrad]
	140309915475872 -> 140309915475824
	140309200919344 [label="stage3.2.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140309200919344 -> 140309915475872
	140309915475872 [label=AccumulateGrad]
	140310157144128 -> 140309915475824
	140309200919424 [label="stage3.2.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140309200919424 -> 140310157144128
	140310157144128 [label=AccumulateGrad]
	140309915475776 -> 140309915475728
	140309915475632 -> 140309915475440
	140309200919824 [label="stage3.2.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309200919824 -> 140309915475632
	140309915475632 [label=AccumulateGrad]
	140309915475392 -> 140309915475344
	140309200919904 [label="stage3.2.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140309200919904 -> 140309915475392
	140309915475392 [label=AccumulateGrad]
	140309915475248 -> 140309915475344
	140309200919984 [label="stage3.2.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140309200919984 -> 140309915475248
	140309915475248 [label=AccumulateGrad]
	140309915474960 -> 140309915475008
	140309200920384 [label="stage3.2.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309200920384 -> 140309915474960
	140309915474960 [label=AccumulateGrad]
	140309915474720 -> 140309915474096
	140309200920464 [label="stage3.2.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140309200920464 -> 140309915474720
	140309915474720 [label=AccumulateGrad]
	140309915474240 -> 140309915474096
	140309201043520 [label="stage3.2.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140309201043520 -> 140309915474240
	140309915474240 [label=AccumulateGrad]
	140309915474672 -> 140309915473856
	140309915474144 -> 140309915473616
	140309201043920 [label="stage3.2.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309201043920 -> 140309915474144
	140309915474144 [label=AccumulateGrad]
	140309915472128 -> 140309915473184
	140309201044000 [label="stage3.2.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140309201044000 -> 140309915472128
	140309915472128 [label=AccumulateGrad]
	140309915471984 -> 140309915473184
	140309201044080 [label="stage3.2.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140309201044080 -> 140309915471984
	140309915471984 [label=AccumulateGrad]
	140309915286064 -> 140309915285344
	140309201044480 [label="stage3.2.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309201044480 -> 140309915286064
	140309915286064 [label=AccumulateGrad]
	140309915285584 -> 140309917389248
	140309201044560 [label="stage3.2.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140309201044560 -> 140309915285584
	140309915285584 [label=AccumulateGrad]
	140309915283712 -> 140309917389248
	140309201044640 [label="stage3.2.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140309201044640 -> 140309915283712
	140309915283712 [label=AccumulateGrad]
	140309917389872 -> 140309917408800
	140309917406496 -> 140309917406304
	140309201045600 [label="stage3.2.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140309201045600 -> 140309917406496
	140309917406496 [label=AccumulateGrad]
	140309917405632 -> 140309917377392
	140309201045680 [label="stage3.2.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140309201045680 -> 140309917405632
	140309917405632 [label=AccumulateGrad]
	140309917405248 -> 140309917377392
	140309201045760 [label="stage3.2.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140309201045760 -> 140309917405248
	140309917405248 [label=AccumulateGrad]
	140309917421280 -> 140309917420992
	140309203002848 [label="stage3.3.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309203002848 -> 140309917421280
	140309917421280 [label=AccumulateGrad]
	140309917420848 -> 140309917420944
	140309203002928 [label="stage3.3.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140309203002928 -> 140309917420848
	140309917420848 [label=AccumulateGrad]
	140309917421088 -> 140309917420944
	140309203003008 [label="stage3.3.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140309203003008 -> 140309917421088
	140309917421088 [label=AccumulateGrad]
	140309917420752 -> 140309917420608
	140309203003408 [label="stage3.3.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309203003408 -> 140309917420752
	140309917420752 [label=AccumulateGrad]
	140309917420560 -> 140309917420368
	140309203003488 [label="stage3.3.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140309203003488 -> 140309917420560
	140309917420560 [label=AccumulateGrad]
	140309917420512 -> 140309917420368
	140309203003568 [label="stage3.3.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140309203003568 -> 140309917420512
	140309917420512 [label=AccumulateGrad]
	140309917420128 -> 140309917420320
	140309917420224 -> 140309917419936
	140309203003968 [label="stage3.3.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309203003968 -> 140309917420224
	140309917420224 [label=AccumulateGrad]
	140309917419792 -> 140309917419888
	140309203004048 [label="stage3.3.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140309203004048 -> 140309917419792
	140309917419792 [label=AccumulateGrad]
	140309917420032 -> 140309917419888
	140309203004128 [label="stage3.3.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140309203004128 -> 140309917420032
	140309917420032 [label=AccumulateGrad]
	140309917419696 -> 140309917419552
	140309203004528 [label="stage3.3.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309203004528 -> 140309917419696
	140309917419696 [label=AccumulateGrad]
	140309917419504 -> 140309917419312
	140309203004608 [label="stage3.3.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140309203004608 -> 140309917419504
	140309917419504 [label=AccumulateGrad]
	140309917419456 -> 140309917419312
	140309203004688 [label="stage3.3.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140309203004688 -> 140309917419456
	140309917419456 [label=AccumulateGrad]
	140309917419072 -> 140309917419264
	140309917419168 -> 140309917418880
	140309203005088 [label="stage3.3.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309203005088 -> 140309917419168
	140309917419168 [label=AccumulateGrad]
	140309917418736 -> 140309917418832
	140309203005168 [label="stage3.3.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140309203005168 -> 140309917418736
	140309917418736 [label=AccumulateGrad]
	140309917418976 -> 140309917418832
	140309203005248 [label="stage3.3.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140309203005248 -> 140309917418976
	140309917418976 [label=AccumulateGrad]
	140309917418640 -> 140309917418496
	140309203140912 [label="stage3.3.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309203140912 -> 140309917418640
	140309917418640 [label=AccumulateGrad]
	140309917418448 -> 140309917418256
	140309203140992 [label="stage3.3.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140309203140992 -> 140309917418448
	140309917418448 [label=AccumulateGrad]
	140309917418400 -> 140309917418256
	140309203141072 [label="stage3.3.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140309203141072 -> 140309917418400
	140309917418400 [label=AccumulateGrad]
	140309917418016 -> 140309917418208
	140309917418112 -> 140309917417824
	140309203141472 [label="stage3.3.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309203141472 -> 140309917418112
	140309917418112 [label=AccumulateGrad]
	140309917417680 -> 140309917417776
	140309203141552 [label="stage3.3.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140309203141552 -> 140309917417680
	140309917417680 [label=AccumulateGrad]
	140309917417920 -> 140309917417776
	140309203141632 [label="stage3.3.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140309203141632 -> 140309917417920
	140309917417920 [label=AccumulateGrad]
	140309917417584 -> 140309917437856
	140309203142032 [label="stage3.3.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309203142032 -> 140309917417584
	140309917417584 [label=AccumulateGrad]
	140309917437808 -> 140309917437616
	140309203142112 [label="stage3.3.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140309203142112 -> 140309917437808
	140309917437808 [label=AccumulateGrad]
	140309917437760 -> 140309917437616
	140309203142192 [label="stage3.3.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140309203142192 -> 140309917437760
	140309917437760 [label=AccumulateGrad]
	140309917437472 -> 140309917437568
	140309917437376 -> 140309917437184
	140309917437376 [label=UpsampleNearest2DBackward1]
	140309917437904 -> 140309917437376
	140309917437904 [label=NativeBatchNormBackward0]
	140309915344704 -> 140309917437904
	140309915344704 [label=ConvolutionBackward0]
	140309917418352 -> 140309915344704
	140309917418352 [label=ReluBackward0]
	140309917418592 -> 140309917418352
	140309917418592 [label=AddBackward0]
	140309917418784 -> 140309917418592
	140309917418784 [label=NativeBatchNormBackward0]
	140309917419216 -> 140309917418784
	140309917419216 [label=ConvolutionBackward0]
	140309917419840 -> 140309917419216
	140309917419840 [label=ReluBackward0]
	140309917420272 -> 140309917419840
	140309917420272 [label=NativeBatchNormBackward0]
	140309917420704 -> 140309917420272
	140309917420704 [label=ConvolutionBackward0]
	140309917419024 -> 140309917420704
	140309917419024 [label=ReluBackward0]
	140309917389152 -> 140309917419024
	140309917389152 [label=AddBackward0]
	140309917420896 -> 140309917389152
	140309917420896 [label=NativeBatchNormBackward0]
	140309915287072 -> 140309917420896
	140309915287072 [label=ConvolutionBackward0]
	140309915475152 -> 140309915287072
	140309915475152 [label=ReluBackward0]
	140309915475104 -> 140309915475152
	140309915475104 [label=NativeBatchNormBackward0]
	140309915475488 -> 140309915475104
	140309915475488 [label=ConvolutionBackward0]
	140309917406928 -> 140309915475488
	140309917406928 [label=ReluBackward0]
	140310157144704 -> 140309917406928
	140310157144704 [label=AddBackward0]
	140310157144416 -> 140310157144704
	140310157144416 [label=NativeBatchNormBackward0]
	140310157144800 -> 140310157144416
	140310157144800 [label=ConvolutionBackward0]
	140310157145376 -> 140310157144800
	140310157145376 [label=ReluBackward0]
	140310157145760 -> 140310157145376
	140310157145760 [label=NativeBatchNormBackward0]
	140310157146864 -> 140310157145760
	140310157146864 [label=ConvolutionBackward0]
	140310157144608 -> 140310157146864
	140310157144608 [label=ReluBackward0]
	140310157147056 -> 140310157144608
	140310157147056 [label=AddBackward0]
	140310157147152 -> 140310157147056
	140310157147152 [label=NativeBatchNormBackward0]
	140310157147296 -> 140310157147152
	140310157147296 [label=ConvolutionBackward0]
	140310157147488 -> 140310157147296
	140310157147488 [label=ReluBackward0]
	140310157147632 -> 140310157147488
	140310157147632 [label=NativeBatchNormBackward0]
	140310157147728 -> 140310157147632
	140310157147728 [label=ConvolutionBackward0]
	140310157147104 -> 140310157147728
	140310157147104 [label=ReluBackward0]
	140310157148016 -> 140310157147104
	140310157148016 [label=AddBackward0]
	140310157148112 -> 140310157148016
	140310157148112 [label=AddBackward0]
	140310157217952 -> 140310157148112
	140310157217952 [label=NativeBatchNormBackward0]
	140310157218048 -> 140310157217952
	140310157218048 [label=ConvolutionBackward0]
	140309917405344 -> 140310157218048
	140310157218240 -> 140310157218048
	140309201046160 [label="stage3.2.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140309201046160 -> 140310157218240
	140310157218240 [label=AccumulateGrad]
	140310157218000 -> 140310157217952
	140309201046240 [label="stage3.2.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140309201046240 -> 140310157218000
	140310157218000 [label=AccumulateGrad]
	140310157217856 -> 140310157217952
	140309201046320 [label="stage3.2.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140309201046320 -> 140310157217856
	140310157217856 [label=AccumulateGrad]
	140309917406688 -> 140310157148112
	140310157148064 -> 140310157148016
	140310157148064 [label=UpsampleNearest2DBackward1]
	140310157218192 -> 140310157148064
	140310157218192 [label=NativeBatchNormBackward0]
	140310157218288 -> 140310157218192
	140310157218288 [label=ConvolutionBackward0]
	140309917407984 -> 140310157218288
	140310157218480 -> 140310157218288
	140309201046720 [label="stage3.2.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140309201046720 -> 140310157218480
	140310157218480 [label=AccumulateGrad]
	140310157218336 -> 140310157218192
	140309201046800 [label="stage3.2.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140309201046800 -> 140310157218336
	140310157218336 [label=AccumulateGrad]
	140310157217904 -> 140310157218192
	140309201046880 [label="stage3.2.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140309201046880 -> 140310157217904
	140310157217904 [label=AccumulateGrad]
	140310157147920 -> 140310157147728
	140309203142592 [label="stage3.3.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309203142592 -> 140310157147920
	140310157147920 [label=AccumulateGrad]
	140310157147680 -> 140310157147632
	140309203142672 [label="stage3.3.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140309203142672 -> 140310157147680
	140310157147680 [label=AccumulateGrad]
	140310157147536 -> 140310157147632
	140309203142752 [label="stage3.3.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140309203142752 -> 140310157147536
	140310157147536 [label=AccumulateGrad]
	140310157147440 -> 140310157147296
	140309203143152 [label="stage3.3.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309203143152 -> 140310157147440
	140310157147440 [label=AccumulateGrad]
	140310157147248 -> 140310157147152
	140309203143232 [label="stage3.3.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140309203143232 -> 140310157147248
	140310157147248 [label=AccumulateGrad]
	140310157147200 -> 140310157147152
	140309203143312 [label="stage3.3.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140309203143312 -> 140310157147200
	140310157147200 [label=AccumulateGrad]
	140310157147104 -> 140310157147056
	140310157146960 -> 140310157146864
	140309203143712 [label="stage3.3.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309203143712 -> 140310157146960
	140310157146960 [label=AccumulateGrad]
	140310157146624 -> 140310157145760
	140309203143792 [label="stage3.3.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140309203143792 -> 140310157146624
	140310157146624 [label=AccumulateGrad]
	140310157145616 -> 140310157145760
	140309203143872 [label="stage3.3.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140309203143872 -> 140310157145616
	140310157145616 [label=AccumulateGrad]
	140310157145568 -> 140310157144800
	140309203144272 [label="stage3.3.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309203144272 -> 140310157145568
	140310157145568 [label=AccumulateGrad]
	140310157144656 -> 140310157144416
	140309203144352 [label="stage3.3.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140309203144352 -> 140310157144656
	140310157144656 [label=AccumulateGrad]
	140310157145136 -> 140310157144416
	140309203144432 [label="stage3.3.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140309203144432 -> 140310157145136
	140310157145136 [label=AccumulateGrad]
	140310157144608 -> 140310157144704
	140309915475680 -> 140309915475488
	140309203620064 [label="stage3.3.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309203620064 -> 140309915475680
	140309915475680 [label=AccumulateGrad]
	140309915475584 -> 140309915475104
	140309203620144 [label="stage3.3.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140309203620144 -> 140309915475584
	140309915475584 [label=AccumulateGrad]
	140309915473280 -> 140309915475104
	140309203620224 [label="stage3.3.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140309203620224 -> 140309915473280
	140309915473280 [label=AccumulateGrad]
	140309915472704 -> 140309915287072
	140309203620624 [label="stage3.3.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309203620624 -> 140309915472704
	140309915472704 [label=AccumulateGrad]
	140309915284096 -> 140309917420896
	140309203620704 [label="stage3.3.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140309203620704 -> 140309915284096
	140309915284096 [label=AccumulateGrad]
	140309917408512 -> 140309917420896
	140309203620784 [label="stage3.3.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140309203620784 -> 140309917408512
	140309917408512 [label=AccumulateGrad]
	140309917406928 -> 140309917389152
	140309917421520 -> 140309917420704
	140309203621184 [label="stage3.3.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309203621184 -> 140309917421520
	140309917421520 [label=AccumulateGrad]
	140309917420656 -> 140309917420272
	140309203621264 [label="stage3.3.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140309203621264 -> 140309917420656
	140309917420656 [label=AccumulateGrad]
	140309917420176 -> 140309917420272
	140309203621344 [label="stage3.3.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140309203621344 -> 140309917420176
	140309917420176 [label=AccumulateGrad]
	140309917420080 -> 140309917419216
	140309203621744 [label="stage3.3.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309203621744 -> 140309917420080
	140309917420080 [label=AccumulateGrad]
	140309917419408 -> 140309917418784
	140309203621824 [label="stage3.3.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140309203621824 -> 140309917419408
	140309917419408 [label=AccumulateGrad]
	140309917419120 -> 140309917418784
	140309203621904 [label="stage3.3.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140309203621904 -> 140309917419120
	140309917419120 [label=AccumulateGrad]
	140309917419024 -> 140309917418592
	140309917418064 -> 140309915344704
	140309203753856 [label="stage3.3.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140309203753856 -> 140309917418064
	140309917418064 [label=AccumulateGrad]
	140309917437520 -> 140309917437904
	140309203753936 [label="stage3.3.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140309203753936 -> 140309917437520
	140309917437520 [label=AccumulateGrad]
	140309917417536 -> 140309917437904
	140309203754016 [label="stage3.3.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140309203754016 -> 140309917417536
	140309917417536 [label=AccumulateGrad]
	140309917436944 -> 140309917437136
	140309917436944 [label=UpsampleNearest2DBackward1]
	140309917406064 -> 140309917436944
	140309917406064 [label=NativeBatchNormBackward0]
	140309917437328 -> 140309917406064
	140309917437328 [label=ConvolutionBackward0]
	140309917419648 -> 140309917437328
	140309917419648 [label=ReluBackward0]
	140309917421232 -> 140309917419648
	140309917421232 [label=AddBackward0]
	140309917421328 -> 140309917421232
	140309917421328 [label=NativeBatchNormBackward0]
	140309915475296 -> 140309917421328
	140309915475296 [label=ConvolutionBackward0]
	140310157144224 -> 140309915475296
	140310157144224 [label=ReluBackward0]
	140310157146912 -> 140310157144224
	140310157146912 [label=NativeBatchNormBackward0]
	140310157147344 -> 140310157146912
	140310157147344 [label=ConvolutionBackward0]
	140309917421136 -> 140310157147344
	140309917421136 [label=ReluBackward0]
	140310157147584 -> 140309917421136
	140310157147584 [label=AddBackward0]
	140310157147968 -> 140310157147584
	140310157147968 [label=NativeBatchNormBackward0]
	140310157218432 -> 140310157147968
	140310157218432 [label=ConvolutionBackward0]
	140310157218624 -> 140310157218432
	140310157218624 [label=ReluBackward0]
	140310157218768 -> 140310157218624
	140310157218768 [label=NativeBatchNormBackward0]
	140310157218864 -> 140310157218768
	140310157218864 [label=ConvolutionBackward0]
	140310157147824 -> 140310157218864
	140310157147824 [label=ReluBackward0]
	140310157219152 -> 140310157147824
	140310157219152 [label=AddBackward0]
	140310157219248 -> 140310157219152
	140310157219248 [label=NativeBatchNormBackward0]
	140310157219392 -> 140310157219248
	140310157219392 [label=ConvolutionBackward0]
	140310157219584 -> 140310157219392
	140310157219584 [label=ReluBackward0]
	140310157219728 -> 140310157219584
	140310157219728 [label=NativeBatchNormBackward0]
	140310157219824 -> 140310157219728
	140310157219824 [label=ConvolutionBackward0]
	140310157219200 -> 140310157219824
	140310157219200 [label=ReluBackward0]
	140310157220112 -> 140310157219200
	140310157220112 [label=AddBackward0]
	140310157220208 -> 140310157220112
	140310157220208 [label=NativeBatchNormBackward0]
	140310157220352 -> 140310157220208
	140310157220352 [label=ConvolutionBackward0]
	140310157220544 -> 140310157220352
	140310157220544 [label=ReluBackward0]
	140310157220688 -> 140310157220544
	140310157220688 [label=NativeBatchNormBackward0]
	140310157220784 -> 140310157220688
	140310157220784 [label=ConvolutionBackward0]
	140310157220160 -> 140310157220784
	140310157220160 [label=ReluBackward0]
	140310157221072 -> 140310157220160
	140310157221072 [label=AddBackward0]
	140310157221168 -> 140310157221072
	140310157221168 [label=AddBackward0]
	140310157221264 -> 140310157221168
	140310157221264 [label=NativeBatchNormBackward0]
	140310157221408 -> 140310157221264
	140310157221408 [label=ConvolutionBackward0]
	140310157221600 -> 140310157221408
	140310157221600 [label=ReluBackward0]
	140310157221744 -> 140310157221600
	140310157221744 [label=NativeBatchNormBackward0]
	140310157221840 -> 140310157221744
	140310157221840 [label=ConvolutionBackward0]
	140309917405344 -> 140310157221840
	140310157246672 -> 140310157221840
	140309201047280 [label="stage3.2.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309201047280 -> 140310157246672
	140310157246672 [label=AccumulateGrad]
	140310157221792 -> 140310157221744
	140309201047360 [label="stage3.2.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140309201047360 -> 140310157221792
	140310157221792 [label=AccumulateGrad]
	140310157221648 -> 140310157221744
	140309201047440 [label="stage3.2.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140309201047440 -> 140310157221648
	140310157221648 [label=AccumulateGrad]
	140310157221552 -> 140310157221408
	140309203001728 [label="stage3.2.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140309203001728 -> 140310157221552
	140310157221552 [label=AccumulateGrad]
	140310157221360 -> 140310157221264
	140309203001808 [label="stage3.2.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140309203001808 -> 140310157221360
	140310157221360 [label=AccumulateGrad]
	140310157221312 -> 140310157221264
	140309203001888 [label="stage3.2.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140309203001888 -> 140310157221312
	140310157221312 [label=AccumulateGrad]
	140310157221216 -> 140310157221168
	140310157221216 [label=NativeBatchNormBackward0]
	140310157221696 -> 140310157221216
	140310157221696 [label=ConvolutionBackward0]
	140309917406688 -> 140310157221696
	140310157246720 -> 140310157221696
	140309203002288 [label="stage3.2.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140309203002288 -> 140310157246720
	140310157246720 [label=AccumulateGrad]
	140310157221504 -> 140310157221216
	140309203002368 [label="stage3.2.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140309203002368 -> 140310157221504
	140310157221504 [label=AccumulateGrad]
	140310157221456 -> 140310157221216
	140309203002448 [label="stage3.2.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140309203002448 -> 140310157221456
	140310157221456 [label=AccumulateGrad]
	140309917407984 -> 140310157221072
	140310157220976 -> 140310157220784
	140309203622304 [label="stage3.3.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309203622304 -> 140310157220976
	140310157220976 [label=AccumulateGrad]
	140310157220736 -> 140310157220688
	140309203622384 [label="stage3.3.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140309203622384 -> 140310157220736
	140310157220736 [label=AccumulateGrad]
	140310157220592 -> 140310157220688
	140309203622464 [label="stage3.3.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140309203622464 -> 140310157220592
	140310157220592 [label=AccumulateGrad]
	140310157220496 -> 140310157220352
	140309203622864 [label="stage3.3.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309203622864 -> 140310157220496
	140310157220496 [label=AccumulateGrad]
	140310157220304 -> 140310157220208
	140309203622944 [label="stage3.3.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140309203622944 -> 140310157220304
	140310157220304 [label=AccumulateGrad]
	140310157220256 -> 140310157220208
	140309203623024 [label="stage3.3.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140309203623024 -> 140310157220256
	140310157220256 [label=AccumulateGrad]
	140310157220160 -> 140310157220112
	140310157220016 -> 140310157219824
	140309203623424 [label="stage3.3.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309203623424 -> 140310157220016
	140310157220016 [label=AccumulateGrad]
	140310157219776 -> 140310157219728
	140309203623504 [label="stage3.3.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140309203623504 -> 140310157219776
	140310157219776 [label=AccumulateGrad]
	140310157219632 -> 140310157219728
	140309203623584 [label="stage3.3.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140309203623584 -> 140310157219632
	140310157219632 [label=AccumulateGrad]
	140310157219536 -> 140310157219392
	140309203751056 [label="stage3.3.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309203751056 -> 140310157219536
	140310157219536 [label=AccumulateGrad]
	140310157219344 -> 140310157219248
	140309203751136 [label="stage3.3.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140309203751136 -> 140310157219344
	140310157219344 [label=AccumulateGrad]
	140310157219296 -> 140310157219248
	140309203751216 [label="stage3.3.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140309203751216 -> 140310157219296
	140310157219296 [label=AccumulateGrad]
	140310157219200 -> 140310157219152
	140310157219056 -> 140310157218864
	140309203751616 [label="stage3.3.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309203751616 -> 140310157219056
	140310157219056 [label=AccumulateGrad]
	140310157218816 -> 140310157218768
	140309203751696 [label="stage3.3.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140309203751696 -> 140310157218816
	140310157218816 [label=AccumulateGrad]
	140310157218672 -> 140310157218768
	140309203751776 [label="stage3.3.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140309203751776 -> 140310157218672
	140310157218672 [label=AccumulateGrad]
	140310157218384 -> 140310157218432
	140309203752176 [label="stage3.3.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309203752176 -> 140310157218384
	140310157218384 [label=AccumulateGrad]
	140310157218144 -> 140310157147968
	140309203752256 [label="stage3.3.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140309203752256 -> 140310157218144
	140310157218144 [label=AccumulateGrad]
	140310157218096 -> 140310157147968
	140309203752336 [label="stage3.3.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140309203752336 -> 140310157218096
	140310157218096 [label=AccumulateGrad]
	140310157147824 -> 140310157147584
	140310157147872 -> 140310157147344
	140309203752736 [label="stage3.3.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309203752736 -> 140310157147872
	140310157147872 [label=AccumulateGrad]
	140310157145856 -> 140310157146912
	140309203752816 [label="stage3.3.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140309203752816 -> 140310157145856
	140310157145856 [label=AccumulateGrad]
	140310157145664 -> 140310157146912
	140309203752896 [label="stage3.3.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140309203752896 -> 140310157145664
	140310157145664 [label=AccumulateGrad]
	140310157144176 -> 140309915475296
	140309203753296 [label="stage3.3.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309203753296 -> 140310157144176
	140310157144176 [label=AccumulateGrad]
	140309915475536 -> 140309917421328
	140309203753376 [label="stage3.3.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140309203753376 -> 140309915475536
	140309915475536 [label=AccumulateGrad]
	140309915472944 -> 140309917421328
	140309203753456 [label="stage3.3.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140309203753456 -> 140309915472944
	140309915472944 [label=AccumulateGrad]
	140309917421136 -> 140309917421232
	140309917419600 -> 140309917437328
	140309203754416 [label="stage3.3.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140309203754416 -> 140309917419600
	140309917419600 [label=AccumulateGrad]
	140309917417728 -> 140309917406064
	140309203754496 [label="stage3.3.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140309203754496 -> 140309917417728
	140309917417728 [label=AccumulateGrad]
	140309917417968 -> 140309917406064
	140309203754576 [label="stage3.3.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140309203754576 -> 140309917417968
	140309917417968 [label=AccumulateGrad]
	140309917437040 -> 140309917436752
	140309337546080 [label="stage4.0.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309337546080 -> 140309917437040
	140309917437040 [label=AccumulateGrad]
	140309917436608 -> 140309917436704
	140309337546160 [label="stage4.0.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140309337546160 -> 140309917436608
	140309917436608 [label=AccumulateGrad]
	140309917436848 -> 140309917436704
	140309337546240 [label="stage4.0.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140309337546240 -> 140309917436848
	140309917436848 [label=AccumulateGrad]
	140309917436512 -> 140309917436368
	140309337546640 [label="stage4.0.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309337546640 -> 140309917436512
	140309917436512 [label=AccumulateGrad]
	140309917436320 -> 140309917436128
	140309337694272 [label="stage4.0.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140309337694272 -> 140309917436320
	140309917436320 [label=AccumulateGrad]
	140309917436272 -> 140309917436128
	140309337694352 [label="stage4.0.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140309337694352 -> 140309917436272
	140309917436272 [label=AccumulateGrad]
	140309917435888 -> 140309917436080
	140309917435984 -> 140309917435696
	140309337694752 [label="stage4.0.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309337694752 -> 140309917435984
	140309917435984 [label=AccumulateGrad]
	140309917435552 -> 140309917435648
	140309337694832 [label="stage4.0.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140309337694832 -> 140309917435552
	140309917435552 [label=AccumulateGrad]
	140309917435792 -> 140309917435648
	140309337694912 [label="stage4.0.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140309337694912 -> 140309917435792
	140309917435792 [label=AccumulateGrad]
	140309917435456 -> 140309917435312
	140309337695312 [label="stage4.0.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309337695312 -> 140309917435456
	140309917435456 [label=AccumulateGrad]
	140309917435264 -> 140309917435072
	140309337695392 [label="stage4.0.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140309337695392 -> 140309917435264
	140309917435264 [label=AccumulateGrad]
	140309917435216 -> 140309917435072
	140309337695472 [label="stage4.0.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140309337695472 -> 140309917435216
	140309917435216 [label=AccumulateGrad]
	140309917434832 -> 140309917435024
	140309917434928 -> 140309917434640
	140309337695872 [label="stage4.0.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309337695872 -> 140309917434928
	140309917434928 [label=AccumulateGrad]
	140309917434496 -> 140309917434592
	140309337695952 [label="stage4.0.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140309337695952 -> 140309917434496
	140309917434496 [label=AccumulateGrad]
	140309917434736 -> 140309917434592
	140309337696032 [label="stage4.0.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140309337696032 -> 140309917434736
	140309917434736 [label=AccumulateGrad]
	140309917434400 -> 140309917434256
	140309337696432 [label="stage4.0.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309337696432 -> 140309917434400
	140309917434400 [label=AccumulateGrad]
	140309917434208 -> 140309917434016
	140309337696512 [label="stage4.0.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140309337696512 -> 140309917434208
	140309917434208 [label=AccumulateGrad]
	140309917434160 -> 140309917434016
	140309337696592 [label="stage4.0.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140309337696592 -> 140309917434160
	140309917434160 [label=AccumulateGrad]
	140309917433920 -> 140309917446000
	140309917446096 -> 140309917445808
	140309337696992 [label="stage4.0.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309337696992 -> 140309917446096
	140309917446096 [label=AccumulateGrad]
	140309917445664 -> 140309917445760
	140309337697072 [label="stage4.0.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140309337697072 -> 140309917445664
	140309917445664 [label=AccumulateGrad]
	140309917445904 -> 140309917445760
	140309337697152 [label="stage4.0.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140309337697152 -> 140309917445904
	140309917445904 [label=AccumulateGrad]
	140309917445568 -> 140309917445424
	140309337697552 [label="stage4.0.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309337697552 -> 140309917445568
	140309917445568 [label=AccumulateGrad]
	140309917445376 -> 140309917445184
	140309337697632 [label="stage4.0.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140309337697632 -> 140309917445376
	140309917445376 [label=AccumulateGrad]
	140309917445328 -> 140309917445184
	140309337697712 [label="stage4.0.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140309337697712 -> 140309917445328
	140309917445328 [label=AccumulateGrad]
	140309917445040 -> 140309917445136
	140309917444944 -> 140309917444848
	140309917444944 [label=UpsampleNearest2DBackward1]
	140309917445472 -> 140309917444944
	140309917445472 [label=NativeBatchNormBackward0]
	140309917446048 -> 140309917445472
	140309917446048 [label=ConvolutionBackward0]
	140309917445712 -> 140309917446048
	140309917445712 [label=ReluBackward0]
	140309917434880 -> 140309917445712
	140309917434880 [label=AddBackward0]
	140309917434544 -> 140309917434880
	140309917434544 [label=NativeBatchNormBackward0]
	140309917434976 -> 140309917434544
	140309917434976 [label=ConvolutionBackward0]
	140309917435600 -> 140309917434976
	140309917435600 [label=ReluBackward0]
	140309917436032 -> 140309917435600
	140309917436032 [label=NativeBatchNormBackward0]
	140309917436992 -> 140309917436032
	140309917436992 [label=ConvolutionBackward0]
	140309917434784 -> 140309917436992
	140309917434784 [label=ReluBackward0]
	140309917437088 -> 140309917434784
	140309917437088 [label=AddBackward0]
	140309915473664 -> 140309917437088
	140309915473664 [label=NativeBatchNormBackward0]
	140309917420464 -> 140309915473664
	140309917420464 [label=ConvolutionBackward0]
	140310157147008 -> 140309917420464
	140310157147008 [label=ReluBackward0]
	140310157147776 -> 140310157147008
	140310157147776 [label=NativeBatchNormBackward0]
	140310157218912 -> 140310157147776
	140310157218912 [label=ConvolutionBackward0]
	140309915474048 -> 140310157218912
	140309915474048 [label=ReluBackward0]
	140310157219968 -> 140309915474048
	140310157219968 [label=AddBackward0]
	140310157219680 -> 140310157219968
	140310157219680 [label=NativeBatchNormBackward0]
	140310157220064 -> 140310157219680
	140310157220064 [label=ConvolutionBackward0]
	140310157220640 -> 140310157220064
	140310157220640 [label=ReluBackward0]
	140310157221024 -> 140310157220640
	140310157221024 [label=NativeBatchNormBackward0]
	140310157220880 -> 140310157221024
	140310157220880 [label=ConvolutionBackward0]
	140310157219872 -> 140310157220880
	140310157219872 [label=ReluBackward0]
	140310157246960 -> 140310157219872
	140310157246960 [label=AddBackward0]
	140310157247056 -> 140310157246960
	140310157247056 [label=NativeBatchNormBackward0]
	140310157247200 -> 140310157247056
	140310157247200 [label=ConvolutionBackward0]
	140310157247392 -> 140310157247200
	140310157247392 [label=ReluBackward0]
	140310157247536 -> 140310157247392
	140310157247536 [label=NativeBatchNormBackward0]
	140310157247632 -> 140310157247536
	140310157247632 [label=ConvolutionBackward0]
	140310157247008 -> 140310157247632
	140310157247008 [label=ReluBackward0]
	140310157247920 -> 140310157247008
	140310157247920 [label=AddBackward0]
	140310157248016 -> 140310157247920
	140310157248016 [label=AddBackward0]
	140310157248160 -> 140310157248016
	140310157248160 [label=NativeBatchNormBackward0]
	140310157248256 -> 140310157248160
	140310157248256 [label=ConvolutionBackward0]
	140309917437424 -> 140310157248256
	140310157248448 -> 140310157248256
	140309337542720 [label="stage3.3.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140309337542720 -> 140310157248448
	140310157248448 [label=AccumulateGrad]
	140310157248208 -> 140310157248160
	140309337542800 [label="stage3.3.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140309337542800 -> 140310157248208
	140310157248208 [label=AccumulateGrad]
	140310157248064 -> 140310157248160
	140309337542880 [label="stage3.3.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140309337542880 -> 140310157248064
	140310157248064 [label=AccumulateGrad]
	140309917418352 -> 140310157248016
	140310157247968 -> 140310157247920
	140310157247968 [label=UpsampleNearest2DBackward1]
	140310157248400 -> 140310157247968
	140310157248400 [label=NativeBatchNormBackward0]
	140310157248496 -> 140310157248400
	140310157248496 [label=ConvolutionBackward0]
	140309917419648 -> 140310157248496
	140310157248688 -> 140310157248496
	140309337543280 [label="stage3.3.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140309337543280 -> 140310157248688
	140310157248688 [label=AccumulateGrad]
	140310157248544 -> 140310157248400
	140309337543360 [label="stage3.3.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140309337543360 -> 140310157248544
	140310157248544 [label=AccumulateGrad]
	140310157248112 -> 140310157248400
	140309337543440 [label="stage3.3.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140309337543440 -> 140310157248112
	140310157248112 [label=AccumulateGrad]
	140310157247824 -> 140310157247632
	140309337698112 [label="stage4.0.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309337698112 -> 140310157247824
	140310157247824 [label=AccumulateGrad]
	140310157247584 -> 140310157247536
	140309337698192 [label="stage4.0.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140309337698192 -> 140310157247584
	140310157247584 [label=AccumulateGrad]
	140310157247440 -> 140310157247536
	140309338701888 [label="stage4.0.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140309338701888 -> 140310157247440
	140310157247440 [label=AccumulateGrad]
	140310157247344 -> 140310157247200
	140309338702288 [label="stage4.0.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309338702288 -> 140310157247344
	140310157247344 [label=AccumulateGrad]
	140310157247152 -> 140310157247056
	140309338702368 [label="stage4.0.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140309338702368 -> 140310157247152
	140310157247152 [label=AccumulateGrad]
	140310157247104 -> 140310157247056
	140309338702448 [label="stage4.0.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140309338702448 -> 140310157247104
	140310157247104 [label=AccumulateGrad]
	140310157247008 -> 140310157246960
	140310157246864 -> 140310157220880
	140309338702848 [label="stage4.0.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309338702848 -> 140310157246864
	140310157246864 [label=AccumulateGrad]
	140310157246768 -> 140310157221024
	140309338702928 [label="stage4.0.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140309338702928 -> 140310157246768
	140310157246768 [label=AccumulateGrad]
	140310157246624 -> 140310157221024
	140309338703008 [label="stage4.0.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140309338703008 -> 140310157246624
	140310157246624 [label=AccumulateGrad]
	140310157220832 -> 140310157220064
	140309338703408 [label="stage4.0.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309338703408 -> 140310157220832
	140310157220832 [label=AccumulateGrad]
	140310157219920 -> 140310157219680
	140309338703488 [label="stage4.0.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140309338703488 -> 140310157219920
	140310157219920 [label=AccumulateGrad]
	140310157220400 -> 140310157219680
	140309338703568 [label="stage4.0.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140309338703568 -> 140310157220400
	140310157220400 [label=AccumulateGrad]
	140310157219872 -> 140310157219968
	140310157219104 -> 140310157218912
	140309338703968 [label="stage4.0.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309338703968 -> 140310157219104
	140310157219104 [label=AccumulateGrad]
	140310157219008 -> 140310157147776
	140309338704048 [label="stage4.0.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140309338704048 -> 140310157219008
	140310157219008 [label=AccumulateGrad]
	140310157218576 -> 140310157147776
	140309338704128 [label="stage4.0.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140309338704128 -> 140310157218576
	140310157218576 [label=AccumulateGrad]
	140310157146432 -> 140309917420464
	140309338704528 [label="stage4.0.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309338704528 -> 140310157146432
	140310157146432 [label=AccumulateGrad]
	140309917418544 -> 140309915473664
	140309338704608 [label="stage4.0.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140309338704608 -> 140309917418544
	140309917418544 [label=AccumulateGrad]
	140310157145184 -> 140309915473664
	140309338704688 [label="stage4.0.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140309338704688 -> 140310157145184
	140310157145184 [label=AccumulateGrad]
	140309915474048 -> 140309917437088
	140309917437280 -> 140309917436992
	140309338705088 [label="stage4.0.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309338705088 -> 140309917437280
	140309917437280 [label=AccumulateGrad]
	140309917436464 -> 140309917436032
	140309338705168 [label="stage4.0.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140309338705168 -> 140309917436464
	140309917436464 [label=AccumulateGrad]
	140309917436416 -> 140309917436032
	140309338705248 [label="stage4.0.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140309338705248 -> 140309917436416
	140309917436416 [label=AccumulateGrad]
	140309917435840 -> 140309917434976
	140309338705648 [label="stage4.0.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309338705648 -> 140309917435840
	140309917435840 [label=AccumulateGrad]
	140309917435168 -> 140309917434544
	140309338705728 [label="stage4.0.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140309338705728 -> 140309917435168
	140309917435168 [label=AccumulateGrad]
	140309917435360 -> 140309917434544
	140309338705808 [label="stage4.0.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140309338705808 -> 140309917435360
	140309917435360 [label=AccumulateGrad]
	140309917434784 -> 140309917434880
	140309917434112 -> 140309917446048
	140309339796800 [label="stage4.0.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140309339796800 -> 140309917434112
	140309917434112 [label=AccumulateGrad]
	140309917445520 -> 140309917445472
	140309339796880 [label="stage4.0.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140309339796880 -> 140309917445520
	140309917445520 [label=AccumulateGrad]
	140309917445088 -> 140309917445472
	140309339796960 [label="stage4.0.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140309339796960 -> 140309917445088
	140309917445088 [label=AccumulateGrad]
	140309917444800 -> 140309917444608
	140309917444800 [label=UpsampleNearest2DBackward1]
	140309917445952 -> 140309917444800
	140309917445952 [label=NativeBatchNormBackward0]
	140309917418160 -> 140309917445952
	140309917418160 [label=ConvolutionBackward0]
	140309917435936 -> 140309917418160
	140309917435936 [label=ReluBackward0]
	140309917437712 -> 140309917435936
	140309917437712 [label=AddBackward0]
	140309917436656 -> 140309917437712
	140309917436656 [label=NativeBatchNormBackward0]
	140310157146672 -> 140309917436656
	140310157146672 [label=ConvolutionBackward0]
	140310157219488 -> 140310157146672
	140310157219488 [label=ReluBackward0]
	140310157221120 -> 140310157219488
	140310157221120 [label=NativeBatchNormBackward0]
	140310157247248 -> 140310157221120
	140310157247248 [label=ConvolutionBackward0]
	140309917436896 -> 140310157247248
	140309917436896 [label=ReluBackward0]
	140310157247488 -> 140309917436896
	140310157247488 [label=AddBackward0]
	140310157247728 -> 140310157247488
	140310157247728 [label=NativeBatchNormBackward0]
	140310157248640 -> 140310157247728
	140310157248640 [label=ConvolutionBackward0]
	140310157248832 -> 140310157248640
	140310157248832 [label=ReluBackward0]
	140310157248976 -> 140310157248832
	140310157248976 [label=NativeBatchNormBackward0]
	140310157249072 -> 140310157248976
	140310157249072 [label=ConvolutionBackward0]
	140310157248304 -> 140310157249072
	140310157248304 [label=ReluBackward0]
	140310157249360 -> 140310157248304
	140310157249360 [label=AddBackward0]
	140310157249456 -> 140310157249360
	140310157249456 [label=NativeBatchNormBackward0]
	140310157249600 -> 140310157249456
	140310157249600 [label=ConvolutionBackward0]
	140310157249792 -> 140310157249600
	140310157249792 [label=ReluBackward0]
	140310157249936 -> 140310157249792
	140310157249936 [label=NativeBatchNormBackward0]
	140310157250032 -> 140310157249936
	140310157250032 [label=ConvolutionBackward0]
	140310157249408 -> 140310157250032
	140310157249408 [label=ReluBackward0]
	140310157250320 -> 140310157249408
	140310157250320 [label=AddBackward0]
	140310157250416 -> 140310157250320
	140310157250416 [label=NativeBatchNormBackward0]
	140310157250512 -> 140310157250416
	140310157250512 [label=ConvolutionBackward0]
	140310157312256 -> 140310157250512
	140310157312256 [label=ReluBackward0]
	140310157312400 -> 140310157312256
	140310157312400 [label=NativeBatchNormBackward0]
	140310157312496 -> 140310157312400
	140310157312496 [label=ConvolutionBackward0]
	140310157250368 -> 140310157312496
	140310157250368 [label=ReluBackward0]
	140310157312784 -> 140310157250368
	140310157312784 [label=AddBackward0]
	140310157312880 -> 140310157312784
	140310157312880 [label=AddBackward0]
	140310157312976 -> 140310157312880
	140310157312976 [label=NativeBatchNormBackward0]
	140310157313120 -> 140310157312976
	140310157313120 [label=ConvolutionBackward0]
	140310157313312 -> 140310157313120
	140310157313312 [label=ReluBackward0]
	140310157313456 -> 140310157313312
	140310157313456 [label=NativeBatchNormBackward0]
	140310157313552 -> 140310157313456
	140310157313552 [label=ConvolutionBackward0]
	140309917437424 -> 140310157313552
	140310157313744 -> 140310157313552
	140309337543840 [label="stage3.3.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309337543840 -> 140310157313744
	140310157313744 [label=AccumulateGrad]
	140310157313504 -> 140310157313456
	140309337543920 [label="stage3.3.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140309337543920 -> 140310157313504
	140310157313504 [label=AccumulateGrad]
	140310157313360 -> 140310157313456
	140309337544000 [label="stage3.3.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140309337544000 -> 140310157313360
	140310157313360 [label=AccumulateGrad]
	140310157313264 -> 140310157313120
	140309337544400 [label="stage3.3.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140309337544400 -> 140310157313264
	140310157313264 [label=AccumulateGrad]
	140310157313072 -> 140310157312976
	140309337544480 [label="stage3.3.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140309337544480 -> 140310157313072
	140310157313072 [label=AccumulateGrad]
	140310157313024 -> 140310157312976
	140309337544560 [label="stage3.3.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140309337544560 -> 140310157313024
	140310157313024 [label=AccumulateGrad]
	140310157312928 -> 140310157312880
	140310157312928 [label=NativeBatchNormBackward0]
	140310157313696 -> 140310157312928
	140310157313696 [label=ConvolutionBackward0]
	140309917418352 -> 140310157313696
	140310157313792 -> 140310157313696
	140309337544960 [label="stage3.3.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140309337544960 -> 140310157313792
	140310157313792 [label=AccumulateGrad]
	140310157313216 -> 140310157312928
	140309337545040 [label="stage3.3.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140309337545040 -> 140310157313216
	140310157313216 [label=AccumulateGrad]
	140310157313168 -> 140310157312928
	140309337545120 [label="stage3.3.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140309337545120 -> 140310157313168
	140310157313168 [label=AccumulateGrad]
	140309917419648 -> 140310157312784
	140310157312688 -> 140310157312496
	140309338816896 [label="stage4.0.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309338816896 -> 140310157312688
	140310157312688 [label=AccumulateGrad]
	140310157312448 -> 140310157312400
	140309338816976 [label="stage4.0.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140309338816976 -> 140310157312448
	140310157312448 [label=AccumulateGrad]
	140310157312304 -> 140310157312400
	140309338817056 [label="stage4.0.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140309338817056 -> 140310157312304
	140310157312304 [label=AccumulateGrad]
	140310157312208 -> 140310157250512
	140309338817456 [label="stage4.0.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309338817456 -> 140310157312208
	140310157312208 [label=AccumulateGrad]
	140310157250464 -> 140310157250416
	140309338817536 [label="stage4.0.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140309338817536 -> 140310157250464
	140310157250464 [label=AccumulateGrad]
	140310157312064 -> 140310157250416
	140309338817616 [label="stage4.0.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140309338817616 -> 140310157312064
	140310157312064 [label=AccumulateGrad]
	140310157250368 -> 140310157250320
	140310157250224 -> 140310157250032
	140309338818016 [label="stage4.0.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309338818016 -> 140310157250224
	140310157250224 [label=AccumulateGrad]
	140310157249984 -> 140310157249936
	140309338818096 [label="stage4.0.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140309338818096 -> 140310157249984
	140310157249984 [label=AccumulateGrad]
	140310157249840 -> 140310157249936
	140309338818176 [label="stage4.0.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140309338818176 -> 140310157249840
	140310157249840 [label=AccumulateGrad]
	140310157249744 -> 140310157249600
	140309338818576 [label="stage4.0.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309338818576 -> 140310157249744
	140310157249744 [label=AccumulateGrad]
	140310157249552 -> 140310157249456
	140309338818656 [label="stage4.0.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140309338818656 -> 140310157249552
	140310157249552 [label=AccumulateGrad]
	140310157249504 -> 140310157249456
	140309338818736 [label="stage4.0.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140309338818736 -> 140310157249504
	140310157249504 [label=AccumulateGrad]
	140310157249408 -> 140310157249360
	140310157249264 -> 140310157249072
	140309338819136 [label="stage4.0.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309338819136 -> 140310157249264
	140310157249264 [label=AccumulateGrad]
	140310157249024 -> 140310157248976
	140309338819216 [label="stage4.0.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140309338819216 -> 140310157249024
	140310157249024 [label=AccumulateGrad]
	140310157248880 -> 140310157248976
	140309338819296 [label="stage4.0.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140309338819296 -> 140310157248880
	140310157248880 [label=AccumulateGrad]
	140310157248592 -> 140310157248640
	140309338819696 [label="stage4.0.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309338819696 -> 140310157248592
	140310157248592 [label=AccumulateGrad]
	140310157248352 -> 140310157247728
	140309338819776 [label="stage4.0.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140309338819776 -> 140310157248352
	140310157248352 [label=AccumulateGrad]
	140310157247872 -> 140310157247728
	140309338819856 [label="stage4.0.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140309338819856 -> 140310157247872
	140310157247872 [label=AccumulateGrad]
	140310157248304 -> 140310157247488
	140310157247776 -> 140310157247248
	140309338820256 [label="stage4.0.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309338820256 -> 140310157247776
	140310157247776 [label=AccumulateGrad]
	140310157246816 -> 140310157221120
	140309338820336 [label="stage4.0.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140309338820336 -> 140310157246816
	140310157246816 [label=AccumulateGrad]
	140310157246528 -> 140310157221120
	140309338820416 [label="stage4.0.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140309338820416 -> 140310157246528
	140310157246528 [label=AccumulateGrad]
	140310157219440 -> 140310157146672
	140309339656496 [label="stage4.0.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140309339656496 -> 140310157219440
	140310157219440 [label=AccumulateGrad]
	140310157218720 -> 140309917436656
	140309339656576 [label="stage4.0.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140309339656576 -> 140310157218720
	140310157218720 [label=AccumulateGrad]
	140310157218960 -> 140309917436656
	140309339656656 [label="stage4.0.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140309339656656 -> 140310157218960
	140310157218960 [label=AccumulateGrad]
	140309917436896 -> 140309917437712
	140309917435408 -> 140309917418160
	140309339797360 [label="stage4.0.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140309339797360 -> 140309917435408
	140309917435408 [label=AccumulateGrad]
	140309917444896 -> 140309917445952
	140309339797440 [label="stage4.0.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140309339797440 -> 140309917444896
	140309917444896 [label=AccumulateGrad]
	140309917434304 -> 140309917445952
	140309339797520 [label="stage4.0.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140309339797520 -> 140309917434304
	140309917434304 [label=AccumulateGrad]
	140309917444368 -> 140309917444560
	140309917444368 [label=UpsampleNearest2DBackward1]
	140310157147392 -> 140309917444368
	140310157147392 [label=NativeBatchNormBackward0]
	140309917444752 -> 140310157147392
	140309917444752 [label=ConvolutionBackward0]
	140310157220928 -> 140309917444752
	140310157220928 [label=ReluBackward0]
	140310157248784 -> 140310157220928
	140310157248784 [label=AddBackward0]
	140310157247680 -> 140310157248784
	140310157247680 [label=NativeBatchNormBackward0]
	140310157249120 -> 140310157247680
	140310157249120 [label=ConvolutionBackward0]
	140310157249312 -> 140310157249120
	140310157249312 [label=ReluBackward0]
	140310157250080 -> 140310157249312
	140310157250080 [label=NativeBatchNormBackward0]
	140310157250128 -> 140310157250080
	140310157250128 [label=ConvolutionBackward0]
	140310157246912 -> 140310157250128
	140310157246912 [label=ReluBackward0]
	140310157312352 -> 140310157246912
	140310157312352 [label=AddBackward0]
	140310157312832 -> 140310157312352
	140310157312832 [label=NativeBatchNormBackward0]
	140310157313840 -> 140310157312832
	140310157313840 [label=ConvolutionBackward0]
	140310157313936 -> 140310157313840
	140310157313936 [label=ReluBackward0]
	140310157314080 -> 140310157313936
	140310157314080 [label=NativeBatchNormBackward0]
	140310157314176 -> 140310157314080
	140310157314176 [label=ConvolutionBackward0]
	140310157312592 -> 140310157314176
	140310157312592 [label=ReluBackward0]
	140310157314464 -> 140310157312592
	140310157314464 [label=AddBackward0]
	140310157314560 -> 140310157314464
	140310157314560 [label=NativeBatchNormBackward0]
	140310157314704 -> 140310157314560
	140310157314704 [label=ConvolutionBackward0]
	140310157314896 -> 140310157314704
	140310157314896 [label=ReluBackward0]
	140310157315040 -> 140310157314896
	140310157315040 [label=NativeBatchNormBackward0]
	140310157315136 -> 140310157315040
	140310157315136 [label=ConvolutionBackward0]
	140310157314512 -> 140310157315136
	140310157314512 [label=ReluBackward0]
	140310157315424 -> 140310157314512
	140310157315424 [label=AddBackward0]
	140310157315520 -> 140310157315424
	140310157315520 [label=NativeBatchNormBackward0]
	140310157315664 -> 140310157315520
	140310157315664 [label=ConvolutionBackward0]
	140310157315856 -> 140310157315664
	140310157315856 [label=ReluBackward0]
	140310157316000 -> 140310157315856
	140310157316000 [label=NativeBatchNormBackward0]
	140310157316048 -> 140310157316000
	140310157316048 [label=ConvolutionBackward0]
	140310157315472 -> 140310157316048
	140310157315472 [label=ReluBackward0]
	140310157336928 -> 140310157315472
	140310157336928 [label=NativeBatchNormBackward0]
	140310157337024 -> 140310157336928
	140310157337024 [label=ConvolutionBackward0]
	140310157250368 -> 140310157337024
	140310157337216 -> 140310157337024
	140309337545520 [label="transition3.3.0.0.weight
 (144, 72, 3, 3)" fillcolor=lightblue]
	140309337545520 -> 140310157337216
	140310157337216 [label=AccumulateGrad]
	140310157336976 -> 140310157336928
	140309337545600 [label="transition3.3.0.1.weight
 (144)" fillcolor=lightblue]
	140309337545600 -> 140310157336976
	140310157336976 [label=AccumulateGrad]
	140310157336736 -> 140310157336928
	140309337545680 [label="transition3.3.0.1.bias
 (144)" fillcolor=lightblue]
	140309337545680 -> 140310157336736
	140310157336736 [label=AccumulateGrad]
	140310157336832 -> 140310157316048
	140309339657056 [label="stage4.0.branches.3.0.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140309339657056 -> 140310157336832
	140310157336832 [label=AccumulateGrad]
	140310157315904 -> 140310157316000
	140309339657136 [label="stage4.0.branches.3.0.bn1.weight
 (144)" fillcolor=lightblue]
	140309339657136 -> 140310157315904
	140310157315904 [label=AccumulateGrad]
	140310157336640 -> 140310157316000
	140309339657216 [label="stage4.0.branches.3.0.bn1.bias
 (144)" fillcolor=lightblue]
	140309339657216 -> 140310157336640
	140310157336640 [label=AccumulateGrad]
	140310157315808 -> 140310157315664
	140309339657616 [label="stage4.0.branches.3.0.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140309339657616 -> 140310157315808
	140310157315808 [label=AccumulateGrad]
	140310157315616 -> 140310157315520
	140309339657696 [label="stage4.0.branches.3.0.bn2.weight
 (144)" fillcolor=lightblue]
	140309339657696 -> 140310157315616
	140310157315616 [label=AccumulateGrad]
	140310157315568 -> 140310157315520
	140309339657776 [label="stage4.0.branches.3.0.bn2.bias
 (144)" fillcolor=lightblue]
	140309339657776 -> 140310157315568
	140310157315568 [label=AccumulateGrad]
	140310157315472 -> 140310157315424
	140310157315328 -> 140310157315136
	140309339658176 [label="stage4.0.branches.3.1.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140309339658176 -> 140310157315328
	140310157315328 [label=AccumulateGrad]
	140310157315088 -> 140310157315040
	140309339658256 [label="stage4.0.branches.3.1.bn1.weight
 (144)" fillcolor=lightblue]
	140309339658256 -> 140310157315088
	140310157315088 [label=AccumulateGrad]
	140310157314944 -> 140310157315040
	140309339658336 [label="stage4.0.branches.3.1.bn1.bias
 (144)" fillcolor=lightblue]
	140309339658336 -> 140310157314944
	140310157314944 [label=AccumulateGrad]
	140310157314848 -> 140310157314704
	140309339658736 [label="stage4.0.branches.3.1.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140309339658736 -> 140310157314848
	140310157314848 [label=AccumulateGrad]
	140310157314656 -> 140310157314560
	140309339658816 [label="stage4.0.branches.3.1.bn2.weight
 (144)" fillcolor=lightblue]
	140309339658816 -> 140310157314656
	140310157314656 [label=AccumulateGrad]
	140310157314608 -> 140310157314560
	140309339658896 [label="stage4.0.branches.3.1.bn2.bias
 (144)" fillcolor=lightblue]
	140309339658896 -> 140310157314608
	140310157314608 [label=AccumulateGrad]
	140310157314512 -> 140310157314464
	140310157314368 -> 140310157314176
	140309339659296 [label="stage4.0.branches.3.2.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140309339659296 -> 140310157314368
	140310157314368 [label=AccumulateGrad]
	140310157314128 -> 140310157314080
	140309339659376 [label="stage4.0.branches.3.2.bn1.weight
 (144)" fillcolor=lightblue]
	140309339659376 -> 140310157314128
	140310157314128 [label=AccumulateGrad]
	140310157313984 -> 140310157314080
	140309339659456 [label="stage4.0.branches.3.2.bn1.bias
 (144)" fillcolor=lightblue]
	140309339659456 -> 140310157313984
	140310157313984 [label=AccumulateGrad]
	140310157313408 -> 140310157313840
	140309339659856 [label="stage4.0.branches.3.2.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140309339659856 -> 140310157313408
	140310157313408 [label=AccumulateGrad]
	140310157313600 -> 140310157312832
	140309339659936 [label="stage4.0.branches.3.2.bn2.weight
 (144)" fillcolor=lightblue]
	140309339659936 -> 140310157313600
	140310157313600 [label=AccumulateGrad]
	140310157312736 -> 140310157312832
	140309339660016 [label="stage4.0.branches.3.2.bn2.bias
 (144)" fillcolor=lightblue]
	140309339660016 -> 140310157312736
	140310157312736 [label=AccumulateGrad]
	140310157312592 -> 140310157312352
	140310157312640 -> 140310157250128
	140309339795680 [label="stage4.0.branches.3.3.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140309339795680 -> 140310157312640
	140310157312640 [label=AccumulateGrad]
	140310157249888 -> 140310157250080
	140309339795760 [label="stage4.0.branches.3.3.bn1.weight
 (144)" fillcolor=lightblue]
	140309339795760 -> 140310157249888
	140310157249888 [label=AccumulateGrad]
	140310157249696 -> 140310157250080
	140309339795840 [label="stage4.0.branches.3.3.bn1.bias
 (144)" fillcolor=lightblue]
	140309339795840 -> 140310157249696
	140310157249696 [label=AccumulateGrad]
	140310157249168 -> 140310157249120
	140309339796240 [label="stage4.0.branches.3.3.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140309339796240 -> 140310157249168
	140310157249168 [label=AccumulateGrad]
	140310157249216 -> 140310157247680
	140309339796320 [label="stage4.0.branches.3.3.bn2.weight
 (144)" fillcolor=lightblue]
	140309339796320 -> 140310157249216
	140310157249216 [label=AccumulateGrad]
	140310157248736 -> 140310157247680
	140309339796400 [label="stage4.0.branches.3.3.bn2.bias
 (144)" fillcolor=lightblue]
	140309339796400 -> 140310157248736
	140310157248736 [label=AccumulateGrad]
	140310157246912 -> 140310157248784
	140310157220448 -> 140309917444752
	140309339797920 [label="stage4.0.fuse_layers.0.3.0.weight
 (18, 144, 1, 1)" fillcolor=lightblue]
	140309339797920 -> 140310157220448
	140310157220448 [label=AccumulateGrad]
	140309917434352 -> 140310157147392
	140309339798000 [label="stage4.0.fuse_layers.0.3.1.weight
 (18)" fillcolor=lightblue]
	140309339798000 -> 140309917434352
	140309917434352 [label=AccumulateGrad]
	140309917433968 -> 140310157147392
	140309339798080 [label="stage4.0.fuse_layers.0.3.1.bias
 (18)" fillcolor=lightblue]
	140309339798080 -> 140309917433968
	140309917433968 [label=AccumulateGrad]
	140309917444464 -> 140309917444176
	140309347440896 [label="stage4.1.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309347440896 -> 140309917444464
	140309917444464 [label=AccumulateGrad]
	140309917444032 -> 140309917444128
	140309347440976 [label="stage4.1.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140309347440976 -> 140309917444032
	140309917444032 [label=AccumulateGrad]
	140309917444272 -> 140309917444128
	140309347441056 [label="stage4.1.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140309347441056 -> 140309917444272
	140309917444272 [label=AccumulateGrad]
	140309917443936 -> 140309917443792
	140309347441456 [label="stage4.1.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309347441456 -> 140309917443936
	140309917443936 [label=AccumulateGrad]
	140309917443744 -> 140309917443552
	140309347441536 [label="stage4.1.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140309347441536 -> 140309917443744
	140309917443744 [label=AccumulateGrad]
	140309917443696 -> 140309917443552
	140309347441616 [label="stage4.1.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140309347441616 -> 140309917443696
	140309917443696 [label=AccumulateGrad]
	140309917443312 -> 140309917443504
	140309917443408 -> 140309917443120
	140309347442016 [label="stage4.1.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309347442016 -> 140309917443408
	140309917443408 [label=AccumulateGrad]
	140309917442976 -> 140309917443072
	140309347442096 [label="stage4.1.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140309347442096 -> 140309917442976
	140309917442976 [label=AccumulateGrad]
	140309917443216 -> 140309917443072
	140309347442176 [label="stage4.1.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140309347442176 -> 140309917443216
	140309917443216 [label=AccumulateGrad]
	140309917442880 -> 140309917442736
	140309347442576 [label="stage4.1.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309347442576 -> 140309917442880
	140309917442880 [label=AccumulateGrad]
	140309917442688 -> 140309917442496
	140310424059968 [label="stage4.1.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140310424059968 -> 140309917442688
	140309917442688 [label=AccumulateGrad]
	140309917442640 -> 140309917442496
	140310424060048 [label="stage4.1.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140310424060048 -> 140309917442640
	140309917442640 [label=AccumulateGrad]
	140309917442256 -> 140309917442448
	140309917442352 -> 140309917458240
	140310424060448 [label="stage4.1.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310424060448 -> 140309917442352
	140309917442352 [label=AccumulateGrad]
	140309917442112 -> 140309917458336
	140310424060528 [label="stage4.1.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140310424060528 -> 140309917442112
	140309917442112 [label=AccumulateGrad]
	140309917442160 -> 140309917458336
	140310424060608 [label="stage4.1.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140310424060608 -> 140309917442160
	140309917442160 [label=AccumulateGrad]
	140309917458144 -> 140309917458000
	140310424061008 [label="stage4.1.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310424061008 -> 140309917458144
	140309917458144 [label=AccumulateGrad]
	140309917457952 -> 140309917457760
	140310424061088 [label="stage4.1.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140310424061088 -> 140309917457952
	140309917457952 [label=AccumulateGrad]
	140309917457904 -> 140309917457760
	140310424061168 [label="stage4.1.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140310424061168 -> 140309917457904
	140309917457904 [label=AccumulateGrad]
	140309917457520 -> 140309917457712
	140309917457616 -> 140309917457328
	140310424061568 [label="stage4.1.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310424061568 -> 140309917457616
	140309917457616 [label=AccumulateGrad]
	140309917457184 -> 140309917457280
	140310424061648 [label="stage4.1.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140310424061648 -> 140309917457184
	140309917457184 [label=AccumulateGrad]
	140309917457424 -> 140309917457280
	140310424061728 [label="stage4.1.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140310424061728 -> 140309917457424
	140309917457424 [label=AccumulateGrad]
	140309917457088 -> 140309917456944
	140310424062128 [label="stage4.1.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140310424062128 -> 140309917457088
	140309917457088 [label=AccumulateGrad]
	140309917456896 -> 140309917456704
	140310424062208 [label="stage4.1.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140310424062208 -> 140309917456896
	140309917456896 [label=AccumulateGrad]
	140309917456848 -> 140309917456704
	140310424062288 [label="stage4.1.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140310424062288 -> 140309917456848
	140309917456848 [label=AccumulateGrad]
	140309917456560 -> 140309917456656
	140309917456464 -> 140309917456368
	140309917456464 [label=UpsampleNearest2DBackward1]
	140309917456992 -> 140309917456464
	140309917456992 [label=NativeBatchNormBackward0]
	140309917457568 -> 140309917456992
	140309917457568 [label=ConvolutionBackward0]
	140309917457856 -> 140309917457568
	140309917457856 [label=ReluBackward0]
	140309917458288 -> 140309917457856
	140309917458288 [label=AddBackward0]
	140309917457664 -> 140309917458288
	140309917457664 [label=NativeBatchNormBackward0]
	140309917442400 -> 140309917457664
	140309917442400 [label=ConvolutionBackward0]
	140309917443024 -> 140309917442400
	140309917443024 [label=ReluBackward0]
	140309917443456 -> 140309917443024
	140309917443456 [label=NativeBatchNormBackward0]
	140309917444416 -> 140309917443456
	140309917444416 [label=ConvolutionBackward0]
	140309917442208 -> 140309917444416
	140309917442208 [label=ReluBackward0]
	140309917436224 -> 140309917442208
	140309917436224 [label=AddBackward0]
	140310157218528 -> 140309917436224
	140310157218528 [label=NativeBatchNormBackward0]
	140310157249648 -> 140310157218528
	140310157249648 [label=ConvolutionBackward0]
	140310157250176 -> 140310157249648
	140310157250176 [label=ReluBackward0]
	140310157313648 -> 140310157250176
	140310157313648 [label=NativeBatchNormBackward0]
	140310157314224 -> 140310157313648
	140310157314224 [label=ConvolutionBackward0]
	140309917444080 -> 140310157314224
	140309917444080 [label=ReluBackward0]
	140310157315280 -> 140309917444080
	140310157315280 [label=AddBackward0]
	140310157314992 -> 140310157315280
	140310157314992 [label=NativeBatchNormBackward0]
	140310157315376 -> 140310157314992
	140310157315376 [label=ConvolutionBackward0]
	140310157315952 -> 140310157315376
	140310157315952 [label=ReluBackward0]
	140310157336880 -> 140310157315952
	140310157336880 [label=NativeBatchNormBackward0]
	140310157337264 -> 140310157336880
	140310157337264 [label=ConvolutionBackward0]
	140310157315184 -> 140310157337264
	140310157315184 [label=ReluBackward0]
	140310157337552 -> 140310157315184
	140310157337552 [label=AddBackward0]
	140310157337648 -> 140310157337552
	140310157337648 [label=NativeBatchNormBackward0]
	140310157337792 -> 140310157337648
	140310157337792 [label=ConvolutionBackward0]
	140310157337984 -> 140310157337792
	140310157337984 [label=ReluBackward0]
	140310157338128 -> 140310157337984
	140310157338128 [label=NativeBatchNormBackward0]
	140310157338224 -> 140310157338128
	140310157338224 [label=ConvolutionBackward0]
	140310157337600 -> 140310157338224
	140310157337600 [label=ReluBackward0]
	140310157338512 -> 140310157337600
	140310157338512 [label=AddBackward0]
	140310157338608 -> 140310157338512
	140310157338608 [label=AddBackward0]
	140310157338752 -> 140310157338608
	140310157338752 [label=AddBackward0]
	140310157338896 -> 140310157338752
	140310157338896 [label=NativeBatchNormBackward0]
	140310157338992 -> 140310157338896
	140310157338992 [label=ConvolutionBackward0]
	140309917444992 -> 140310157338992
	140310157339184 -> 140310157338992
	140309339798480 [label="stage4.0.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140309339798480 -> 140310157339184
	140310157339184 [label=AccumulateGrad]
	140310157338944 -> 140310157338896
	140309339798560 [label="stage4.0.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140309339798560 -> 140310157338944
	140310157338944 [label=AccumulateGrad]
	140310157338800 -> 140310157338896
	140309339798640 [label="stage4.0.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140309339798640 -> 140310157338800
	140310157338800 [label=AccumulateGrad]
	140309917445712 -> 140310157338752
	140310157338704 -> 140310157338608
	140310157338704 [label=UpsampleNearest2DBackward1]
	140310157339136 -> 140310157338704
	140310157339136 [label=NativeBatchNormBackward0]
	140310157339232 -> 140310157339136
	140310157339232 [label=ConvolutionBackward0]
	140309917435936 -> 140310157339232
	140310157339424 -> 140310157339232
	140309339799040 [label="stage4.0.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140309339799040 -> 140310157339424
	140310157339424 [label=AccumulateGrad]
	140310157339280 -> 140310157339136
	140309339799120 [label="stage4.0.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140309339799120 -> 140310157339280
	140310157339280 [label=AccumulateGrad]
	140310157338848 -> 140310157339136
	140309339799200 [label="stage4.0.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140309339799200 -> 140310157338848
	140310157338848 [label=AccumulateGrad]
	140310157338560 -> 140310157338512
	140310157338560 [label=UpsampleNearest2DBackward1]
	140310157339088 -> 140310157338560
	140310157339088 [label=NativeBatchNormBackward0]
	140310157339520 -> 140310157339088
	140310157339520 [label=ConvolutionBackward0]
	140310157220928 -> 140310157339520
	140310157339616 -> 140310157339520
	140309347319952 [label="stage4.0.fuse_layers.1.3.0.weight
 (36, 144, 1, 1)" fillcolor=lightblue]
	140309347319952 -> 140310157339616
	140310157339616 [label=AccumulateGrad]
	140310157339376 -> 140310157339088
	140309347320032 [label="stage4.0.fuse_layers.1.3.1.weight
 (36)" fillcolor=lightblue]
	140309347320032 -> 140310157339376
	140310157339376 [label=AccumulateGrad]
	140310157338656 -> 140310157339088
	140309347320112 [label="stage4.0.fuse_layers.1.3.1.bias
 (36)" fillcolor=lightblue]
	140309347320112 -> 140310157338656
	140310157338656 [label=AccumulateGrad]
	140310157338416 -> 140310157338224
	140310424062688 [label="stage4.1.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310424062688 -> 140310157338416
	140310157338416 [label=AccumulateGrad]
	140310157338176 -> 140310157338128
	140310424062768 [label="stage4.1.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140310424062768 -> 140310157338176
	140310157338176 [label=AccumulateGrad]
	140310157338032 -> 140310157338128
	140310424062848 [label="stage4.1.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140310424062848 -> 140310157338032
	140310157338032 [label=AccumulateGrad]
	140310157337936 -> 140310157337792
	140310424063248 [label="stage4.1.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310424063248 -> 140310157337936
	140310157337936 [label=AccumulateGrad]
	140310157337744 -> 140310157337648
	140310424063328 [label="stage4.1.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140310424063328 -> 140310157337744
	140310157337744 [label=AccumulateGrad]
	140310157337696 -> 140310157337648
	140310424063408 [label="stage4.1.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140310424063408 -> 140310157337696
	140310157337696 [label=AccumulateGrad]
	140310157337600 -> 140310157337552
	140310157337456 -> 140310157337264
	140310424063808 [label="stage4.1.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310424063808 -> 140310157337456
	140310157337456 [label=AccumulateGrad]
	140310157337312 -> 140310157336880
	140310424063888 [label="stage4.1.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140310424063888 -> 140310157337312
	140310157337312 [label=AccumulateGrad]
	140310157337168 -> 140310157336880
	140310424191040 [label="stage4.1.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140310424191040 -> 140310157337168
	140310157337168 [label=AccumulateGrad]
	140310157336688 -> 140310157315376
	140310424191440 [label="stage4.1.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310424191440 -> 140310157336688
	140310157336688 [label=AccumulateGrad]
	140310157315232 -> 140310157314992
	140310424191520 [label="stage4.1.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140310424191520 -> 140310157315232
	140310157315232 [label=AccumulateGrad]
	140310157315712 -> 140310157314992
	140310424191600 [label="stage4.1.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140310424191600 -> 140310157315712
	140310157315712 [label=AccumulateGrad]
	140310157315184 -> 140310157315280
	140310157314416 -> 140310157314224
	140310424192000 [label="stage4.1.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310424192000 -> 140310157314416
	140310157314416 [label=AccumulateGrad]
	140310157314320 -> 140310157313648
	140310424192080 [label="stage4.1.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140310424192080 -> 140310157314320
	140310157314320 [label=AccumulateGrad]
	140310157312112 -> 140310157313648
	140310424192160 [label="stage4.1.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140310424192160 -> 140310157312112
	140310157312112 [label=AccumulateGrad]
	140310157313888 -> 140310157249648
	140310424192560 [label="stage4.1.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310424192560 -> 140310157313888
	140310157313888 [label=AccumulateGrad]
	140310157246576 -> 140310157218528
	140310424192640 [label="stage4.1.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140310424192640 -> 140310157246576
	140310157246576 [label=AccumulateGrad]
	140310157247296 -> 140310157218528
	140310424192720 [label="stage4.1.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140310424192720 -> 140310157247296
	140310157247296 [label=AccumulateGrad]
	140309917444080 -> 140309917436224
	140309917444704 -> 140309917444416
	140310424193120 [label="stage4.1.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310424193120 -> 140309917444704
	140309917444704 [label=AccumulateGrad]
	140309917443888 -> 140309917443456
	140310424193200 [label="stage4.1.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140310424193200 -> 140309917443888
	140309917443888 [label=AccumulateGrad]
	140309917443840 -> 140309917443456
	140310424193280 [label="stage4.1.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140310424193280 -> 140309917443840
	140309917443840 [label=AccumulateGrad]
	140309917443264 -> 140309917442400
	140310424193680 [label="stage4.1.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310424193680 -> 140309917443264
	140309917443264 [label=AccumulateGrad]
	140309917442592 -> 140309917457664
	140310424193760 [label="stage4.1.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140310424193760 -> 140309917442592
	140309917442592 [label=AccumulateGrad]
	140309917442784 -> 140309917457664
	140310424193840 [label="stage4.1.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140310424193840 -> 140309917442784
	140309917442784 [label=AccumulateGrad]
	140309917442208 -> 140309917458288
	140309917458048 -> 140309917457568
	140309075280096 [label="stage4.1.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140309075280096 -> 140309917458048
	140309917458048 [label=AccumulateGrad]
	140309917457040 -> 140309917456992
	140309075280176 [label="stage4.1.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140309075280176 -> 140309917457040
	140309917457040 [label=AccumulateGrad]
	140309917456608 -> 140309917456992
	140309075280256 [label="stage4.1.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140309075280256 -> 140309917456608
	140309917456608 [label=AccumulateGrad]
	140309917456320 -> 140309917456128
	140309917456320 [label=UpsampleNearest2DBackward1]
	140310157248928 -> 140309917456320
	140310157248928 [label=NativeBatchNormBackward0]
	140309917457472 -> 140310157248928
	140309917457472 [label=ConvolutionBackward0]
	140309917458096 -> 140309917457472
	140309917458096 [label=ReluBackward0]
	140309917444320 -> 140309917458096
	140309917444320 [label=AddBackward0]
	140309917444512 -> 140309917444320
	140309917444512 [label=NativeBatchNormBackward0]
	140310157314032 -> 140309917444512
	140310157314032 [label=ConvolutionBackward0]
	140310157314800 -> 140310157314032
	140310157314800 [label=ReluBackward0]
	140310157337120 -> 140310157314800
	140310157337120 [label=NativeBatchNormBackward0]
	140310157337840 -> 140310157337120
	140310157337840 [label=ConvolutionBackward0]
	140309917445280 -> 140310157337840
	140309917445280 [label=ReluBackward0]
	140310157338080 -> 140309917445280
	140310157338080 [label=AddBackward0]
	140310157338320 -> 140310157338080
	140310157338320 [label=NativeBatchNormBackward0]
	140310157339568 -> 140310157338320
	140310157339568 [label=ConvolutionBackward0]
	140310157339760 -> 140310157339568
	140310157339760 [label=ReluBackward0]
	140310157339904 -> 140310157339760
	140310157339904 [label=NativeBatchNormBackward0]
	140310157340000 -> 140310157339904
	140310157340000 [label=ConvolutionBackward0]
	140310157339040 -> 140310157340000
	140310157339040 [label=ReluBackward0]
	140310157340288 -> 140310157339040
	140310157340288 [label=AddBackward0]
	140310157340384 -> 140310157340288
	140310157340384 [label=NativeBatchNormBackward0]
	140310157340528 -> 140310157340384
	140310157340528 [label=ConvolutionBackward0]
	140310157340624 -> 140310157340528
	140310157340624 [label=ReluBackward0]
	140309654180096 -> 140310157340624
	140309654180096 [label=NativeBatchNormBackward0]
	140309654180192 -> 140309654180096
	140309654180192 [label=ConvolutionBackward0]
	140310157340336 -> 140309654180192
	140310157340336 [label=ReluBackward0]
	140309654180480 -> 140310157340336
	140309654180480 [label=AddBackward0]
	140309654180576 -> 140309654180480
	140309654180576 [label=NativeBatchNormBackward0]
	140309654180720 -> 140309654180576
	140309654180720 [label=ConvolutionBackward0]
	140309654180912 -> 140309654180720
	140309654180912 [label=ReluBackward0]
	140309654181056 -> 140309654180912
	140309654181056 [label=NativeBatchNormBackward0]
	140309654181152 -> 140309654181056
	140309654181152 [label=ConvolutionBackward0]
	140309654180528 -> 140309654181152
	140309654180528 [label=ReluBackward0]
	140309654181440 -> 140309654180528
	140309654181440 [label=AddBackward0]
	140309654181536 -> 140309654181440
	140309654181536 [label=AddBackward0]
	140309654181680 -> 140309654181536
	140309654181680 [label=AddBackward0]
	140309654181776 -> 140309654181680
	140309654181776 [label=NativeBatchNormBackward0]
	140309654181920 -> 140309654181776
	140309654181920 [label=ConvolutionBackward0]
	140309654182112 -> 140309654181920
	140309654182112 [label=ReluBackward0]
	140309654182256 -> 140309654182112
	140309654182256 [label=NativeBatchNormBackward0]
	140309654182352 -> 140309654182256
	140309654182352 [label=ConvolutionBackward0]
	140309917444992 -> 140309654182352
	140309654182544 -> 140309654182352
	140309347320512 [label="stage4.0.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309347320512 -> 140309654182544
	140309654182544 [label=AccumulateGrad]
	140309654182304 -> 140309654182256
	140309347320592 [label="stage4.0.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140309347320592 -> 140309654182304
	140309654182304 [label=AccumulateGrad]
	140309654182160 -> 140309654182256
	140309347320672 [label="stage4.0.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140309347320672 -> 140309654182160
	140309654182160 [label=AccumulateGrad]
	140309654182064 -> 140309654181920
	140309347321072 [label="stage4.0.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140309347321072 -> 140309654182064
	140309654182064 [label=AccumulateGrad]
	140309654181872 -> 140309654181776
	140309347321152 [label="stage4.0.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140309347321152 -> 140309654181872
	140309654181872 [label=AccumulateGrad]
	140309654181824 -> 140309654181776
	140309347321232 [label="stage4.0.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140309347321232 -> 140309654181824
	140309654181824 [label=AccumulateGrad]
	140309654181728 -> 140309654181680
	140309654181728 [label=NativeBatchNormBackward0]
	140309654182496 -> 140309654181728
	140309654182496 [label=ConvolutionBackward0]
	140309917445712 -> 140309654182496
	140309654182592 -> 140309654182496
	140309347321632 [label="stage4.0.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140309347321632 -> 140309654182592
	140309654182592 [label=AccumulateGrad]
	140309654182016 -> 140309654181728
	140309347321712 [label="stage4.0.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140309347321712 -> 140309654182016
	140309654182016 [label=AccumulateGrad]
	140309654181968 -> 140309654181728
	140309347321792 [label="stage4.0.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140309347321792 -> 140309654181968
	140309654181968 [label=AccumulateGrad]
	140309917435936 -> 140309654181536
	140309654181488 -> 140309654181440
	140309654181488 [label=UpsampleNearest2DBackward1]
	140309654182400 -> 140309654181488
	140309654182400 [label=NativeBatchNormBackward0]
	140309654182688 -> 140309654182400
	140309654182688 [label=ConvolutionBackward0]
	140310157220928 -> 140309654182688
	140309654182784 -> 140309654182688
	140309347322192 [label="stage4.0.fuse_layers.2.3.0.weight
 (72, 144, 1, 1)" fillcolor=lightblue]
	140309347322192 -> 140309654182784
	140309654182784 [label=AccumulateGrad]
	140309654182640 -> 140309654182400
	140309347322272 [label="stage4.0.fuse_layers.2.3.1.weight
 (72)" fillcolor=lightblue]
	140309347322272 -> 140309654182640
	140309654182640 [label=AccumulateGrad]
	140309654181632 -> 140309654182400
	140309347322352 [label="stage4.0.fuse_layers.2.3.1.bias
 (72)" fillcolor=lightblue]
	140309347322352 -> 140309654181632
	140309654181632 [label=AccumulateGrad]
	140309654181344 -> 140309654181152
	140310424194240 [label="stage4.1.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140310424194240 -> 140309654181344
	140309654181344 [label=AccumulateGrad]
	140309654181104 -> 140309654181056
	140310424194320 [label="stage4.1.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140310424194320 -> 140309654181104
	140309654181104 [label=AccumulateGrad]
	140309654180960 -> 140309654181056
	140310424194400 [label="stage4.1.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140310424194400 -> 140309654180960
	140309654180960 [label=AccumulateGrad]
	140309654180864 -> 140309654180720
	140310424194800 [label="stage4.1.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140310424194800 -> 140309654180864
	140309654180864 [label=AccumulateGrad]
	140309654180672 -> 140309654180576
	140310424194880 [label="stage4.1.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140310424194880 -> 140309654180672
	140309654180672 [label=AccumulateGrad]
	140309654180624 -> 140309654180576
	140310424194960 [label="stage4.1.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140310424194960 -> 140309654180624
	140309654180624 [label=AccumulateGrad]
	140309654180528 -> 140309654180480
	140309654180384 -> 140309654180192
	140310424772992 [label="stage4.1.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140310424772992 -> 140309654180384
	140309654180384 [label=AccumulateGrad]
	140309654180144 -> 140309654180096
	140310424773072 [label="stage4.1.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140310424773072 -> 140309654180144
	140309654180144 [label=AccumulateGrad]
	140309654180000 -> 140309654180096
	140310424773152 [label="stage4.1.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140310424773152 -> 140309654180000
	140309654180000 [label=AccumulateGrad]
	140309654179952 -> 140310157340528
	140310424773552 [label="stage4.1.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140310424773552 -> 140309654179952
	140309654179952 [label=AccumulateGrad]
	140310157340480 -> 140310157340384
	140310424773632 [label="stage4.1.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140310424773632 -> 140310157340480
	140310157340480 [label=AccumulateGrad]
	140310157340432 -> 140310157340384
	140310424773712 [label="stage4.1.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140310424773712 -> 140310157340432
	140310157340432 [label=AccumulateGrad]
	140310157340336 -> 140310157340288
	140310157340192 -> 140310157340000
	140310424774112 [label="stage4.1.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140310424774112 -> 140310157340192
	140310157340192 [label=AccumulateGrad]
	140310157339952 -> 140310157339904
	140310424774192 [label="stage4.1.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140310424774192 -> 140310157339952
	140310157339952 [label=AccumulateGrad]
	140310157339808 -> 140310157339904
	140310424774272 [label="stage4.1.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140310424774272 -> 140310157339808
	140310157339808 [label=AccumulateGrad]
	140310157339328 -> 140310157339568
	140310424774672 [label="stage4.1.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140310424774672 -> 140310157339328
	140310157339328 [label=AccumulateGrad]
	140310157339472 -> 140310157338320
	140310424774752 [label="stage4.1.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140310424774752 -> 140310157339472
	140310157339472 [label=AccumulateGrad]
	140310157338464 -> 140310157338320
	140310424774832 [label="stage4.1.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140310424774832 -> 140310157338464
	140310157338464 [label=AccumulateGrad]
	140310157339040 -> 140310157338080
	140310157338368 -> 140310157337840
	140310424775232 [label="stage4.1.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140310424775232 -> 140310157338368
	140310157338368 [label=AccumulateGrad]
	140310157337072 -> 140310157337120
	140310424775312 [label="stage4.1.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140310424775312 -> 140310157337072
	140310157337072 [label=AccumulateGrad]
	140310157336784 -> 140310157337120
	140310424775392 [label="stage4.1.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140310424775392 -> 140310157336784
	140310157336784 [label=AccumulateGrad]
	140310157314752 -> 140310157314032
	140310424775792 [label="stage4.1.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140310424775792 -> 140310157314752
	140310157314752 [label=AccumulateGrad]
	140310157314272 -> 140309917444512
	140310424775872 [label="stage4.1.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140310424775872 -> 140310157314272
	140310157314272 [label=AccumulateGrad]
	140310157312160 -> 140309917444512
	140310424775952 [label="stage4.1.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140310424775952 -> 140310157312160
	140310157312160 [label=AccumulateGrad]
	140309917445280 -> 140309917444320
	140309917442832 -> 140309917457472
	140309075280656 [label="stage4.1.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140309075280656 -> 140309917442832
	140309917442832 [label=AccumulateGrad]
	140309917456800 -> 140310157248928
	140309075280736 [label="stage4.1.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140309075280736 -> 140309917456800
	140309917456800 [label=AccumulateGrad]
	140309917456416 -> 140310157248928
	140309075280816 [label="stage4.1.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140309075280816 -> 140309917456416
	140309917456416 [label=AccumulateGrad]
	140309917455888 -> 140309917456080
	140309917455888 [label=UpsampleNearest2DBackward1]
	140309917457232 -> 140309917455888
	140309917457232 [label=NativeBatchNormBackward0]
	140310157250272 -> 140309917457232
	140310157250272 [label=ConvolutionBackward0]
	140310157315760 -> 140310157250272
	140310157315760 [label=ReluBackward0]
	140310157339712 -> 140310157315760
	140310157339712 [label=AddBackward0]
	140310157338272 -> 140310157339712
	140310157338272 [label=NativeBatchNormBackward0]
	140310157340048 -> 140310157338272
	140310157340048 [label=ConvolutionBackward0]
	140310157340240 -> 140310157340048
	140310157340240 [label=ReluBackward0]
	140309654180240 -> 140310157340240
	140309654180240 [label=NativeBatchNormBackward0]
	140309654180768 -> 140309654180240
	140309654180768 [label=ConvolutionBackward0]
	140310157337504 -> 140309654180768
	140310157337504 [label=ReluBackward0]
	140309654181008 -> 140310157337504
	140309654181008 [label=AddBackward0]
	140309654181248 -> 140309654181008
	140309654181248 [label=NativeBatchNormBackward0]
	140309654182736 -> 140309654181248
	140309654182736 [label=ConvolutionBackward0]
	140309654182928 -> 140309654182736
	140309654182928 [label=ReluBackward0]
	140309654183072 -> 140309654182928
	140309654183072 [label=NativeBatchNormBackward0]
	140309654183168 -> 140309654183072
	140309654183168 [label=ConvolutionBackward0]
	140309654181584 -> 140309654183168
	140309654181584 [label=ReluBackward0]
	140309654183456 -> 140309654181584
	140309654183456 [label=AddBackward0]
	140309654183552 -> 140309654183456
	140309654183552 [label=NativeBatchNormBackward0]
	140309654183696 -> 140309654183552
	140309654183696 [label=ConvolutionBackward0]
	140309654183888 -> 140309654183696
	140309654183888 [label=ReluBackward0]
	140309654212768 -> 140309654183888
	140309654212768 [label=NativeBatchNormBackward0]
	140309654212864 -> 140309654212768
	140309654212864 [label=ConvolutionBackward0]
	140309654183504 -> 140309654212864
	140309654183504 [label=ReluBackward0]
	140309654213152 -> 140309654183504
	140309654213152 [label=AddBackward0]
	140309654213248 -> 140309654213152
	140309654213248 [label=NativeBatchNormBackward0]
	140309654213392 -> 140309654213248
	140309654213392 [label=ConvolutionBackward0]
	140309654213584 -> 140309654213392
	140309654213584 [label=ReluBackward0]
	140309654213728 -> 140309654213584
	140309654213728 [label=NativeBatchNormBackward0]
	140309654213824 -> 140309654213728
	140309654213824 [label=ConvolutionBackward0]
	140309654213200 -> 140309654213824
	140309654213200 [label=ReluBackward0]
	140309654214112 -> 140309654213200
	140309654214112 [label=AddBackward0]
	140309654214208 -> 140309654214112
	140309654214208 [label=AddBackward0]
	140309654214304 -> 140309654214208
	140309654214304 [label=AddBackward0]
	140309654214448 -> 140309654214304
	140309654214448 [label=NativeBatchNormBackward0]
	140309654214592 -> 140309654214448
	140309654214592 [label=ConvolutionBackward0]
	140309654214784 -> 140309654214592
	140309654214784 [label=ReluBackward0]
	140309654214928 -> 140309654214784
	140309654214928 [label=NativeBatchNormBackward0]
	140309654215024 -> 140309654214928
	140309654215024 [label=ConvolutionBackward0]
	140309654215216 -> 140309654215024
	140309654215216 [label=ReluBackward0]
	140309654215360 -> 140309654215216
	140309654215360 [label=NativeBatchNormBackward0]
	140309654215456 -> 140309654215360
	140309654215456 [label=ConvolutionBackward0]
	140309917444992 -> 140309654215456
	140309654215648 -> 140309654215456
	140309347322752 [label="stage4.0.fuse_layers.3.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309347322752 -> 140309654215648
	140309654215648 [label=AccumulateGrad]
	140309654215408 -> 140309654215360
	140309347322832 [label="stage4.0.fuse_layers.3.0.0.1.weight
 (18)" fillcolor=lightblue]
	140309347322832 -> 140309654215408
	140309654215408 [label=AccumulateGrad]
	140309654215264 -> 140309654215360
	140309347322912 [label="stage4.0.fuse_layers.3.0.0.1.bias
 (18)" fillcolor=lightblue]
	140309347322912 -> 140309654215264
	140309654215264 [label=AccumulateGrad]
	140309654215168 -> 140309654215024
	140309347323312 [label="stage4.0.fuse_layers.3.0.1.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309347323312 -> 140309654215168
	140309654215168 [label=AccumulateGrad]
	140309654214976 -> 140309654214928
	140309347323392 [label="stage4.0.fuse_layers.3.0.1.1.weight
 (18)" fillcolor=lightblue]
	140309347323392 -> 140309654214976
	140309654214976 [label=AccumulateGrad]
	140309654214832 -> 140309654214928
	140309347323472 [label="stage4.0.fuse_layers.3.0.1.1.bias
 (18)" fillcolor=lightblue]
	140309347323472 -> 140309654214832
	140309654214832 [label=AccumulateGrad]
	140309654214736 -> 140309654214592
	140309347438656 [label="stage4.0.fuse_layers.3.0.2.0.weight
 (144, 18, 3, 3)" fillcolor=lightblue]
	140309347438656 -> 140309654214736
	140309654214736 [label=AccumulateGrad]
	140309654214544 -> 140309654214448
	140309347438736 [label="stage4.0.fuse_layers.3.0.2.1.weight
 (144)" fillcolor=lightblue]
	140309347438736 -> 140309654214544
	140309654214544 [label=AccumulateGrad]
	140309654214496 -> 140309654214448
	140309347438816 [label="stage4.0.fuse_layers.3.0.2.1.bias
 (144)" fillcolor=lightblue]
	140309347438816 -> 140309654214496
	140309654214496 [label=AccumulateGrad]
	140309654214400 -> 140309654214304
	140309654214400 [label=NativeBatchNormBackward0]
	140309654215120 -> 140309654214400
	140309654215120 [label=ConvolutionBackward0]
	140309654215504 -> 140309654215120
	140309654215504 [label=ReluBackward0]
	140309654215696 -> 140309654215504
	140309654215696 [label=NativeBatchNormBackward0]
	140309654215792 -> 140309654215696
	140309654215792 [label=ConvolutionBackward0]
	140309917445712 -> 140309654215792
	140309654215984 -> 140309654215792
	140309347439216 [label="stage4.0.fuse_layers.3.1.0.0.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309347439216 -> 140309654215984
	140309654215984 [label=AccumulateGrad]
	140309654215552 -> 140309654215696
	140309347439296 [label="stage4.0.fuse_layers.3.1.0.1.weight
 (36)" fillcolor=lightblue]
	140309347439296 -> 140309654215552
	140309654215552 [label=AccumulateGrad]
	140309654215312 -> 140309654215696
	140309347439376 [label="stage4.0.fuse_layers.3.1.0.1.bias
 (36)" fillcolor=lightblue]
	140309347439376 -> 140309654215312
	140309654215312 [label=AccumulateGrad]
	140309654215600 -> 140309654215120
	140309347439776 [label="stage4.0.fuse_layers.3.1.1.0.weight
 (144, 36, 3, 3)" fillcolor=lightblue]
	140309347439776 -> 140309654215600
	140309654215600 [label=AccumulateGrad]
	140309654214688 -> 140309654214400
	140309347439856 [label="stage4.0.fuse_layers.3.1.1.1.weight
 (144)" fillcolor=lightblue]
	140309347439856 -> 140309654214688
	140309654214688 [label=AccumulateGrad]
	140309654214640 -> 140309654214400
	140309347439936 [label="stage4.0.fuse_layers.3.1.1.1.bias
 (144)" fillcolor=lightblue]
	140309347439936 -> 140309654214640
	140309654214640 [label=AccumulateGrad]
	140309654214256 -> 140309654214208
	140309654214256 [label=NativeBatchNormBackward0]
	140309654214880 -> 140309654214256
	140309654214880 [label=ConvolutionBackward0]
	140309917435936 -> 140309654214880
	140309654216080 -> 140309654214880
	140309347440336 [label="stage4.0.fuse_layers.3.2.0.0.weight
 (144, 72, 3, 3)" fillcolor=lightblue]
	140309347440336 -> 140309654216080
	140309654216080 [label=AccumulateGrad]
	140309654215072 -> 140309654214256
	140309347440416 [label="stage4.0.fuse_layers.3.2.0.1.weight
 (144)" fillcolor=lightblue]
	140309347440416 -> 140309654215072
	140309654215072 [label=AccumulateGrad]
	140309654214352 -> 140309654214256
	140309347440496 [label="stage4.0.fuse_layers.3.2.0.1.bias
 (144)" fillcolor=lightblue]
	140309347440496 -> 140309654214352
	140309654214352 [label=AccumulateGrad]
	140310157220928 -> 140309654214112
	140309654214016 -> 140309654213824
	140310424776352 [label="stage4.1.branches.3.0.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140310424776352 -> 140309654214016
	140309654214016 [label=AccumulateGrad]
	140309654213776 -> 140309654213728
	140310424776432 [label="stage4.1.branches.3.0.bn1.weight
 (144)" fillcolor=lightblue]
	140310424776432 -> 140309654213776
	140309654213776 [label=AccumulateGrad]
	140309654213632 -> 140309654213728
	140310424776512 [label="stage4.1.branches.3.0.bn1.bias
 (144)" fillcolor=lightblue]
	140310424776512 -> 140309654213632
	140309654213632 [label=AccumulateGrad]
	140309654213536 -> 140309654213392
	140310424883504 [label="stage4.1.branches.3.0.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140310424883504 -> 140309654213536
	140309654213536 [label=AccumulateGrad]
	140309654213344 -> 140309654213248
	140310424883584 [label="stage4.1.branches.3.0.bn2.weight
 (144)" fillcolor=lightblue]
	140310424883584 -> 140309654213344
	140309654213344 [label=AccumulateGrad]
	140309654213296 -> 140309654213248
	140310424883664 [label="stage4.1.branches.3.0.bn2.bias
 (144)" fillcolor=lightblue]
	140310424883664 -> 140309654213296
	140309654213296 [label=AccumulateGrad]
	140309654213200 -> 140309654213152
	140309654213056 -> 140309654212864
	140310424884064 [label="stage4.1.branches.3.1.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140310424884064 -> 140309654213056
	140309654213056 [label=AccumulateGrad]
	140309654212816 -> 140309654212768
	140310424884144 [label="stage4.1.branches.3.1.bn1.weight
 (144)" fillcolor=lightblue]
	140310424884144 -> 140309654212816
	140309654212816 [label=AccumulateGrad]
	140309654212672 -> 140309654212768
	140310424884224 [label="stage4.1.branches.3.1.bn1.bias
 (144)" fillcolor=lightblue]
	140310424884224 -> 140309654212672
	140309654212672 [label=AccumulateGrad]
	140309654183840 -> 140309654183696
	140310424884624 [label="stage4.1.branches.3.1.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140310424884624 -> 140309654183840
	140309654183840 [label=AccumulateGrad]
	140309654183648 -> 140309654183552
	140310424884704 [label="stage4.1.branches.3.1.bn2.weight
 (144)" fillcolor=lightblue]
	140310424884704 -> 140309654183648
	140309654183648 [label=AccumulateGrad]
	140309654183600 -> 140309654183552
	140310424884784 [label="stage4.1.branches.3.1.bn2.bias
 (144)" fillcolor=lightblue]
	140310424884784 -> 140309654183600
	140309654183600 [label=AccumulateGrad]
	140309654183504 -> 140309654183456
	140309654183360 -> 140309654183168
	140310424885184 [label="stage4.1.branches.3.2.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140310424885184 -> 140309654183360
	140309654183360 [label=AccumulateGrad]
	140309654183120 -> 140309654183072
	140310424885264 [label="stage4.1.branches.3.2.bn1.weight
 (144)" fillcolor=lightblue]
	140310424885264 -> 140309654183120
	140309654183120 [label=AccumulateGrad]
	140309654182976 -> 140309654183072
	140310424885344 [label="stage4.1.branches.3.2.bn1.bias
 (144)" fillcolor=lightblue]
	140310424885344 -> 140309654182976
	140309654182976 [label=AccumulateGrad]
	140309654182208 -> 140309654182736
	140310424885744 [label="stage4.1.branches.3.2.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140310424885744 -> 140309654182208
	140309654182208 [label=AccumulateGrad]
	140309654182448 -> 140309654181248
	140310424885824 [label="stage4.1.branches.3.2.bn2.weight
 (144)" fillcolor=lightblue]
	140310424885824 -> 140309654182448
	140309654182448 [label=AccumulateGrad]
	140309654181392 -> 140309654181248
	140310424885904 [label="stage4.1.branches.3.2.bn2.bias
 (144)" fillcolor=lightblue]
	140310424885904 -> 140309654181392
	140309654181392 [label=AccumulateGrad]
	140309654181584 -> 140309654181008
	140309654181296 -> 140309654180768
	140310424886304 [label="stage4.1.branches.3.3.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140310424886304 -> 140309654181296
	140309654181296 [label=AccumulateGrad]
	140309654180048 -> 140309654180240
	140310424886384 [label="stage4.1.branches.3.3.bn1.weight
 (144)" fillcolor=lightblue]
	140310424886384 -> 140309654180048
	140309654180048 [label=AccumulateGrad]
	140309654179904 -> 140309654180240
	140310424886464 [label="stage4.1.branches.3.3.bn1.bias
 (144)" fillcolor=lightblue]
	140310424886464 -> 140309654179904
	140309654179904 [label=AccumulateGrad]
	140310157340096 -> 140310157340048
	140310424886864 [label="stage4.1.branches.3.3.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140310424886864 -> 140310157340096
	140310157340096 [label=AccumulateGrad]
	140310157340144 -> 140310157338272
	140310424886944 [label="stage4.1.branches.3.3.bn2.weight
 (144)" fillcolor=lightblue]
	140310424886944 -> 140310157340144
	140310157340144 [label=AccumulateGrad]
	140310157339664 -> 140310157338272
	140310424887024 [label="stage4.1.branches.3.3.bn2.bias
 (144)" fillcolor=lightblue]
	140310424887024 -> 140310157339664
	140310157339664 [label=AccumulateGrad]
	140310157337504 -> 140310157339712
	140310157312544 -> 140310157250272
	140309075281216 [label="stage4.1.fuse_layers.0.3.0.weight
 (18, 144, 1, 1)" fillcolor=lightblue]
	140309075281216 -> 140310157312544
	140310157312544 [label=AccumulateGrad]
	140309917443360 -> 140309917457232
	140309075281296 [label="stage4.1.fuse_layers.0.3.1.weight
 (18)" fillcolor=lightblue]
	140309075281296 -> 140309917443360
	140309917443360 [label=AccumulateGrad]
	140309917442304 -> 140309917457232
	140309075281376 [label="stage4.1.fuse_layers.0.3.1.bias
 (18)" fillcolor=lightblue]
	140309075281376 -> 140309917442304
	140309917442304 [label=AccumulateGrad]
	140309917455984 -> 140309917455696
	140309348140192 [label="stage4.2.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309348140192 -> 140309917455984
	140309917455984 [label=AccumulateGrad]
	140309917455552 -> 140309917455648
	140309348140272 [label="stage4.2.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140309348140272 -> 140309917455552
	140309917455552 [label=AccumulateGrad]
	140309917455792 -> 140309917455648
	140309348140352 [label="stage4.2.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140309348140352 -> 140309917455792
	140309917455792 [label=AccumulateGrad]
	140309917455456 -> 140309917455312
	140309348140752 [label="stage4.2.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309348140752 -> 140309917455456
	140309917455456 [label=AccumulateGrad]
	140309917455264 -> 140309917455072
	140309348140832 [label="stage4.2.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140309348140832 -> 140309917455264
	140309917455264 [label=AccumulateGrad]
	140309917455216 -> 140309917455072
	140309348140912 [label="stage4.2.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140309348140912 -> 140309917455216
	140309917455216 [label=AccumulateGrad]
	140309917454832 -> 140309917455024
	140309917454928 -> 140309917454640
	140309348141312 [label="stage4.2.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309348141312 -> 140309917454928
	140309917454928 [label=AccumulateGrad]
	140309917454496 -> 140309917454592
	140309348141392 [label="stage4.2.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140309348141392 -> 140309917454496
	140309917454496 [label=AccumulateGrad]
	140309917454736 -> 140309917454592
	140309348141472 [label="stage4.2.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140309348141472 -> 140309917454736
	140309917454736 [label=AccumulateGrad]
	140309917454400 -> 140309917482864
	140309348141872 [label="stage4.2.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309348141872 -> 140309917454400
	140309917454400 [label=AccumulateGrad]
	140309917482816 -> 140309917482624
	140309348141952 [label="stage4.2.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140309348141952 -> 140309917482816
	140309917482816 [label=AccumulateGrad]
	140309917482768 -> 140309917482624
	140309348142032 [label="stage4.2.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140309348142032 -> 140309917482768
	140309917482768 [label=AccumulateGrad]
	140309917482384 -> 140309917482576
	140309917482480 -> 140309917482192
	140309348142432 [label="stage4.2.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309348142432 -> 140309917482480
	140309917482480 [label=AccumulateGrad]
	140309917482048 -> 140309917482144
	140309348142512 [label="stage4.2.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140309348142512 -> 140309917482048
	140309917482048 [label=AccumulateGrad]
	140309917482288 -> 140309917482144
	140309348142592 [label="stage4.2.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140309348142592 -> 140309917482288
	140309917482288 [label=AccumulateGrad]
	140309917481952 -> 140309917481808
	140309348142992 [label="stage4.2.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309348142992 -> 140309917481952
	140309917481952 [label=AccumulateGrad]
	140309917481760 -> 140309917481568
	140309348278336 [label="stage4.2.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140309348278336 -> 140309917481760
	140309917481760 [label=AccumulateGrad]
	140309917481712 -> 140309917481568
	140309348278416 [label="stage4.2.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140309348278416 -> 140309917481712
	140309917481712 [label=AccumulateGrad]
	140309917481328 -> 140309917481520
	140309917481424 -> 140309917481136
	140309348278816 [label="stage4.2.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309348278816 -> 140309917481424
	140309917481424 [label=AccumulateGrad]
	140309917480992 -> 140309917481088
	140309348278896 [label="stage4.2.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140309348278896 -> 140309917480992
	140309917480992 [label=AccumulateGrad]
	140309917481232 -> 140309917481088
	140309348278976 [label="stage4.2.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140309348278976 -> 140309917481232
	140309917481232 [label=AccumulateGrad]
	140309917480896 -> 140309917480752
	140309348279376 [label="stage4.2.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309348279376 -> 140309917480896
	140309917480896 [label=AccumulateGrad]
	140309917480704 -> 140309917480512
	140309348279456 [label="stage4.2.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140309348279456 -> 140309917480704
	140309917480704 [label=AccumulateGrad]
	140309917480656 -> 140309917480512
	140309348279536 [label="stage4.2.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140309348279536 -> 140309917480656
	140309917480656 [label=AccumulateGrad]
	140309917480368 -> 140309917480464
	140309917480272 -> 140309917480128
	140309077242560 [label="stage4.2.fuse_layers.3.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309077242560 -> 140309917480272
	140309917480272 [label=AccumulateGrad]
	140309917480080 -> 140309917480032
	140309077242640 [label="stage4.2.fuse_layers.3.0.0.1.weight
 (18)" fillcolor=lightblue]
	140309077242640 -> 140309917480080
	140309917480080 [label=AccumulateGrad]
	140309917479936 -> 140309917480032
	140309077242720 [label="stage4.2.fuse_layers.3.0.0.1.bias
 (18)" fillcolor=lightblue]
	140309077242720 -> 140309917479936
	140309917479936 [label=AccumulateGrad]
	140309917479840 -> 140309917479696
	140309077243120 [label="stage4.2.fuse_layers.3.0.1.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309077243120 -> 140309917479840
	140309917479840 [label=AccumulateGrad]
	140309917479648 -> 140309917479600
	140309077243200 [label="stage4.2.fuse_layers.3.0.1.1.weight
 (18)" fillcolor=lightblue]
	140309077243200 -> 140309917479648
	140309917479648 [label=AccumulateGrad]
	140309917479504 -> 140309917479600
	140309077243280 [label="stage4.2.fuse_layers.3.0.1.1.bias
 (18)" fillcolor=lightblue]
	140309077243280 -> 140309917479504
	140309917479504 [label=AccumulateGrad]
	140309917479408 -> 140309917479264
	140309077243680 [label="stage4.2.fuse_layers.3.0.2.0.weight
 (144, 18, 3, 3)" fillcolor=lightblue]
	140309077243680 -> 140309917479408
	140309917479408 [label=AccumulateGrad]
	140309917479216 -> 140309917479120
	140309077243760 [label="stage4.2.fuse_layers.3.0.2.1.weight
 (144)" fillcolor=lightblue]
	140309077243760 -> 140309917479216
	140309917479216 [label=AccumulateGrad]
	140309917479168 -> 140309917479120
	140309077243840 [label="stage4.2.fuse_layers.3.0.2.1.bias
 (144)" fillcolor=lightblue]
	140309077243840 -> 140309917479168
	140309917479168 [label=AccumulateGrad]
	140309917479072 -> 140310156636112
	140309917479072 [label=NativeBatchNormBackward0]
	140309917479792 -> 140309917479072
	140309917479792 [label=ConvolutionBackward0]
	140309917480176 -> 140309917479792
	140309917480176 [label=ReluBackward0]
	140309917480608 -> 140309917480176
	140309917480608 [label=NativeBatchNormBackward0]
	140309917480848 -> 140309917480608
	140309917480848 [label=ConvolutionBackward0]
	140309917481856 -> 140309917480848
	140309917481856 [label=ReluBackward0]
	140309917481904 -> 140309917481856
	140309917481904 [label=AddBackward0]
	140309917482336 -> 140309917481904
	140309917482336 [label=NativeBatchNormBackward0]
	140309917482720 -> 140309917482336
	140309917482720 [label=ConvolutionBackward0]
	140309917454784 -> 140309917482720
	140309917454784 [label=ReluBackward0]
	140309917455168 -> 140309917454784
	140309917455168 [label=NativeBatchNormBackward0]
	140309917455408 -> 140309917455168
	140309917455408 [label=ConvolutionBackward0]
	140309917482432 -> 140309917455408
	140309917482432 [label=ReluBackward0]
	140309917456032 -> 140309917482432
	140309917456032 [label=AddBackward0]
	140309917443648 -> 140309917456032
	140309917443648 [label=NativeBatchNormBackward0]
	140310157337408 -> 140309917443648
	140310157337408 [label=ConvolutionBackward0]
	140309654180336 -> 140310157337408
	140309654180336 [label=ReluBackward0]
	140309654181200 -> 140309654180336
	140309654181200 [label=NativeBatchNormBackward0]
	140309654183312 -> 140309654181200
	140309654183312 [label=ConvolutionBackward0]
	140309917455840 -> 140309654183312
	140309917455840 [label=ReluBackward0]
	140309654183792 -> 140309917455840
	140309654183792 [label=AddBackward0]
	140309654183024 -> 140309654183792
	140309654183024 [label=NativeBatchNormBackward0]
	140309654212960 -> 140309654183024
	140309654212960 [label=ConvolutionBackward0]
	140309654213872 -> 140309654212960
	140309654213872 [label=ReluBackward0]
	140309654214160 -> 140309654213872
	140309654214160 [label=NativeBatchNormBackward0]
	140309654215936 -> 140309654214160
	140309654215936 [label=ConvolutionBackward0]
	140309654212912 -> 140309654215936
	140309654212912 [label=ReluBackward0]
	140309654216176 -> 140309654212912
	140309654216176 [label=AddBackward0]
	140309654216272 -> 140309654216176
	140309654216272 [label=NativeBatchNormBackward0]
	140309654216416 -> 140309654216272
	140309654216416 [label=ConvolutionBackward0]
	140309654216608 -> 140309654216416
	140309654216608 [label=ReluBackward0]
	140309654216656 -> 140309654216608
	140309654216656 [label=NativeBatchNormBackward0]
	140309654261968 -> 140309654216656
	140309654261968 [label=ConvolutionBackward0]
	140309654216224 -> 140309654261968
	140309654216224 [label=ReluBackward0]
	140309654262256 -> 140309654216224
	140309654262256 [label=AddBackward0]
	140309654262352 -> 140309654262256
	140309654262352 [label=AddBackward0]
	140309654262496 -> 140309654262352
	140309654262496 [label=AddBackward0]
	140309654262640 -> 140309654262496
	140309654262640 [label=NativeBatchNormBackward0]
	140309654262736 -> 140309654262640
	140309654262736 [label=ConvolutionBackward0]
	140309917456512 -> 140309654262736
	140309654262928 -> 140309654262736
	140309075281776 [label="stage4.1.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140309075281776 -> 140309654262928
	140309654262928 [label=AccumulateGrad]
	140309654262688 -> 140309654262640
	140309075281856 [label="stage4.1.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140309075281856 -> 140309654262688
	140309654262688 [label=AccumulateGrad]
	140309654262544 -> 140309654262640
	140309075281936 [label="stage4.1.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140309075281936 -> 140309654262544
	140309654262544 [label=AccumulateGrad]
	140309917457856 -> 140309654262496
	140309654262448 -> 140309654262352
	140309654262448 [label=UpsampleNearest2DBackward1]
	140309654262880 -> 140309654262448
	140309654262880 [label=NativeBatchNormBackward0]
	140309654262976 -> 140309654262880
	140309654262976 [label=ConvolutionBackward0]
	140309917458096 -> 140309654262976
	140309654263168 -> 140309654262976
	140309075282336 [label="stage4.1.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140309075282336 -> 140309654263168
	140309654263168 [label=AccumulateGrad]
	140309654263024 -> 140309654262880
	140309075282416 [label="stage4.1.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140309075282416 -> 140309654263024
	140309654263024 [label=AccumulateGrad]
	140309654262592 -> 140309654262880
	140309075282496 [label="stage4.1.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140309075282496 -> 140309654262592
	140309654262592 [label=AccumulateGrad]
	140309654262304 -> 140309654262256
	140309654262304 [label=UpsampleNearest2DBackward1]
	140309654262832 -> 140309654262304
	140309654262832 [label=NativeBatchNormBackward0]
	140309654263264 -> 140309654262832
	140309654263264 [label=ConvolutionBackward0]
	140310157315760 -> 140309654263264
	140309654263360 -> 140309654263264
	140309075282896 [label="stage4.1.fuse_layers.1.3.0.weight
 (36, 144, 1, 1)" fillcolor=lightblue]
	140309075282896 -> 140309654263360
	140309654263360 [label=AccumulateGrad]
	140309654263120 -> 140309654262832
	140309075282976 [label="stage4.1.fuse_layers.1.3.1.weight
 (36)" fillcolor=lightblue]
	140309075282976 -> 140309654263120
	140309654263120 [label=AccumulateGrad]
	140309654262400 -> 140309654262832
	140309075283056 [label="stage4.1.fuse_layers.1.3.1.bias
 (36)" fillcolor=lightblue]
	140309075283056 -> 140309654262400
	140309654262400 [label=AccumulateGrad]
	140309654262160 -> 140309654261968
	140309348279936 [label="stage4.2.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309348279936 -> 140309654262160
	140309654262160 [label=AccumulateGrad]
	140309654261920 -> 140309654216656
	140309348280016 [label="stage4.2.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140309348280016 -> 140309654261920
	140309654261920 [label=AccumulateGrad]
	140309654261824 -> 140309654216656
	140309348280096 [label="stage4.2.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140309348280096 -> 140309654261824
	140309654261824 [label=AccumulateGrad]
	140309654216560 -> 140309654216416
	140309348280496 [label="stage4.2.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309348280496 -> 140309654216560
	140309654216560 [label=AccumulateGrad]
	140309654216368 -> 140309654216272
	140309348280576 [label="stage4.2.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140309348280576 -> 140309654216368
	140309654216368 [label=AccumulateGrad]
	140309654216320 -> 140309654216272
	140309348280656 [label="stage4.2.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140309348280656 -> 140309654216320
	140309654216320 [label=AccumulateGrad]
	140309654216224 -> 140309654216176
	140309654215840 -> 140309654215936
	140309348281056 [label="stage4.2.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309348281056 -> 140309654215840
	140309654215840 [label=AccumulateGrad]
	140309654214064 -> 140309654214160
	140309348281136 [label="stage4.2.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140309348281136 -> 140309654214064
	140309654214064 [label=AccumulateGrad]
	140309654213680 -> 140309654214160
	140309348281216 [label="stage4.2.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140309348281216 -> 140309654213680
	140309654213680 [label=AccumulateGrad]
	140309654213968 -> 140309654212960
	140309348281616 [label="stage4.2.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309348281616 -> 140309654213968
	140309654213968 [label=AccumulateGrad]
	140309654213440 -> 140309654183024
	140309348281696 [label="stage4.2.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140309348281696 -> 140309654213440
	140309654213440 [label=AccumulateGrad]
	140309654212720 -> 140309654183024
	140309348281776 [label="stage4.2.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140309348281776 -> 140309654212720
	140309654212720 [label=AccumulateGrad]
	140309654212912 -> 140309654183792
	140309654183264 -> 140309654183312
	140309348282176 [label="stage4.2.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309348282176 -> 140309654183264
	140309654183264 [label=AccumulateGrad]
	140309654182832 -> 140309654181200
	140309348282256 [label="stage4.2.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140309348282256 -> 140309654182832
	140309654182832 [label=AccumulateGrad]
	140309654182880 -> 140309654181200
	140310427639872 [label="stage4.2.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140310427639872 -> 140309654182880
	140309654182880 [label=AccumulateGrad]
	140309654180288 -> 140310157337408
	140310427640272 [label="stage4.2.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310427640272 -> 140309654180288
	140309654180288 [label=AccumulateGrad]
	140310157337360 -> 140309917443648
	140310427640352 [label="stage4.2.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140310427640352 -> 140310157337360
	140310157337360 [label=AccumulateGrad]
	140310157339856 -> 140309917443648
	140310427640432 [label="stage4.2.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140310427640432 -> 140310157339856
	140310157339856 [label=AccumulateGrad]
	140309917455840 -> 140309917456032
	140309917456272 -> 140309917455408
	140310427640832 [label="stage4.2.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310427640832 -> 140309917456272
	140309917456272 [label=AccumulateGrad]
	140309917454976 -> 140309917455168
	140310427640912 [label="stage4.2.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140310427640912 -> 140309917454976
	140309917454976 [label=AccumulateGrad]
	140309917454544 -> 140309917455168
	140310427640992 [label="stage4.2.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140310427640992 -> 140309917454544
	140309917454544 [label=AccumulateGrad]
	140309917454880 -> 140309917482720
	140310427641392 [label="stage4.2.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140310427641392 -> 140309917454880
	140309917454880 [label=AccumulateGrad]
	140309917482912 -> 140309917482336
	140310427641472 [label="stage4.2.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140310427641472 -> 140309917482912
	140309917482912 [label=AccumulateGrad]
	140309917482096 -> 140309917482336
	140310427641552 [label="stage4.2.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140310427641552 -> 140309917482096
	140309917482096 [label=AccumulateGrad]
	140309917482432 -> 140309917481904
	140309917481040 -> 140309917480848
	140309077244240 [label="stage4.2.fuse_layers.3.1.0.0.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309077244240 -> 140309917481040
	140309917481040 [label=AccumulateGrad]
	140309917480416 -> 140309917480608
	140309077244320 [label="stage4.2.fuse_layers.3.1.0.1.weight
 (36)" fillcolor=lightblue]
	140309077244320 -> 140309917480416
	140309917480416 [label=AccumulateGrad]
	140309917479984 -> 140309917480608
	140309077244400 [label="stage4.2.fuse_layers.3.1.0.1.bias
 (36)" fillcolor=lightblue]
	140309077244400 -> 140309917479984
	140309917479984 [label=AccumulateGrad]
	140309917480224 -> 140309917479792
	140309077244800 [label="stage4.2.fuse_layers.3.1.1.0.weight
 (144, 36, 3, 3)" fillcolor=lightblue]
	140309077244800 -> 140309917480224
	140309917480224 [label=AccumulateGrad]
	140309917479360 -> 140309917479072
	140309077244880 [label="stage4.2.fuse_layers.3.1.1.1.weight
 (144)" fillcolor=lightblue]
	140309077244880 -> 140309917479360
	140309917479360 [label=AccumulateGrad]
	140309917479312 -> 140309917479072
	140309077244960 [label="stage4.2.fuse_layers.3.1.1.1.bias
 (144)" fillcolor=lightblue]
	140309077244960 -> 140309917479312
	140309917479312 [label=AccumulateGrad]
	140310156636064 -> 140310156636016
	140310156636064 [label=NativeBatchNormBackward0]
	140309917479552 -> 140310156636064
	140309917479552 [label=ConvolutionBackward0]
	140309917482528 -> 140309917479552
	140309917482528 [label=ReluBackward0]
	140309917481472 -> 140309917482528
	140309917481472 [label=AddBackward0]
	140310157340576 -> 140309917481472
	140310157340576 [label=NativeBatchNormBackward0]
	140309917455600 -> 140310157340576
	140309917455600 [label=ConvolutionBackward0]
	140309654183216 -> 140309917455600
	140309654183216 [label=ReluBackward0]
	140309654183408 -> 140309654183216
	140309654183408 [label=NativeBatchNormBackward0]
	140309654213488 -> 140309654183408
	140309654213488 [label=ConvolutionBackward0]
	140310157337888 -> 140309654213488
	140310157337888 [label=ReluBackward0]
	140309654216128 -> 140310157337888
	140309654216128 [label=AddBackward0]
	140309654216512 -> 140309654216128
	140309654216512 [label=NativeBatchNormBackward0]
	140309654262784 -> 140309654216512
	140309654262784 [label=ConvolutionBackward0]
	140309654263312 -> 140309654262784
	140309654263312 [label=ReluBackward0]
	140309654263072 -> 140309654263312
	140309654263072 [label=NativeBatchNormBackward0]
	140309654263552 -> 140309654263072
	140309654263552 [label=ConvolutionBackward0]
	140309654215744 -> 140309654263552
	140309654215744 [label=ReluBackward0]
	140309654263840 -> 140309654215744
	140309654263840 [label=AddBackward0]
	140309654263936 -> 140309654263840
	140309654263936 [label=NativeBatchNormBackward0]
	140309654264080 -> 140309654263936
	140309654264080 [label=ConvolutionBackward0]
	140309654264272 -> 140309654264080
	140309654264272 [label=ReluBackward0]
	140309654264416 -> 140309654264272
	140309654264416 [label=NativeBatchNormBackward0]
	140309654264512 -> 140309654264416
	140309654264512 [label=ConvolutionBackward0]
	140309654263888 -> 140309654264512
	140309654263888 [label=ReluBackward0]
	140309654264800 -> 140309654263888
	140309654264800 [label=AddBackward0]
	140309654264896 -> 140309654264800
	140309654264896 [label=NativeBatchNormBackward0]
	140309654265040 -> 140309654264896
	140309654265040 [label=ConvolutionBackward0]
	140309654265232 -> 140309654265040
	140309654265232 [label=ReluBackward0]
	140309654265376 -> 140309654265232
	140309654265376 [label=NativeBatchNormBackward0]
	140309654265472 -> 140309654265376
	140309654265472 [label=ConvolutionBackward0]
	140309654264848 -> 140309654265472
	140309654264848 [label=ReluBackward0]
	140309654265760 -> 140309654264848
	140309654265760 [label=AddBackward0]
	140309654265808 -> 140309654265760
	140309654265808 [label=AddBackward0]
	140309654294736 -> 140309654265808
	140309654294736 [label=AddBackward0]
	140309654294832 -> 140309654294736
	140309654294832 [label=NativeBatchNormBackward0]
	140309654294976 -> 140309654294832
	140309654294976 [label=ConvolutionBackward0]
	140309654295168 -> 140309654294976
	140309654295168 [label=ReluBackward0]
	140309654295312 -> 140309654295168
	140309654295312 [label=NativeBatchNormBackward0]
	140309654295408 -> 140309654295312
	140309654295408 [label=ConvolutionBackward0]
	140309917456512 -> 140309654295408
	140309654295600 -> 140309654295408
	140309075283456 [label="stage4.1.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309075283456 -> 140309654295600
	140309654295600 [label=AccumulateGrad]
	140309654295360 -> 140309654295312
	140309075283536 [label="stage4.1.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140309075283536 -> 140309654295360
	140309654295360 [label=AccumulateGrad]
	140309654295216 -> 140309654295312
	140309075283616 [label="stage4.1.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140309075283616 -> 140309654295216
	140309654295216 [label=AccumulateGrad]
	140309654295120 -> 140309654294976
	140309075390608 [label="stage4.1.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140309075390608 -> 140309654295120
	140309654295120 [label=AccumulateGrad]
	140309654294928 -> 140309654294832
	140309075390688 [label="stage4.1.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140309075390688 -> 140309654294928
	140309654294928 [label=AccumulateGrad]
	140309654294880 -> 140309654294832
	140309075390768 [label="stage4.1.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140309075390768 -> 140309654294880
	140309654294880 [label=AccumulateGrad]
	140309654294784 -> 140309654294736
	140309654294784 [label=NativeBatchNormBackward0]
	140309654295552 -> 140309654294784
	140309654295552 [label=ConvolutionBackward0]
	140309917457856 -> 140309654295552
	140309654295648 -> 140309654295552
	140309075391168 [label="stage4.1.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140309075391168 -> 140309654295648
	140309654295648 [label=AccumulateGrad]
	140309654295072 -> 140309654294784
	140309075391248 [label="stage4.1.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140309075391248 -> 140309654295072
	140309654295072 [label=AccumulateGrad]
	140309654295024 -> 140309654294784
	140309075391328 [label="stage4.1.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140309075391328 -> 140309654295024
	140309654295024 [label=AccumulateGrad]
	140309917458096 -> 140309654265808
	140309654265568 -> 140309654265760
	140309654265568 [label=UpsampleNearest2DBackward1]
	140309654295456 -> 140309654265568
	140309654295456 [label=NativeBatchNormBackward0]
	140309654295744 -> 140309654295456
	140309654295744 [label=ConvolutionBackward0]
	140310157315760 -> 140309654295744
	140309654295840 -> 140309654295744
	140309075391728 [label="stage4.1.fuse_layers.2.3.0.weight
 (72, 144, 1, 1)" fillcolor=lightblue]
	140309075391728 -> 140309654295840
	140309654295840 [label=AccumulateGrad]
	140309654295696 -> 140309654295456
	140309075391808 [label="stage4.1.fuse_layers.2.3.1.weight
 (72)" fillcolor=lightblue]
	140309075391808 -> 140309654295696
	140309654295696 [label=AccumulateGrad]
	140309654294688 -> 140309654295456
	140309075391888 [label="stage4.1.fuse_layers.2.3.1.bias
 (72)" fillcolor=lightblue]
	140309075391888 -> 140309654294688
	140309654294688 [label=AccumulateGrad]
	140309654265664 -> 140309654265472
	140310427641952 [label="stage4.2.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140310427641952 -> 140309654265664
	140309654265664 [label=AccumulateGrad]
	140309654265424 -> 140309654265376
	140310427642032 [label="stage4.2.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140310427642032 -> 140309654265424
	140309654265424 [label=AccumulateGrad]
	140309654265280 -> 140309654265376
	140310427642112 [label="stage4.2.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140310427642112 -> 140309654265280
	140309654265280 [label=AccumulateGrad]
	140309654265184 -> 140309654265040
	140310427642512 [label="stage4.2.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140310427642512 -> 140309654265184
	140309654265184 [label=AccumulateGrad]
	140309654264992 -> 140309654264896
	140310427642592 [label="stage4.2.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140310427642592 -> 140309654264992
	140309654264992 [label=AccumulateGrad]
	140309654264944 -> 140309654264896
	140310427642672 [label="stage4.2.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140310427642672 -> 140309654264944
	140309654264944 [label=AccumulateGrad]
	140309654264848 -> 140309654264800
	140309654264704 -> 140309654264512
	140310427643072 [label="stage4.2.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140310427643072 -> 140309654264704
	140309654264704 [label=AccumulateGrad]
	140309654264464 -> 140309654264416
	140310427643152 [label="stage4.2.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140310427643152 -> 140309654264464
	140309654264464 [label=AccumulateGrad]
	140309654264320 -> 140309654264416
	140310427643232 [label="stage4.2.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140310427643232 -> 140309654264320
	140309654264320 [label=AccumulateGrad]
	140309654264224 -> 140309654264080
	140310427643632 [label="stage4.2.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140310427643632 -> 140309654264224
	140309654264224 [label=AccumulateGrad]
	140309654264032 -> 140309654263936
	140310427643712 [label="stage4.2.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140310427643712 -> 140309654264032
	140309654264032 [label=AccumulateGrad]
	140309654263984 -> 140309654263936
	140310427643792 [label="stage4.2.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140310427643792 -> 140309654263984
	140309654263984 [label=AccumulateGrad]
	140309654263888 -> 140309654263840
	140309654263744 -> 140309654263552
	140310427767168 [label="stage4.2.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140310427767168 -> 140309654263744
	140309654263744 [label=AccumulateGrad]
	140309654263504 -> 140309654263072
	140310427767248 [label="stage4.2.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140310427767248 -> 140309654263504
	140309654263504 [label=AccumulateGrad]
	140309654263456 -> 140309654263072
	140310427767328 [label="stage4.2.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140310427767328 -> 140309654263456
	140309654263456 [label=AccumulateGrad]
	140309654263216 -> 140309654262784
	140310427767728 [label="stage4.2.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140310427767728 -> 140309654263216
	140309654263216 [label=AccumulateGrad]
	140309654261872 -> 140309654216512
	140310427767808 [label="stage4.2.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140310427767808 -> 140309654261872
	140309654261872 [label=AccumulateGrad]
	140309654262016 -> 140309654216512
	140310427767888 [label="stage4.2.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140310427767888 -> 140309654262016
	140309654262016 [label=AccumulateGrad]
	140309654215744 -> 140309654216128
	140309654216464 -> 140309654213488
	140310427768288 [label="stage4.2.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140310427768288 -> 140309654216464
	140309654216464 [label=AccumulateGrad]
	140309654213008 -> 140309654183408
	140310427768368 [label="stage4.2.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140310427768368 -> 140309654213008
	140309654213008 [label=AccumulateGrad]
	140309654213104 -> 140309654183408
	140310427768448 [label="stage4.2.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140310427768448 -> 140309654213104
	140309654213104 [label=AccumulateGrad]
	140309654183744 -> 140309917455600
	140310427768848 [label="stage4.2.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140310427768848 -> 140309654183744
	140309654183744 [label=AccumulateGrad]
	140309917455936 -> 140310157340576
	140310427768928 [label="stage4.2.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140310427768928 -> 140309917455936
	140309917455936 [label=AccumulateGrad]
	140309917455360 -> 140310157340576
	140310427769008 [label="stage4.2.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140310427769008 -> 140309917455360
	140309917455360 [label=AccumulateGrad]
	140310157337888 -> 140309917481472
	140309917480800 -> 140309917479552
	140309077245360 [label="stage4.2.fuse_layers.3.2.0.0.weight
 (144, 72, 3, 3)" fillcolor=lightblue]
	140309077245360 -> 140309917480800
	140309917480800 [label=AccumulateGrad]
	140309917479744 -> 140310156636064
	140309077245440 [label="stage4.2.fuse_layers.3.2.0.1.weight
 (144)" fillcolor=lightblue]
	140309077245440 -> 140309917479744
	140309917479744 [label=AccumulateGrad]
	140309917479024 -> 140310156636064
	140309077245520 [label="stage4.2.fuse_layers.3.2.0.1.bias
 (144)" fillcolor=lightblue]
	140309077245520 -> 140309917479024
	140309917479024 [label=AccumulateGrad]
	140310156635968 -> 140310156635920
	140310156635968 [label=ReluBackward0]
	140309917454448 -> 140310156635968
	140309917454448 [label=AddBackward0]
	140309917481376 -> 140309917454448
	140309917481376 [label=NativeBatchNormBackward0]
	140309654180432 -> 140309917481376
	140309654180432 [label=ConvolutionBackward0]
	140309654215888 -> 140309654180432
	140309654215888 [label=ReluBackward0]
	140309654263696 -> 140309654215888
	140309654263696 [label=NativeBatchNormBackward0]
	140309654263408 -> 140309654263696
	140309654263408 [label=ConvolutionBackward0]
	140309917481280 -> 140309654263408
	140309917481280 [label=ReluBackward0]
	140309654264560 -> 140309917481280
	140309654264560 [label=AddBackward0]
	140309654265088 -> 140309654264560
	140309654265088 [label=NativeBatchNormBackward0]
	140309654265136 -> 140309654265088
	140309654265136 [label=ConvolutionBackward0]
	140309654265712 -> 140309654265136
	140309654265712 [label=ReluBackward0]
	140309654295504 -> 140309654265712
	140309654295504 [label=NativeBatchNormBackward0]
	140309654295936 -> 140309654295504
	140309654295936 [label=ConvolutionBackward0]
	140309654264368 -> 140309654295936
	140309654264368 [label=ReluBackward0]
	140309654296128 -> 140309654264368
	140309654296128 [label=AddBackward0]
	140309654296224 -> 140309654296128
	140309654296224 [label=NativeBatchNormBackward0]
	140309654296368 -> 140309654296224
	140309654296368 [label=ConvolutionBackward0]
	140309654296560 -> 140309654296368
	140309654296560 [label=ReluBackward0]
	140309654296704 -> 140309654296560
	140309654296704 [label=NativeBatchNormBackward0]
	140309654296800 -> 140309654296704
	140309654296800 [label=ConvolutionBackward0]
	140309654296176 -> 140309654296800
	140309654296176 [label=ReluBackward0]
	140309654297088 -> 140309654296176
	140309654297088 [label=AddBackward0]
	140309654297184 -> 140309654297088
	140309654297184 [label=NativeBatchNormBackward0]
	140309654297328 -> 140309654297184
	140309654297328 [label=ConvolutionBackward0]
	140309654297520 -> 140309654297328
	140309654297520 [label=ReluBackward0]
	140309654297664 -> 140309654297520
	140309654297664 [label=NativeBatchNormBackward0]
	140309654297760 -> 140309654297664
	140309654297760 [label=ConvolutionBackward0]
	140309654297136 -> 140309654297760
	140309654297136 [label=ReluBackward0]
	140309654298048 -> 140309654297136
	140309654298048 [label=AddBackward0]
	140309654298144 -> 140309654298048
	140309654298144 [label=AddBackward0]
	140309654298240 -> 140309654298144
	140309654298240 [label=AddBackward0]
	140309654298384 -> 140309654298240
	140309654298384 [label=NativeBatchNormBackward0]
	140309654298528 -> 140309654298384
	140309654298528 [label=ConvolutionBackward0]
	140309654327456 -> 140309654298528
	140309654327456 [label=ReluBackward0]
	140309654327600 -> 140309654327456
	140309654327600 [label=NativeBatchNormBackward0]
	140309654327696 -> 140309654327600
	140309654327696 [label=ConvolutionBackward0]
	140309654327888 -> 140309654327696
	140309654327888 [label=ReluBackward0]
	140309654328032 -> 140309654327888
	140309654328032 [label=NativeBatchNormBackward0]
	140309654328128 -> 140309654328032
	140309654328128 [label=ConvolutionBackward0]
	140309917456512 -> 140309654328128
	140309654328320 -> 140309654328128
	140309075392288 [label="stage4.1.fuse_layers.3.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309075392288 -> 140309654328320
	140309654328320 [label=AccumulateGrad]
	140309654328080 -> 140309654328032
	140309075392368 [label="stage4.1.fuse_layers.3.0.0.1.weight
 (18)" fillcolor=lightblue]
	140309075392368 -> 140309654328080
	140309654328080 [label=AccumulateGrad]
	140309654327936 -> 140309654328032
	140309075392448 [label="stage4.1.fuse_layers.3.0.0.1.bias
 (18)" fillcolor=lightblue]
	140309075392448 -> 140309654327936
	140309654327936 [label=AccumulateGrad]
	140309654327840 -> 140309654327696
	140309075392848 [label="stage4.1.fuse_layers.3.0.1.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309075392848 -> 140309654327840
	140309654327840 [label=AccumulateGrad]
	140309654327648 -> 140309654327600
	140309075392928 [label="stage4.1.fuse_layers.3.0.1.1.weight
 (18)" fillcolor=lightblue]
	140309075392928 -> 140309654327648
	140309654327648 [label=AccumulateGrad]
	140309654327504 -> 140309654327600
	140309075393008 [label="stage4.1.fuse_layers.3.0.1.1.bias
 (18)" fillcolor=lightblue]
	140309075393008 -> 140309654327504
	140309654327504 [label=AccumulateGrad]
	140309654327408 -> 140309654298528
	140309075393408 [label="stage4.1.fuse_layers.3.0.2.0.weight
 (144, 18, 3, 3)" fillcolor=lightblue]
	140309075393408 -> 140309654327408
	140309654327408 [label=AccumulateGrad]
	140309654298480 -> 140309654298384
	140309075393488 [label="stage4.1.fuse_layers.3.0.2.1.weight
 (144)" fillcolor=lightblue]
	140309075393488 -> 140309654298480
	140309654298480 [label=AccumulateGrad]
	140309654298432 -> 140309654298384
	140309075393568 [label="stage4.1.fuse_layers.3.0.2.1.bias
 (144)" fillcolor=lightblue]
	140309075393568 -> 140309654298432
	140309654298432 [label=AccumulateGrad]
	140309654298336 -> 140309654298240
	140309654298336 [label=NativeBatchNormBackward0]
	140309654298576 -> 140309654298336
	140309654298576 [label=ConvolutionBackward0]
	140309654328176 -> 140309654298576
	140309654328176 [label=ReluBackward0]
	140309654328368 -> 140309654328176
	140309654328368 [label=NativeBatchNormBackward0]
	140309654328464 -> 140309654328368
	140309654328464 [label=ConvolutionBackward0]
	140309917457856 -> 140309654328464
	140309654328656 -> 140309654328464
	140309075393968 [label="stage4.1.fuse_layers.3.1.0.0.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140309075393968 -> 140309654328656
	140309654328656 [label=AccumulateGrad]
	140309654328224 -> 140309654328368
	140309075394048 [label="stage4.1.fuse_layers.3.1.0.1.weight
 (36)" fillcolor=lightblue]
	140309075394048 -> 140309654328224
	140309654328224 [label=AccumulateGrad]
	140309654327984 -> 140309654328368
	140309075394128 [label="stage4.1.fuse_layers.3.1.0.1.bias
 (36)" fillcolor=lightblue]
	140309075394128 -> 140309654327984
	140309654327984 [label=AccumulateGrad]
	140309654328272 -> 140309654298576
	140309348139072 [label="stage4.1.fuse_layers.3.1.1.0.weight
 (144, 36, 3, 3)" fillcolor=lightblue]
	140309348139072 -> 140309654328272
	140309654328272 [label=AccumulateGrad]
	140309654327792 -> 140309654298336
	140309348139152 [label="stage4.1.fuse_layers.3.1.1.1.weight
 (144)" fillcolor=lightblue]
	140309348139152 -> 140309654327792
	140309654327792 [label=AccumulateGrad]
	140309654327360 -> 140309654298336
	140309348139232 [label="stage4.1.fuse_layers.3.1.1.1.bias
 (144)" fillcolor=lightblue]
	140309348139232 -> 140309654327360
	140309654327360 [label=AccumulateGrad]
	140309654298192 -> 140309654298144
	140309654298192 [label=NativeBatchNormBackward0]
	140309654298288 -> 140309654298192
	140309654298288 [label=ConvolutionBackward0]
	140309917458096 -> 140309654298288
	140309654328752 -> 140309654298288
	140309348139632 [label="stage4.1.fuse_layers.3.2.0.0.weight
 (144, 72, 3, 3)" fillcolor=lightblue]
	140309348139632 -> 140309654328752
	140309654328752 [label=AccumulateGrad]
	140309654327552 -> 140309654298192
	140309348139712 [label="stage4.1.fuse_layers.3.2.0.1.weight
 (144)" fillcolor=lightblue]
	140309348139712 -> 140309654327552
	140309654327552 [label=AccumulateGrad]
	140309654327744 -> 140309654298192
	140309348139792 [label="stage4.1.fuse_layers.3.2.0.1.bias
 (144)" fillcolor=lightblue]
	140309348139792 -> 140309654327744
	140309654327744 [label=AccumulateGrad]
	140310157315760 -> 140309654298048
	140309654297952 -> 140309654297760
	140310427769408 [label="stage4.2.branches.3.0.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140310427769408 -> 140309654297952
	140309654297952 [label=AccumulateGrad]
	140309654297712 -> 140309654297664
	140310427769488 [label="stage4.2.branches.3.0.bn1.weight
 (144)" fillcolor=lightblue]
	140310427769488 -> 140309654297712
	140309654297712 [label=AccumulateGrad]
	140309654297568 -> 140309654297664
	140310427769568 [label="stage4.2.branches.3.0.bn1.bias
 (144)" fillcolor=lightblue]
	140310427769568 -> 140309654297568
	140309654297568 [label=AccumulateGrad]
	140309654297472 -> 140309654297328
	140310427769968 [label="stage4.2.branches.3.0.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140310427769968 -> 140309654297472
	140309654297472 [label=AccumulateGrad]
	140309654297280 -> 140309654297184
	140310427770048 [label="stage4.2.branches.3.0.bn2.weight
 (144)" fillcolor=lightblue]
	140310427770048 -> 140309654297280
	140309654297280 [label=AccumulateGrad]
	140309654297232 -> 140309654297184
	140310427770128 [label="stage4.2.branches.3.0.bn2.bias
 (144)" fillcolor=lightblue]
	140310427770128 -> 140309654297232
	140309654297232 [label=AccumulateGrad]
	140309654297136 -> 140309654297088
	140309654296992 -> 140309654296800
	140310427770528 [label="stage4.2.branches.3.1.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140310427770528 -> 140309654296992
	140309654296992 [label=AccumulateGrad]
	140309654296752 -> 140309654296704
	140310427770608 [label="stage4.2.branches.3.1.bn1.weight
 (144)" fillcolor=lightblue]
	140310427770608 -> 140309654296752
	140309654296752 [label=AccumulateGrad]
	140309654296608 -> 140309654296704
	140310427770688 [label="stage4.2.branches.3.1.bn1.bias
 (144)" fillcolor=lightblue]
	140310427770688 -> 140309654296608
	140309654296608 [label=AccumulateGrad]
	140309654296512 -> 140309654296368
	140310427881776 [label="stage4.2.branches.3.1.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140310427881776 -> 140309654296512
	140309654296512 [label=AccumulateGrad]
	140309654296320 -> 140309654296224
	140310427881856 [label="stage4.2.branches.3.1.bn2.weight
 (144)" fillcolor=lightblue]
	140310427881856 -> 140309654296320
	140309654296320 [label=AccumulateGrad]
	140309654296272 -> 140309654296224
	140310427881936 [label="stage4.2.branches.3.1.bn2.bias
 (144)" fillcolor=lightblue]
	140310427881936 -> 140309654296272
	140309654296272 [label=AccumulateGrad]
	140309654296176 -> 140309654296128
	140309654296032 -> 140309654295936
	140310427882336 [label="stage4.2.branches.3.2.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140310427882336 -> 140309654296032
	140309654296032 [label=AccumulateGrad]
	140309654295792 -> 140309654295504
	140310427882416 [label="stage4.2.branches.3.2.bn1.weight
 (144)" fillcolor=lightblue]
	140310427882416 -> 140309654295792
	140309654295792 [label=AccumulateGrad]
	140309654294640 -> 140309654295504
	140310427882496 [label="stage4.2.branches.3.2.bn1.bias
 (144)" fillcolor=lightblue]
	140310427882496 -> 140309654294640
	140309654294640 [label=AccumulateGrad]
	140309654265328 -> 140309654265136
	140310427882896 [label="stage4.2.branches.3.2.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140310427882896 -> 140309654265328
	140309654265328 [label=AccumulateGrad]
	140309654264752 -> 140309654265088
	140310427882976 [label="stage4.2.branches.3.2.bn2.weight
 (144)" fillcolor=lightblue]
	140310427882976 -> 140309654264752
	140309654264752 [label=AccumulateGrad]
	140309654264608 -> 140309654265088
	140310427883056 [label="stage4.2.branches.3.2.bn2.bias
 (144)" fillcolor=lightblue]
	140310427883056 -> 140309654264608
	140309654264608 [label=AccumulateGrad]
	140309654264368 -> 140309654264560
	140309654264176 -> 140309654263408
	140310427883456 [label="stage4.2.branches.3.3.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140310427883456 -> 140309654264176
	140309654264176 [label=AccumulateGrad]
	140309654263600 -> 140309654263696
	140310427883536 [label="stage4.2.branches.3.3.bn1.weight
 (144)" fillcolor=lightblue]
	140310427883536 -> 140309654263600
	140309654263600 [label=AccumulateGrad]
	140309654262112 -> 140309654263696
	140310427883616 [label="stage4.2.branches.3.3.bn1.bias
 (144)" fillcolor=lightblue]
	140310427883616 -> 140309654262112
	140309654262112 [label=AccumulateGrad]
	140309654216032 -> 140309654180432
	140310427884016 [label="stage4.2.branches.3.3.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140310427884016 -> 140309654216032
	140309654216032 [label=AccumulateGrad]
	140309654180816 -> 140309917481376
	140310427884096 [label="stage4.2.branches.3.3.bn2.weight
 (144)" fillcolor=lightblue]
	140310427884096 -> 140309654180816
	140309654180816 [label=AccumulateGrad]
	140309917481664 -> 140309917481376
	140310427884176 [label="stage4.2.branches.3.3.bn2.bias
 (144)" fillcolor=lightblue]
	140310427884176 -> 140309917481664
	140309917481664 [label=AccumulateGrad]
	140309917481280 -> 140309917454448
	140310156635728 -> 140310156635584
	140309351685392 [label="incre_modules.3.0.conv1.weight
 (256, 144, 1, 1)" fillcolor=lightblue]
	140309351685392 -> 140310156635728
	140310156635728 [label=AccumulateGrad]
	140310156635536 -> 140310156635488
	140309351685472 [label="incre_modules.3.0.bn1.weight
 (256)" fillcolor=lightblue]
	140309351685472 -> 140310156635536
	140310156635536 [label=AccumulateGrad]
	140310156635392 -> 140310156635488
	140309351685552 [label="incre_modules.3.0.bn1.bias
 (256)" fillcolor=lightblue]
	140309351685552 -> 140310156635392
	140310156635392 [label=AccumulateGrad]
	140310156635296 -> 140310156635200
	140309351686032 [label="incre_modules.3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140309351686032 -> 140310156635296
	140310156635296 [label=AccumulateGrad]
	140310156634912 -> 140310156635056
	140309351685952 [label="incre_modules.3.0.bn2.weight
 (256)" fillcolor=lightblue]
	140309351685952 -> 140310156634912
	140310156634912 [label=AccumulateGrad]
	140310156634480 -> 140310156635056
	140309353713728 [label="incre_modules.3.0.bn2.bias
 (256)" fillcolor=lightblue]
	140309353713728 -> 140310156634480
	140310156634480 [label=AccumulateGrad]
	140310156635008 -> 140310156634432
	140309353714128 [label="incre_modules.3.0.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140309353714128 -> 140310156635008
	140310156635008 [label=AccumulateGrad]
	140310156634384 -> 140310156634576
	140309353714208 [label="incre_modules.3.0.bn3.weight
 (1024)" fillcolor=lightblue]
	140309353714208 -> 140310156634384
	140310156634384 [label=AccumulateGrad]
	140310156634624 -> 140310156634576
	140309353714288 [label="incre_modules.3.0.bn3.bias
 (1024)" fillcolor=lightblue]
	140309353714288 -> 140310156634624
	140310156634624 [label=AccumulateGrad]
	140310156634816 -> 140310156634720
	140310156634816 [label=NativeBatchNormBackward0]
	140309917456224 -> 140310156634816
	140309917456224 [label=ConvolutionBackward0]
	140310156635776 -> 140309917456224
	140310156635632 -> 140309917456224
	140309351684832 [label="incre_modules.3.0.downsample.0.weight
 (1024, 144, 1, 1)" fillcolor=lightblue]
	140309351684832 -> 140310156635632
	140310156635632 [label=AccumulateGrad]
	140310156635104 -> 140310156634816
	140309351684912 [label="incre_modules.3.0.downsample.1.weight
 (1024)" fillcolor=lightblue]
	140309351684912 -> 140310156635104
	140310156635104 [label=AccumulateGrad]
	140310156633952 -> 140310156634816
	140309351684992 [label="incre_modules.3.0.downsample.1.bias
 (1024)" fillcolor=lightblue]
	140309351684992 -> 140310156633952
	140310156633952 [label=AccumulateGrad]
	140310156634288 -> 140310156634672
	140310156634288 [label=ReluBackward0]
	140310156635152 -> 140310156634288
	140310156635152 [label=NativeBatchNormBackward0]
	140310156635680 -> 140310156635152
	140310156635680 [label=ConvolutionBackward0]
	140310156635872 -> 140310156635680
	140310156635872 [label=AddBackward0]
	140309654213920 -> 140310156635872
	140309654213920 [label=ReluBackward0]
	140309654265616 -> 140309654213920
	140309654265616 [label=AddBackward0]
	140309654264656 -> 140309654265616
	140309654264656 [label=NativeBatchNormBackward0]
	140309654265520 -> 140309654264656
	140309654265520 [label=ConvolutionBackward0]
	140309654296080 -> 140309654265520
	140309654296080 [label=ReluBackward0]
	140309654296848 -> 140309654296080
	140309654296848 [label=NativeBatchNormBackward0]
	140309654297376 -> 140309654296848
	140309654297376 [label=ConvolutionBackward0]
	140309654297904 -> 140309654297376
	140309654297904 [label=ReluBackward0]
	140309654297856 -> 140309654297904
	140309654297856 [label=NativeBatchNormBackward0]
	140309654298000 -> 140309654297856
	140309654298000 [label=ConvolutionBackward0]
	140309654328704 -> 140309654298000
	140309654328704 [label=ReluBackward0]
	140309654328848 -> 140309654328704
	140309654328848 [label=AddBackward0]
	140309654328944 -> 140309654328848
	140309654328944 [label=AddBackward0]
	140309654329088 -> 140309654328944
	140309654329088 [label=AddBackward0]
	140309654329184 -> 140309654329088
	140309654329184 [label=NativeBatchNormBackward0]
	140309654329328 -> 140309654329184
	140309654329328 [label=ConvolutionBackward0]
	140309654329520 -> 140309654329328
	140309654329520 [label=ReluBackward0]
	140309654329664 -> 140309654329520
	140309654329664 [label=NativeBatchNormBackward0]
	140309654329760 -> 140309654329664
	140309654329760 [label=ConvolutionBackward0]
	140309917480320 -> 140309654329760
	140309654329952 -> 140309654329760
	140309077129632 [label="stage4.2.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140309077129632 -> 140309654329952
	140309654329952 [label=AccumulateGrad]
	140309654329712 -> 140309654329664
	140309077129712 [label="stage4.2.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140309077129712 -> 140309654329712
	140309654329712 [label=AccumulateGrad]
	140309654329568 -> 140309654329664
	140309077129792 [label="stage4.2.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140309077129792 -> 140309654329568
	140309654329568 [label=AccumulateGrad]
	140309654329472 -> 140309654329328
	140309077130192 [label="stage4.2.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140309077130192 -> 140309654329472
	140309654329472 [label=AccumulateGrad]
	140309654329280 -> 140309654329184
	140309077130272 [label="stage4.2.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140309077130272 -> 140309654329280
	140309654329280 [label=AccumulateGrad]
	140309654329232 -> 140309654329184
	140309077130352 [label="stage4.2.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140309077130352 -> 140309654329232
	140309654329232 [label=AccumulateGrad]
	140309654329136 -> 140309654329088
	140309654329136 [label=NativeBatchNormBackward0]
	140309654329904 -> 140309654329136
	140309654329904 [label=ConvolutionBackward0]
	140309917481856 -> 140309654329904
	140309654330000 -> 140309654329904
	140309077130752 [label="stage4.2.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140309077130752 -> 140309654330000
	140309654330000 [label=AccumulateGrad]
	140309654329424 -> 140309654329136
	140309077130832 [label="stage4.2.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140309077130832 -> 140309654329424
	140309654329424 [label=AccumulateGrad]
	140309654329376 -> 140309654329136
	140309077130912 [label="stage4.2.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140309077130912 -> 140309654329376
	140309654329376 [label=AccumulateGrad]
	140309917482528 -> 140309654328944
	140309654328896 -> 140309654328848
	140309654328896 [label=UpsampleNearest2DBackward1]
	140309654329808 -> 140309654328896
	140309654329808 [label=NativeBatchNormBackward0]
	140309654330096 -> 140309654329808
	140309654330096 [label=ConvolutionBackward0]
	140310156635968 -> 140309654330096
	140309654330192 -> 140309654330096
	140309077242000 [label="stage4.2.fuse_layers.2.3.0.weight
 (72, 144, 1, 1)" fillcolor=lightblue]
	140309077242000 -> 140309654330192
	140309654330192 [label=AccumulateGrad]
	140309654330048 -> 140309654329808
	140309077242080 [label="stage4.2.fuse_layers.2.3.1.weight
 (72)" fillcolor=lightblue]
	140309077242080 -> 140309654330048
	140309654330048 [label=AccumulateGrad]
	140309654329040 -> 140309654329808
	140309077242160 [label="stage4.2.fuse_layers.2.3.1.bias
 (72)" fillcolor=lightblue]
	140309077242160 -> 140309654329040
	140309654329040 [label=AccumulateGrad]
	140309654328560 -> 140309654298000
	140309351683152 [label="incre_modules.2.0.conv1.weight
 (128, 72, 1, 1)" fillcolor=lightblue]
	140309351683152 -> 140309654328560
	140309654328560 [label=AccumulateGrad]
	140309654298096 -> 140309654297856
	140309351683232 [label="incre_modules.2.0.bn1.weight
 (128)" fillcolor=lightblue]
	140309351683232 -> 140309654298096
	140309654298096 [label=AccumulateGrad]
	140309654297808 -> 140309654297856
	140309351683312 [label="incre_modules.2.0.bn1.bias
 (128)" fillcolor=lightblue]
	140309351683312 -> 140309654297808
	140309654297808 [label=AccumulateGrad]
	140309654297424 -> 140309654297376
	140309351683792 [label="incre_modules.2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140309351683792 -> 140309654297424
	140309654297424 [label=AccumulateGrad]
	140309654296656 -> 140309654296848
	140309351683712 [label="incre_modules.2.0.bn2.weight
 (128)" fillcolor=lightblue]
	140309351683712 -> 140309654296656
	140309654296656 [label=AccumulateGrad]
	140309654296464 -> 140309654296848
	140309351683872 [label="incre_modules.2.0.bn2.bias
 (128)" fillcolor=lightblue]
	140309351683872 -> 140309654296464
	140309654296464 [label=AccumulateGrad]
	140309654295264 -> 140309654265520
	140309351684272 [label="incre_modules.2.0.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	140309351684272 -> 140309654295264
	140309654295264 [label=AccumulateGrad]
	140309654295888 -> 140309654264656
	140309351684352 [label="incre_modules.2.0.bn3.weight
 (512)" fillcolor=lightblue]
	140309351684352 -> 140309654295888
	140309654295888 [label=AccumulateGrad]
	140309654295984 -> 140309654264656
	140309351684432 [label="incre_modules.2.0.bn3.bias
 (512)" fillcolor=lightblue]
	140309351684432 -> 140309654295984
	140309654295984 [label=AccumulateGrad]
	140309654263648 -> 140309654265616
	140309654263648 [label=NativeBatchNormBackward0]
	140309654297040 -> 140309654263648
	140309654297040 [label=ConvolutionBackward0]
	140309654328704 -> 140309654297040
	140309654297616 -> 140309654297040
	140309351682592 [label="incre_modules.2.0.downsample.0.weight
 (512, 72, 1, 1)" fillcolor=lightblue]
	140309351682592 -> 140309654297616
	140309654297616 [label=AccumulateGrad]
	140309654296416 -> 140309654263648
	140309351682672 [label="incre_modules.2.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	140309351682672 -> 140309654296416
	140309654296416 [label=AccumulateGrad]
	140309654294592 -> 140309654263648
	140309351682752 [label="incre_modules.2.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	140309351682752 -> 140309654294592
	140309654294592 [label=AccumulateGrad]
	140309654263792 -> 140310156635872
	140309654263792 [label=ReluBackward0]
	140309654264128 -> 140309654263792
	140309654264128 [label=NativeBatchNormBackward0]
	140309654296944 -> 140309654264128
	140309654296944 [label=ConvolutionBackward0]
	140309654328800 -> 140309654296944
	140309654328800 [label=AddBackward0]
	140309654330240 -> 140309654328800
	140309654330240 [label=ReluBackward0]
	140309654330384 -> 140309654330240
	140309654330384 [label=AddBackward0]
	140309654330480 -> 140309654330384
	140309654330480 [label=NativeBatchNormBackward0]
	140309654330624 -> 140309654330480
	140309654330624 [label=ConvolutionBackward0]
	140309654330816 -> 140309654330624
	140309654330816 [label=ReluBackward0]
	140309654330960 -> 140309654330816
	140309654330960 [label=NativeBatchNormBackward0]
	140309654331056 -> 140309654330960
	140309654331056 [label=ConvolutionBackward0]
	140309654331248 -> 140309654331056
	140309654331248 [label=ReluBackward0]
	140309654331344 -> 140309654331248
	140309654331344 [label=NativeBatchNormBackward0]
	140309654380704 -> 140309654331344
	140309654380704 [label=ConvolutionBackward0]
	140309654380896 -> 140309654380704
	140309654380896 [label=ReluBackward0]
	140309654381040 -> 140309654380896
	140309654381040 [label=AddBackward0]
	140309654381136 -> 140309654381040
	140309654381136 [label=AddBackward0]
	140309654381280 -> 140309654381136
	140309654381280 [label=AddBackward0]
	140309654381424 -> 140309654381280
	140309654381424 [label=NativeBatchNormBackward0]
	140309654381520 -> 140309654381424
	140309654381520 [label=ConvolutionBackward0]
	140309917480320 -> 140309654381520
	140309654381712 -> 140309654381520
	140309077127952 [label="stage4.2.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140309077127952 -> 140309654381712
	140309654381712 [label=AccumulateGrad]
	140309654381472 -> 140309654381424
	140309077128032 [label="stage4.2.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140309077128032 -> 140309654381472
	140309654381472 [label=AccumulateGrad]
	140309654381328 -> 140309654381424
	140309077128112 [label="stage4.2.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140309077128112 -> 140309654381328
	140309654381328 [label=AccumulateGrad]
	140309917481856 -> 140309654381280
	140309654381232 -> 140309654381136
	140309654381232 [label=UpsampleNearest2DBackward1]
	140309654381664 -> 140309654381232
	140309654381664 [label=NativeBatchNormBackward0]
	140309654381760 -> 140309654381664
	140309654381760 [label=ConvolutionBackward0]
	140309917482528 -> 140309654381760
	140309654381952 -> 140309654381760
	140309077128512 [label="stage4.2.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140309077128512 -> 140309654381952
	140309654381952 [label=AccumulateGrad]
	140309654381808 -> 140309654381664
	140309077128592 [label="stage4.2.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140309077128592 -> 140309654381808
	140309654381808 [label=AccumulateGrad]
	140309654381376 -> 140309654381664
	140309077128672 [label="stage4.2.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140309077128672 -> 140309654381376
	140309654381376 [label=AccumulateGrad]
	140309654381088 -> 140309654381040
	140309654381088 [label=UpsampleNearest2DBackward1]
	140309654381616 -> 140309654381088
	140309654381616 [label=NativeBatchNormBackward0]
	140309654382048 -> 140309654381616
	140309654382048 [label=ConvolutionBackward0]
	140310156635968 -> 140309654382048
	140309654382144 -> 140309654382048
	140309077129072 [label="stage4.2.fuse_layers.1.3.0.weight
 (36, 144, 1, 1)" fillcolor=lightblue]
	140309077129072 -> 140309654382144
	140309654382144 [label=AccumulateGrad]
	140309654381904 -> 140309654381616
	140309077129152 [label="stage4.2.fuse_layers.1.3.1.weight
 (36)" fillcolor=lightblue]
	140309077129152 -> 140309654381904
	140309654381904 [label=AccumulateGrad]
	140309654381184 -> 140309654381616
	140309077129232 [label="stage4.2.fuse_layers.1.3.1.bias
 (36)" fillcolor=lightblue]
	140309077129232 -> 140309654381184
	140309654381184 [label=AccumulateGrad]
	140309654380848 -> 140309654380704
	140309351574320 [label="incre_modules.1.0.conv1.weight
 (64, 36, 1, 1)" fillcolor=lightblue]
	140309351574320 -> 140309654380848
	140309654380848 [label=AccumulateGrad]
	140309654380656 -> 140309654331344
	140309351574400 [label="incre_modules.1.0.bn1.weight
 (64)" fillcolor=lightblue]
	140309351574400 -> 140309654380656
	140309654380656 [label=AccumulateGrad]
	140309654380608 -> 140309654331344
	140309351574480 [label="incre_modules.1.0.bn1.bias
 (64)" fillcolor=lightblue]
	140309351574480 -> 140309654380608
	140309654380608 [label=AccumulateGrad]
	140309654331200 -> 140309654331056
	140309351574960 [label="incre_modules.1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140309351574960 -> 140309654331200
	140309654331200 [label=AccumulateGrad]
	140309654331008 -> 140309654330960
	140309351574880 [label="incre_modules.1.0.bn2.weight
 (64)" fillcolor=lightblue]
	140309351574880 -> 140309654331008
	140309654331008 [label=AccumulateGrad]
	140309654330864 -> 140309654330960
	140309351575040 [label="incre_modules.1.0.bn2.bias
 (64)" fillcolor=lightblue]
	140309351575040 -> 140309654330864
	140309654330864 [label=AccumulateGrad]
	140309654330768 -> 140309654330624
	140309351575440 [label="incre_modules.1.0.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140309351575440 -> 140309654330768
	140309654330768 [label=AccumulateGrad]
	140309654330576 -> 140309654330480
	140309351682112 [label="incre_modules.1.0.bn3.weight
 (256)" fillcolor=lightblue]
	140309351682112 -> 140309654330576
	140309654330576 [label=AccumulateGrad]
	140309654330528 -> 140309654330480
	140309351682192 [label="incre_modules.1.0.bn3.bias
 (256)" fillcolor=lightblue]
	140309351682192 -> 140309654330528
	140309654330528 [label=AccumulateGrad]
	140309654330432 -> 140309654330384
	140309654330432 [label=NativeBatchNormBackward0]
	140309654331152 -> 140309654330432
	140309654331152 [label=ConvolutionBackward0]
	140309654380896 -> 140309654331152
	140309654331296 -> 140309654331152
	140309351573760 [label="incre_modules.1.0.downsample.0.weight
 (256, 36, 1, 1)" fillcolor=lightblue]
	140309351573760 -> 140309654331296
	140309654331296 [label=AccumulateGrad]
	140309654330720 -> 140309654330432
	140309351573840 [label="incre_modules.1.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	140309351573840 -> 140309654330720
	140309654330720 [label=AccumulateGrad]
	140309654330672 -> 140309654330432
	140309351573920 [label="incre_modules.1.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	140309351573920 -> 140309654330672
	140309654330672 [label=AccumulateGrad]
	140309654330288 -> 140309654328800
	140309654330288 [label=ReluBackward0]
	140309654331104 -> 140309654330288
	140309654331104 [label=NativeBatchNormBackward0]
	140309654330912 -> 140309654331104
	140309654330912 [label=ConvolutionBackward0]
	140309654380992 -> 140309654330912
	140309654380992 [label=ReluBackward0]
	140309654382192 -> 140309654380992
	140309654382192 [label=AddBackward0]
	140309654382288 -> 140309654382192
	140309654382288 [label=NativeBatchNormBackward0]
	140309654382432 -> 140309654382288
	140309654382432 [label=ConvolutionBackward0]
	140309654382624 -> 140309654382432
	140309654382624 [label=ReluBackward0]
	140309654382768 -> 140309654382624
	140309654382768 [label=NativeBatchNormBackward0]
	140309654382864 -> 140309654382768
	140309654382864 [label=ConvolutionBackward0]
	140309654383056 -> 140309654382864
	140309654383056 [label=ReluBackward0]
	140309654383200 -> 140309654383056
	140309654383200 [label=NativeBatchNormBackward0]
	140309654383296 -> 140309654383200
	140309654383296 [label=ConvolutionBackward0]
	140309654383488 -> 140309654383296
	140309654383488 [label=ReluBackward0]
	140309654383632 -> 140309654383488
	140309654383632 [label=AddBackward0]
	140309654383728 -> 140309654383632
	140309654383728 [label=AddBackward0]
	140309654383872 -> 140309654383728
	140309654383872 [label=AddBackward0]
	140309917480320 -> 140309654383872
	140309654384016 -> 140309654383872
	140309654384016 [label=UpsampleNearest2DBackward1]
	140309654384112 -> 140309654384016
	140309654384112 [label=NativeBatchNormBackward0]
	140309654384208 -> 140309654384112
	140309654384208 [label=ConvolutionBackward0]
	140309917481856 -> 140309654384208
	140309654384400 -> 140309654384208
	140310427884576 [label="stage4.2.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140310427884576 -> 140309654384400
	140309654384400 [label=AccumulateGrad]
	140309654384160 -> 140309654384112
	140310427884656 [label="stage4.2.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140310427884656 -> 140309654384160
	140309654384160 [label=AccumulateGrad]
	140309654383920 -> 140309654384112
	140310427884736 [label="stage4.2.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140310427884736 -> 140309654383920
	140309654383920 [label=AccumulateGrad]
	140309654383824 -> 140309654383728
	140309654383824 [label=UpsampleNearest2DBackward1]
	140309654384256 -> 140309654383824
	140309654384256 [label=NativeBatchNormBackward0]
	140309654384496 -> 140309654384256
	140309654384496 [label=ConvolutionBackward0]
	140309917482528 -> 140309654384496
	140309654384592 -> 140309654384496
	140310427885136 [label="stage4.2.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140310427885136 -> 140309654384592
	140309654384592 [label=AccumulateGrad]
	140309654384352 -> 140309654384256
	140310427885216 [label="stage4.2.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140310427885216 -> 140309654384352
	140309654384352 [label=AccumulateGrad]
	140309654383968 -> 140309654384256
	140310427885296 [label="stage4.2.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140310427885296 -> 140309654383968
	140309654383968 [label=AccumulateGrad]
	140309654383680 -> 140309654383632
	140309654383680 [label=UpsampleNearest2DBackward1]
	140309654384448 -> 140309654383680
	140309654384448 [label=NativeBatchNormBackward0]
	140309654384304 -> 140309654384448
	140309654384304 [label=ConvolutionBackward0]
	140310156635968 -> 140309654384304
	140309654401232 -> 140309654384304
	140309077127392 [label="stage4.2.fuse_layers.0.3.0.weight
 (18, 144, 1, 1)" fillcolor=lightblue]
	140309077127392 -> 140309654401232
	140309654401232 [label=AccumulateGrad]
	140309654384544 -> 140309654384448
	140309077127472 [label="stage4.2.fuse_layers.0.3.1.weight
 (18)" fillcolor=lightblue]
	140309077127472 -> 140309654384544
	140309654384544 [label=AccumulateGrad]
	140309654383776 -> 140309654384448
	140309077127552 [label="stage4.2.fuse_layers.0.3.1.bias
 (18)" fillcolor=lightblue]
	140309077127552 -> 140309654383776
	140309654383776 [label=AccumulateGrad]
	140309654383440 -> 140309654383296
	140309351572080 [label="incre_modules.0.0.conv1.weight
 (32, 18, 1, 1)" fillcolor=lightblue]
	140309351572080 -> 140309654383440
	140309654383440 [label=AccumulateGrad]
	140309654383248 -> 140309654383200
	140309351572160 [label="incre_modules.0.0.bn1.weight
 (32)" fillcolor=lightblue]
	140309351572160 -> 140309654383248
	140309654383248 [label=AccumulateGrad]
	140309654383104 -> 140309654383200
	140309351572240 [label="incre_modules.0.0.bn1.bias
 (32)" fillcolor=lightblue]
	140309351572240 -> 140309654383104
	140309654383104 [label=AccumulateGrad]
	140309654383008 -> 140309654382864
	140309351572720 [label="incre_modules.0.0.conv2.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140309351572720 -> 140309654383008
	140309654383008 [label=AccumulateGrad]
	140309654382816 -> 140309654382768
	140309351572640 [label="incre_modules.0.0.bn2.weight
 (32)" fillcolor=lightblue]
	140309351572640 -> 140309654382816
	140309654382816 [label=AccumulateGrad]
	140309654382672 -> 140309654382768
	140309351572800 [label="incre_modules.0.0.bn2.bias
 (32)" fillcolor=lightblue]
	140309351572800 -> 140309654382672
	140309654382672 [label=AccumulateGrad]
	140309654382576 -> 140309654382432
	140309351573200 [label="incre_modules.0.0.conv3.weight
 (128, 32, 1, 1)" fillcolor=lightblue]
	140309351573200 -> 140309654382576
	140309654382576 [label=AccumulateGrad]
	140309654382384 -> 140309654382288
	140309351573280 [label="incre_modules.0.0.bn3.weight
 (128)" fillcolor=lightblue]
	140309351573280 -> 140309654382384
	140309654382384 [label=AccumulateGrad]
	140309654382336 -> 140309654382288
	140309351573360 [label="incre_modules.0.0.bn3.bias
 (128)" fillcolor=lightblue]
	140309351573360 -> 140309654382336
	140309654382336 [label=AccumulateGrad]
	140309654381856 -> 140309654382192
	140309654381856 [label=NativeBatchNormBackward0]
	140309654382960 -> 140309654381856
	140309654382960 [label=ConvolutionBackward0]
	140309654383488 -> 140309654382960
	140309654383344 -> 140309654382960
	140309351571520 [label="incre_modules.0.0.downsample.0.weight
 (128, 18, 1, 1)" fillcolor=lightblue]
	140309351571520 -> 140309654383344
	140309654383344 [label=AccumulateGrad]
	140309654382528 -> 140309654381856
	140309351571600 [label="incre_modules.0.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	140309351571600 -> 140309654382528
	140309654382528 [label=AccumulateGrad]
	140309654382480 -> 140309654381856
	140309351571680 [label="incre_modules.0.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	140309351571680 -> 140309654382480
	140309654382480 [label=AccumulateGrad]
	140309654380944 -> 140309654330912
	140309353714688 [label="downsamp_modules.0.0.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	140309353714688 -> 140309654380944
	140309654380944 [label=AccumulateGrad]
	140309654380800 -> 140309654330912
	140309353714768 [label="downsamp_modules.0.0.bias
 (256)" fillcolor=lightblue]
	140309353714768 -> 140309654380800
	140309654380800 [label=AccumulateGrad]
	140309654330336 -> 140309654331104
	140309353714848 [label="downsamp_modules.0.1.weight
 (256)" fillcolor=lightblue]
	140309353714848 -> 140309654330336
	140309654330336 [label=AccumulateGrad]
	140309654381568 -> 140309654331104
	140309353714928 [label="downsamp_modules.0.1.bias
 (256)" fillcolor=lightblue]
	140309353714928 -> 140309654381568
	140309654381568 [label=AccumulateGrad]
	140309654328512 -> 140309654296944
	140309353715328 [label="downsamp_modules.1.0.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	140309353715328 -> 140309654328512
	140309654328512 [label=AccumulateGrad]
	140309654328416 -> 140309654296944
	140309353715408 [label="downsamp_modules.1.0.bias
 (512)" fillcolor=lightblue]
	140309353715408 -> 140309654328416
	140309654328416 [label=AccumulateGrad]
	140309654296896 -> 140309654264128
	140309353715488 [label="downsamp_modules.1.1.weight
 (512)" fillcolor=lightblue]
	140309353715488 -> 140309654296896
	140309654296896 [label=AccumulateGrad]
	140309654328992 -> 140309654264128
	140309353715568 [label="downsamp_modules.1.1.bias
 (512)" fillcolor=lightblue]
	140309353715568 -> 140309654328992
	140309654328992 [label=AccumulateGrad]
	140310156635824 -> 140310156635680
	140309353715968 [label="downsamp_modules.2.0.weight
 (1024, 512, 3, 3)" fillcolor=lightblue]
	140309353715968 -> 140310156635824
	140310156635824 [label=AccumulateGrad]
	140310156634864 -> 140310156635680
	140309353716048 [label="downsamp_modules.2.0.bias
 (1024)" fillcolor=lightblue]
	140309353716048 -> 140310156634864
	140310156634864 [label=AccumulateGrad]
	140310156635248 -> 140310156635152
	140309353716128 [label="downsamp_modules.2.1.weight
 (1024)" fillcolor=lightblue]
	140309353716128 -> 140310156635248
	140310156635248 [label=AccumulateGrad]
	140310156634240 -> 140310156635152
	140309353716208 [label="downsamp_modules.2.1.bias
 (1024)" fillcolor=lightblue]
	140309353716208 -> 140310156634240
	140310156634240 [label=AccumulateGrad]
	140310156634768 -> 140309353857184
	140309353716608 [label="final_layer.0.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	140309353716608 -> 140310156634768
	140310156634768 [label=AccumulateGrad]
	140310156634960 -> 140309353857184
	140309353716688 [label="final_layer.0.bias
 (2048)" fillcolor=lightblue]
	140309353716688 -> 140310156634960
	140310156634960 [label=AccumulateGrad]
	140309353857280 -> 140309353859872
	140309353716768 [label="final_layer.1.weight
 (2048)" fillcolor=lightblue]
	140309353716768 -> 140309353857280
	140309353857280 [label=AccumulateGrad]
	140309353857424 -> 140309353859872
	140309353716848 [label="final_layer.1.bias
 (2048)" fillcolor=lightblue]
	140309353716848 -> 140309353857424
	140309353857424 [label=AccumulateGrad]
	140309353860160 -> 140309353857520
	140309353860160 [label=TBackward0]
	140309353860688 -> 140309353860160
	140309353717168 [label="classifier.weight
 (1000, 2048)" fillcolor=lightblue]
	140309353717168 -> 140309353860688
	140309353860688 [label=AccumulateGrad]
	140309353857520 -> 140310156952176
}
