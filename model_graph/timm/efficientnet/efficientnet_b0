digraph {
	graph [size="203.7,203.7"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140235124238512 [label="
 (1, 1000)" fillcolor=darkolivegreen1]
	140236191338208 [label=AddmmBackward0]
	140236191338112 -> 140236191338208
	140235113211120 [label="classifier.bias
 (1000)" fillcolor=lightblue]
	140235113211120 -> 140236191338112
	140236191338112 [label=AccumulateGrad]
	140236191337056 -> 140236191338208
	140236191337056 [label=ReshapeAliasBackward0]
	140236191337008 -> 140236191337056
	140236191337008 [label=MeanBackward1]
	140236191338064 -> 140236191337008
	140236191338064 [label=SiluBackward0]
	140236191338304 -> 140236191338064
	140236191338304 [label=NativeBatchNormBackward0]
	140235113318048 -> 140236191338304
	140235113318048 [label=ConvolutionBackward0]
	140235113317472 -> 140235113318048
	140235113317472 [label=NativeBatchNormBackward0]
	140235113317904 -> 140235113317472
	140235113317904 [label=ConvolutionBackward0]
	140235113318144 -> 140235113317904
	140235113318144 [label=MulBackward0]
	140235113318288 -> 140235113318144
	140235113318288 [label=SiluBackward0]
	140235113318432 -> 140235113318288
	140235113318432 [label=NativeBatchNormBackward0]
	140235113318528 -> 140235113318432
	140235113318528 [label=ConvolutionBackward0]
	140235113318720 -> 140235113318528
	140235113318720 [label=SiluBackward0]
	140235113318864 -> 140235113318720
	140235113318864 [label=NativeBatchNormBackward0]
	140235113318960 -> 140235113318864
	140235113318960 [label=ConvolutionBackward0]
	140235113319152 -> 140235113318960
	140235113319152 [label=AddBackward0]
	140235113319296 -> 140235113319152
	140235113319296 [label=NativeBatchNormBackward0]
	140235113319440 -> 140235113319296
	140235113319440 [label=ConvolutionBackward0]
	140235113319632 -> 140235113319440
	140235113319632 [label=MulBackward0]
	140235113319776 -> 140235113319632
	140235113319776 [label=SiluBackward0]
	140235113319920 -> 140235113319776
	140235113319920 [label=NativeBatchNormBackward0]
	140235113320016 -> 140235113319920
	140235113320016 [label=ConvolutionBackward0]
	140235113320208 -> 140235113320016
	140235113320208 [label=SiluBackward0]
	140235113320352 -> 140235113320208
	140235113320352 [label=NativeBatchNormBackward0]
	140235113320400 -> 140235113320352
	140235113320400 [label=ConvolutionBackward0]
	140235113319248 -> 140235113320400
	140235113319248 [label=AddBackward0]
	140235124191584 -> 140235113319248
	140235124191584 [label=NativeBatchNormBackward0]
	140235124191728 -> 140235124191584
	140235124191728 [label=ConvolutionBackward0]
	140235124191920 -> 140235124191728
	140235124191920 [label=MulBackward0]
	140235124192064 -> 140235124191920
	140235124192064 [label=SiluBackward0]
	140235124192208 -> 140235124192064
	140235124192208 [label=NativeBatchNormBackward0]
	140235124192304 -> 140235124192208
	140235124192304 [label=ConvolutionBackward0]
	140235124192496 -> 140235124192304
	140235124192496 [label=SiluBackward0]
	140235124192640 -> 140235124192496
	140235124192640 [label=NativeBatchNormBackward0]
	140235124192736 -> 140235124192640
	140235124192736 [label=ConvolutionBackward0]
	140235124191536 -> 140235124192736
	140235124191536 [label=AddBackward0]
	140235124193024 -> 140235124191536
	140235124193024 [label=NativeBatchNormBackward0]
	140235124193168 -> 140235124193024
	140235124193168 [label=ConvolutionBackward0]
	140235124193360 -> 140235124193168
	140235124193360 [label=MulBackward0]
	140235124193504 -> 140235124193360
	140235124193504 [label=SiluBackward0]
	140235124193648 -> 140235124193504
	140235124193648 [label=NativeBatchNormBackward0]
	140235124193744 -> 140235124193648
	140235124193744 [label=ConvolutionBackward0]
	140235124193936 -> 140235124193744
	140235124193936 [label=SiluBackward0]
	140235124194080 -> 140235124193936
	140235124194080 [label=NativeBatchNormBackward0]
	140235124194176 -> 140235124194080
	140235124194176 [label=ConvolutionBackward0]
	140235124192976 -> 140235124194176
	140235124192976 [label=NativeBatchNormBackward0]
	140235124194464 -> 140235124192976
	140235124194464 [label=ConvolutionBackward0]
	140235124194656 -> 140235124194464
	140235124194656 [label=MulBackward0]
	140235124194800 -> 140235124194656
	140235124194800 [label=SiluBackward0]
	140235124194944 -> 140235124194800
	140235124194944 [label=NativeBatchNormBackward0]
	140235124195040 -> 140235124194944
	140235124195040 [label=ConvolutionBackward0]
	140235124195232 -> 140235124195040
	140235124195232 [label=SiluBackward0]
	140235124195280 -> 140235124195232
	140235124195280 [label=NativeBatchNormBackward0]
	140235124166864 -> 140235124195280
	140235124166864 [label=ConvolutionBackward0]
	140235124167056 -> 140235124166864
	140235124167056 [label=AddBackward0]
	140235124167200 -> 140235124167056
	140235124167200 [label=NativeBatchNormBackward0]
	140235124167344 -> 140235124167200
	140235124167344 [label=ConvolutionBackward0]
	140235124167536 -> 140235124167344
	140235124167536 [label=MulBackward0]
	140235124167680 -> 140235124167536
	140235124167680 [label=SiluBackward0]
	140235124167824 -> 140235124167680
	140235124167824 [label=NativeBatchNormBackward0]
	140235124167920 -> 140235124167824
	140235124167920 [label=ConvolutionBackward0]
	140235124168112 -> 140235124167920
	140235124168112 [label=SiluBackward0]
	140235124168256 -> 140235124168112
	140235124168256 [label=NativeBatchNormBackward0]
	140235124168352 -> 140235124168256
	140235124168352 [label=ConvolutionBackward0]
	140235124167152 -> 140235124168352
	140235124167152 [label=AddBackward0]
	140235124168640 -> 140235124167152
	140235124168640 [label=NativeBatchNormBackward0]
	140235124168784 -> 140235124168640
	140235124168784 [label=ConvolutionBackward0]
	140235124168976 -> 140235124168784
	140235124168976 [label=MulBackward0]
	140235124169120 -> 140235124168976
	140235124169120 [label=SiluBackward0]
	140235124169264 -> 140235124169120
	140235124169264 [label=NativeBatchNormBackward0]
	140235124169360 -> 140235124169264
	140235124169360 [label=ConvolutionBackward0]
	140235124169552 -> 140235124169360
	140235124169552 [label=SiluBackward0]
	140235124169696 -> 140235124169552
	140235124169696 [label=NativeBatchNormBackward0]
	140235124169792 -> 140235124169696
	140235124169792 [label=ConvolutionBackward0]
	140235124168592 -> 140235124169792
	140235124168592 [label=NativeBatchNormBackward0]
	140235124170080 -> 140235124168592
	140235124170080 [label=ConvolutionBackward0]
	140235124170272 -> 140235124170080
	140235124170272 [label=MulBackward0]
	140235124170416 -> 140235124170272
	140235124170416 [label=SiluBackward0]
	140235124170560 -> 140235124170416
	140235124170560 [label=NativeBatchNormBackward0]
	140235124170608 -> 140235124170560
	140235124170608 [label=ConvolutionBackward0]
	140235124183248 -> 140235124170608
	140235124183248 [label=SiluBackward0]
	140235124183392 -> 140235124183248
	140235124183392 [label=NativeBatchNormBackward0]
	140235124183440 -> 140235124183392
	140235124183440 [label=ConvolutionBackward0]
	140235124183728 -> 140235124183440
	140235124183728 [label=AddBackward0]
	140235124183872 -> 140235124183728
	140235124183872 [label=NativeBatchNormBackward0]
	140235124184016 -> 140235124183872
	140235124184016 [label=ConvolutionBackward0]
	140235124184208 -> 140235124184016
	140235124184208 [label=MulBackward0]
	140235124184352 -> 140235124184208
	140235124184352 [label=SiluBackward0]
	140235124184496 -> 140235124184352
	140235124184496 [label=NativeBatchNormBackward0]
	140235124184544 -> 140235124184496
	140235124184544 [label=ConvolutionBackward0]
	140235124184832 -> 140235124184544
	140235124184832 [label=SiluBackward0]
	140235124184976 -> 140235124184832
	140235124184976 [label=NativeBatchNormBackward0]
	140235124185024 -> 140235124184976
	140235124185024 [label=ConvolutionBackward0]
	140235124183824 -> 140235124185024
	140235124183824 [label=AddBackward0]
	140235124185408 -> 140235124183824
	140235124185408 [label=NativeBatchNormBackward0]
	140235124185552 -> 140235124185408
	140235124185552 [label=ConvolutionBackward0]
	140235124185744 -> 140235124185552
	140235124185744 [label=MulBackward0]
	140235124185888 -> 140235124185744
	140235124185888 [label=SiluBackward0]
	140235124186032 -> 140235124185888
	140235124186032 [label=NativeBatchNormBackward0]
	140235124186080 -> 140235124186032
	140235124186080 [label=ConvolutionBackward0]
	140235124186368 -> 140235124186080
	140235124186368 [label=SiluBackward0]
	140235124186512 -> 140235124186368
	140235124186512 [label=NativeBatchNormBackward0]
	140235124186560 -> 140235124186512
	140235124186560 [label=ConvolutionBackward0]
	140235124185360 -> 140235124186560
	140235124185360 [label=NativeBatchNormBackward0]
	140235124186944 -> 140235124185360
	140235124186944 [label=ConvolutionBackward0]
	140235124187088 -> 140235124186944
	140235124187088 [label=MulBackward0]
	140235124297936 -> 140235124187088
	140235124297936 [label=SiluBackward0]
	140235124298080 -> 140235124297936
	140235124298080 [label=NativeBatchNormBackward0]
	140235124298128 -> 140235124298080
	140235124298128 [label=ConvolutionBackward0]
	140235124298416 -> 140235124298128
	140235124298416 [label=SiluBackward0]
	140235124298560 -> 140235124298416
	140235124298560 [label=NativeBatchNormBackward0]
	140235124298608 -> 140235124298560
	140235124298608 [label=ConvolutionBackward0]
	140235124298896 -> 140235124298608
	140235124298896 [label=AddBackward0]
	140235124299040 -> 140235124298896
	140235124299040 [label=NativeBatchNormBackward0]
	140235124299184 -> 140235124299040
	140235124299184 [label=ConvolutionBackward0]
	140235124299376 -> 140235124299184
	140235124299376 [label=MulBackward0]
	140235124299520 -> 140235124299376
	140235124299520 [label=SiluBackward0]
	140235124299664 -> 140235124299520
	140235124299664 [label=NativeBatchNormBackward0]
	140235124299712 -> 140235124299664
	140235124299712 [label=ConvolutionBackward0]
	140235124300000 -> 140235124299712
	140235124300000 [label=SiluBackward0]
	140235124300144 -> 140235124300000
	140235124300144 [label=NativeBatchNormBackward0]
	140235124300192 -> 140235124300144
	140235124300192 [label=ConvolutionBackward0]
	140235124298992 -> 140235124300192
	140235124298992 [label=NativeBatchNormBackward0]
	140235124300576 -> 140235124298992
	140235124300576 [label=ConvolutionBackward0]
	140235124300768 -> 140235124300576
	140235124300768 [label=MulBackward0]
	140235124300912 -> 140235124300768
	140235124300912 [label=SiluBackward0]
	140235124301056 -> 140235124300912
	140235124301056 [label=NativeBatchNormBackward0]
	140235124301104 -> 140235124301056
	140235124301104 [label=ConvolutionBackward0]
	140235124301392 -> 140235124301104
	140235124301392 [label=SiluBackward0]
	140235124301536 -> 140235124301392
	140235124301536 [label=NativeBatchNormBackward0]
	140235124301584 -> 140235124301536
	140235124301584 [label=ConvolutionBackward0]
	140235124301776 -> 140235124301584
	140235124301776 [label=AddBackward0]
	140235124306176 -> 140235124301776
	140235124306176 [label=NativeBatchNormBackward0]
	140235124306320 -> 140235124306176
	140235124306320 [label=ConvolutionBackward0]
	140235124306512 -> 140235124306320
	140235124306512 [label=MulBackward0]
	140235124306656 -> 140235124306512
	140235124306656 [label=SiluBackward0]
	140235124306800 -> 140235124306656
	140235124306800 [label=NativeBatchNormBackward0]
	140235124306848 -> 140235124306800
	140235124306848 [label=ConvolutionBackward0]
	140235124307136 -> 140235124306848
	140235124307136 [label=SiluBackward0]
	140235124307280 -> 140235124307136
	140235124307280 [label=NativeBatchNormBackward0]
	140235124307328 -> 140235124307280
	140235124307328 [label=ConvolutionBackward0]
	140235124306128 -> 140235124307328
	140235124306128 [label=NativeBatchNormBackward0]
	140235124307712 -> 140235124306128
	140235124307712 [label=ConvolutionBackward0]
	140235124307904 -> 140235124307712
	140235124307904 [label=MulBackward0]
	140235124308048 -> 140235124307904
	140235124308048 [label=SiluBackward0]
	140235124308192 -> 140235124308048
	140235124308192 [label=NativeBatchNormBackward0]
	140235124308240 -> 140235124308192
	140235124308240 [label=ConvolutionBackward0]
	140235124308528 -> 140235124308240
	140235124308528 [label=SiluBackward0]
	140235124308672 -> 140235124308528
	140235124308672 [label=NativeBatchNormBackward0]
	140235124308720 -> 140235124308672
	140235124308720 [label=ConvolutionBackward0]
	140235124309008 -> 140235124308720
	140235124309008 [label=NativeBatchNormBackward0]
	140235124309152 -> 140235124309008
	140235124309152 [label=ConvolutionBackward0]
	140235124309344 -> 140235124309152
	140235124309344 [label=MulBackward0]
	140235124309488 -> 140235124309344
	140235124309488 [label=SiluBackward0]
	140235124309632 -> 140235124309488
	140235124309632 [label=NativeBatchNormBackward0]
	140235124309680 -> 140235124309632
	140235124309680 [label=ConvolutionBackward0]
	140235124309968 -> 140235124309680
	140235124309968 [label=SiluBackward0]
	140235124318368 -> 140235124309968
	140235124318368 [label=NativeBatchNormBackward0]
	140235124318416 -> 140235124318368
	140235124318416 [label=ConvolutionBackward0]
	140235124318704 -> 140235124318416
	140236496429680 [label="conv_stem.weight
 (32, 3, 3, 3)" fillcolor=lightblue]
	140236496429680 -> 140235124318704
	140235124318704 [label=AccumulateGrad]
	140235124318272 -> 140235124318368
	140236496429760 [label="bn1.weight
 (32)" fillcolor=lightblue]
	140236496429760 -> 140235124318272
	140235124318272 [label=AccumulateGrad]
	140235124318512 -> 140235124318368
	140236496429840 [label="bn1.bias
 (32)" fillcolor=lightblue]
	140236496429840 -> 140235124318512
	140235124318512 [label=AccumulateGrad]
	140235124309920 -> 140235124309680
	140236496430480 [label="blocks.0.0.conv_dw.weight
 (32, 1, 3, 3)" fillcolor=lightblue]
	140236496430480 -> 140235124309920
	140235124309920 [label=AccumulateGrad]
	140235124309536 -> 140235124309632
	140236496430560 [label="blocks.0.0.bn1.weight
 (32)" fillcolor=lightblue]
	140236496430560 -> 140235124309536
	140235124309536 [label=AccumulateGrad]
	140235124309776 -> 140235124309632
	140236496430640 [label="blocks.0.0.bn1.bias
 (32)" fillcolor=lightblue]
	140236496430640 -> 140235124309776
	140235124309776 [label=AccumulateGrad]
	140235124309440 -> 140235124309344
	140235124309440 [label=SigmoidBackward0]
	140235124309872 -> 140235124309440
	140235124309872 [label=ConvolutionBackward0]
	140235124309584 -> 140235124309872
	140235124309584 [label=SiluBackward0]
	140235124318848 -> 140235124309584
	140235124318848 [label=ConvolutionBackward0]
	140235124319040 -> 140235124318848
	140235124319040 [label=MeanBackward1]
	140235124309488 -> 140235124319040
	140235124318992 -> 140235124318848
	140236496431200 [label="blocks.0.0.se.conv_reduce.weight
 (8, 32, 1, 1)" fillcolor=lightblue]
	140236496431200 -> 140235124318992
	140235124318992 [label=AccumulateGrad]
	140235124318944 -> 140235124318848
	140236496431280 [label="blocks.0.0.se.conv_reduce.bias
 (8)" fillcolor=lightblue]
	140236496431280 -> 140235124318944
	140235124318944 [label=AccumulateGrad]
	140235124318560 -> 140235124309872
	140236496431440 [label="blocks.0.0.se.conv_expand.weight
 (32, 8, 1, 1)" fillcolor=lightblue]
	140236496431440 -> 140235124318560
	140235124318560 [label=AccumulateGrad]
	140235124318656 -> 140235124309872
	140236496431520 [label="blocks.0.0.se.conv_expand.bias
 (32)" fillcolor=lightblue]
	140236496431520 -> 140235124318656
	140235124318656 [label=AccumulateGrad]
	140235124309296 -> 140235124309152
	140236496431680 [label="blocks.0.0.conv_pw.weight
 (16, 32, 1, 1)" fillcolor=lightblue]
	140236496431680 -> 140235124309296
	140235124309296 [label=AccumulateGrad]
	140235124309104 -> 140235124309008
	140236496431760 [label="blocks.0.0.bn2.weight
 (16)" fillcolor=lightblue]
	140236496431760 -> 140235124309104
	140235124309104 [label=AccumulateGrad]
	140235124309056 -> 140235124309008
	140236496431840 [label="blocks.0.0.bn2.bias
 (16)" fillcolor=lightblue]
	140236496431840 -> 140235124309056
	140235124309056 [label=AccumulateGrad]
	140235124308960 -> 140235124308720
	140236496432320 [label="blocks.1.0.conv_pw.weight
 (96, 16, 1, 1)" fillcolor=lightblue]
	140236496432320 -> 140235124308960
	140235124308960 [label=AccumulateGrad]
	140235124308576 -> 140235124308672
	140236496432400 [label="blocks.1.0.bn1.weight
 (96)" fillcolor=lightblue]
	140236496432400 -> 140235124308576
	140235124308576 [label=AccumulateGrad]
	140235124308816 -> 140235124308672
	140236496432480 [label="blocks.1.0.bn1.bias
 (96)" fillcolor=lightblue]
	140236496432480 -> 140235124308816
	140235124308816 [label=AccumulateGrad]
	140235124308480 -> 140235124308240
	140236496432960 [label="blocks.1.0.conv_dw.weight
 (96, 1, 3, 3)" fillcolor=lightblue]
	140236496432960 -> 140235124308480
	140235124308480 [label=AccumulateGrad]
	140235124308096 -> 140235124308192
	140236496432880 [label="blocks.1.0.bn2.weight
 (96)" fillcolor=lightblue]
	140236496432880 -> 140235124308096
	140235124308096 [label=AccumulateGrad]
	140235124308336 -> 140235124308192
	140236496433040 [label="blocks.1.0.bn2.bias
 (96)" fillcolor=lightblue]
	140236496433040 -> 140235124308336
	140235124308336 [label=AccumulateGrad]
	140235124308000 -> 140235124307904
	140235124308000 [label=SigmoidBackward0]
	140235124308432 -> 140235124308000
	140235124308432 [label=ConvolutionBackward0]
	140235124308864 -> 140235124308432
	140235124308864 [label=SiluBackward0]
	140235124309200 -> 140235124308864
	140235124309200 [label=ConvolutionBackward0]
	140235124309392 -> 140235124309200
	140235124309392 [label=MeanBackward1]
	140235124308048 -> 140235124309392
	140235124309824 -> 140235124309200
	140235395793280 [label="blocks.1.0.se.conv_reduce.weight
 (4, 96, 1, 1)" fillcolor=lightblue]
	140235395793280 -> 140235124309824
	140235124309824 [label=AccumulateGrad]
	140235124318320 -> 140235124309200
	140235395793360 [label="blocks.1.0.se.conv_reduce.bias
 (4)" fillcolor=lightblue]
	140235395793360 -> 140235124318320
	140235124318320 [label=AccumulateGrad]
	140235124308912 -> 140235124308432
	140235395793520 [label="blocks.1.0.se.conv_expand.weight
 (96, 4, 1, 1)" fillcolor=lightblue]
	140235395793520 -> 140235124308912
	140235124308912 [label=AccumulateGrad]
	140235124308144 -> 140235124308432
	140235395793600 [label="blocks.1.0.se.conv_expand.bias
 (96)" fillcolor=lightblue]
	140235395793600 -> 140235124308144
	140235124308144 [label=AccumulateGrad]
	140235124307856 -> 140235124307712
	140235395793760 [label="blocks.1.0.conv_pwl.weight
 (24, 96, 1, 1)" fillcolor=lightblue]
	140235395793760 -> 140235124307856
	140235124307856 [label=AccumulateGrad]
	140235124307664 -> 140235124306128
	140235395793840 [label="blocks.1.0.bn3.weight
 (24)" fillcolor=lightblue]
	140235395793840 -> 140235124307664
	140235124307664 [label=AccumulateGrad]
	140235124307520 -> 140235124306128
	140235395793920 [label="blocks.1.0.bn3.bias
 (24)" fillcolor=lightblue]
	140235395793920 -> 140235124307520
	140235124307520 [label=AccumulateGrad]
	140235124307616 -> 140235124307328
	140235395794400 [label="blocks.1.1.conv_pw.weight
 (144, 24, 1, 1)" fillcolor=lightblue]
	140235395794400 -> 140235124307616
	140235124307616 [label=AccumulateGrad]
	140235124307184 -> 140235124307280
	140235395794480 [label="blocks.1.1.bn1.weight
 (144)" fillcolor=lightblue]
	140235395794480 -> 140235124307184
	140235124307184 [label=AccumulateGrad]
	140235124307424 -> 140235124307280
	140235395794560 [label="blocks.1.1.bn1.bias
 (144)" fillcolor=lightblue]
	140235395794560 -> 140235124307424
	140235124307424 [label=AccumulateGrad]
	140235124307088 -> 140235124306848
	140235395795040 [label="blocks.1.1.conv_dw.weight
 (144, 1, 3, 3)" fillcolor=lightblue]
	140235395795040 -> 140235124307088
	140235124307088 [label=AccumulateGrad]
	140235124306704 -> 140235124306800
	140235395794960 [label="blocks.1.1.bn2.weight
 (144)" fillcolor=lightblue]
	140235395794960 -> 140235124306704
	140235124306704 [label=AccumulateGrad]
	140235124306944 -> 140235124306800
	140235395795120 [label="blocks.1.1.bn2.bias
 (144)" fillcolor=lightblue]
	140235395795120 -> 140235124306944
	140235124306944 [label=AccumulateGrad]
	140235124306608 -> 140235124306512
	140235124306608 [label=SigmoidBackward0]
	140235124307040 -> 140235124306608
	140235124307040 [label=ConvolutionBackward0]
	140235124307472 -> 140235124307040
	140235124307472 [label=SiluBackward0]
	140235124307808 -> 140235124307472
	140235124307808 [label=ConvolutionBackward0]
	140235124309248 -> 140235124307808
	140235124309248 [label=MeanBackward1]
	140235124306656 -> 140235124309248
	140235124307952 -> 140235124307808
	140235395795520 [label="blocks.1.1.se.conv_reduce.weight
 (6, 144, 1, 1)" fillcolor=lightblue]
	140235395795520 -> 140235124307952
	140235124307952 [label=AccumulateGrad]
	140235124308384 -> 140235124307808
	140235395795600 [label="blocks.1.1.se.conv_reduce.bias
 (6)" fillcolor=lightblue]
	140235395795600 -> 140235124308384
	140235124308384 [label=AccumulateGrad]
	140235124307568 -> 140235124307040
	140235395795760 [label="blocks.1.1.se.conv_expand.weight
 (144, 6, 1, 1)" fillcolor=lightblue]
	140235395795760 -> 140235124307568
	140235124307568 [label=AccumulateGrad]
	140235124306752 -> 140235124307040
	140235395795840 [label="blocks.1.1.se.conv_expand.bias
 (144)" fillcolor=lightblue]
	140235395795840 -> 140235124306752
	140235124306752 [label=AccumulateGrad]
	140235124306464 -> 140235124306320
	140235395796000 [label="blocks.1.1.conv_pwl.weight
 (24, 144, 1, 1)" fillcolor=lightblue]
	140235395796000 -> 140235124306464
	140235124306464 [label=AccumulateGrad]
	140235124306272 -> 140235124306176
	140235395796080 [label="blocks.1.1.bn3.weight
 (24)" fillcolor=lightblue]
	140235395796080 -> 140235124306272
	140235124306272 [label=AccumulateGrad]
	140235124306224 -> 140235124306176
	140235395796160 [label="blocks.1.1.bn3.bias
 (24)" fillcolor=lightblue]
	140235395796160 -> 140235124306224
	140235124306224 [label=AccumulateGrad]
	140235124306128 -> 140235124301776
	140235124306032 -> 140235124301584
	140235395796640 [label="blocks.2.0.conv_pw.weight
 (144, 24, 1, 1)" fillcolor=lightblue]
	140235395796640 -> 140235124306032
	140235124306032 [label=AccumulateGrad]
	140235124301440 -> 140235124301536
	140235395796720 [label="blocks.2.0.bn1.weight
 (144)" fillcolor=lightblue]
	140235395796720 -> 140235124301440
	140235124301440 [label=AccumulateGrad]
	140235124301680 -> 140235124301536
	140235395796800 [label="blocks.2.0.bn1.bias
 (144)" fillcolor=lightblue]
	140235395796800 -> 140235124301680
	140235124301680 [label=AccumulateGrad]
	140235124301344 -> 140235124301104
	140235395924352 [label="blocks.2.0.conv_dw.weight
 (144, 1, 5, 5)" fillcolor=lightblue]
	140235395924352 -> 140235124301344
	140235124301344 [label=AccumulateGrad]
	140235124300960 -> 140235124301056
	140235395924272 [label="blocks.2.0.bn2.weight
 (144)" fillcolor=lightblue]
	140235395924272 -> 140235124300960
	140235124300960 [label=AccumulateGrad]
	140235124301200 -> 140235124301056
	140235395924432 [label="blocks.2.0.bn2.bias
 (144)" fillcolor=lightblue]
	140235395924432 -> 140235124301200
	140235124301200 [label=AccumulateGrad]
	140235124300864 -> 140235124300768
	140235124300864 [label=SigmoidBackward0]
	140235124301296 -> 140235124300864
	140235124301296 [label=ConvolutionBackward0]
	140235124301488 -> 140235124301296
	140235124301488 [label=SiluBackward0]
	140235124306080 -> 140235124301488
	140235124306080 [label=ConvolutionBackward0]
	140235124306992 -> 140235124306080
	140235124306992 [label=MeanBackward1]
	140235124300912 -> 140235124306992
	140235124307232 -> 140235124306080
	140235395924832 [label="blocks.2.0.se.conv_reduce.weight
 (6, 144, 1, 1)" fillcolor=lightblue]
	140235395924832 -> 140235124307232
	140235124307232 [label=AccumulateGrad]
	140235124306416 -> 140235124306080
	140235395924912 [label="blocks.2.0.se.conv_reduce.bias
 (6)" fillcolor=lightblue]
	140235395924912 -> 140235124306416
	140235124306416 [label=AccumulateGrad]
	140235124301728 -> 140235124301296
	140235395925072 [label="blocks.2.0.se.conv_expand.weight
 (144, 6, 1, 1)" fillcolor=lightblue]
	140235395925072 -> 140235124301728
	140235124301728 [label=AccumulateGrad]
	140235124301008 -> 140235124301296
	140235395925152 [label="blocks.2.0.se.conv_expand.bias
 (144)" fillcolor=lightblue]
	140235395925152 -> 140235124301008
	140235124301008 [label=AccumulateGrad]
	140235124300720 -> 140235124300576
	140235395925312 [label="blocks.2.0.conv_pwl.weight
 (40, 144, 1, 1)" fillcolor=lightblue]
	140235395925312 -> 140235124300720
	140235124300720 [label=AccumulateGrad]
	140235124300528 -> 140235124298992
	140235395925392 [label="blocks.2.0.bn3.weight
 (40)" fillcolor=lightblue]
	140235395925392 -> 140235124300528
	140235124300528 [label=AccumulateGrad]
	140235124300384 -> 140235124298992
	140235395925472 [label="blocks.2.0.bn3.bias
 (40)" fillcolor=lightblue]
	140235395925472 -> 140235124300384
	140235124300384 [label=AccumulateGrad]
	140235124300480 -> 140235124300192
	140235395925952 [label="blocks.2.1.conv_pw.weight
 (240, 40, 1, 1)" fillcolor=lightblue]
	140235395925952 -> 140235124300480
	140235124300480 [label=AccumulateGrad]
	140235124300048 -> 140235124300144
	140235395926032 [label="blocks.2.1.bn1.weight
 (240)" fillcolor=lightblue]
	140235395926032 -> 140235124300048
	140235124300048 [label=AccumulateGrad]
	140235124300288 -> 140235124300144
	140235395926112 [label="blocks.2.1.bn1.bias
 (240)" fillcolor=lightblue]
	140235395926112 -> 140235124300288
	140235124300288 [label=AccumulateGrad]
	140235124299952 -> 140235124299712
	140235395926592 [label="blocks.2.1.conv_dw.weight
 (240, 1, 5, 5)" fillcolor=lightblue]
	140235395926592 -> 140235124299952
	140235124299952 [label=AccumulateGrad]
	140235124299568 -> 140235124299664
	140235395926512 [label="blocks.2.1.bn2.weight
 (240)" fillcolor=lightblue]
	140235395926512 -> 140235124299568
	140235124299568 [label=AccumulateGrad]
	140235124299808 -> 140235124299664
	140235395926672 [label="blocks.2.1.bn2.bias
 (240)" fillcolor=lightblue]
	140235395926672 -> 140235124299808
	140235124299808 [label=AccumulateGrad]
	140235124299472 -> 140235124299376
	140235124299472 [label=SigmoidBackward0]
	140235124299904 -> 140235124299472
	140235124299904 [label=ConvolutionBackward0]
	140235124300336 -> 140235124299904
	140235124300336 [label=SiluBackward0]
	140235124300624 -> 140235124300336
	140235124300624 [label=ConvolutionBackward0]
	140235124300816 -> 140235124300624
	140235124300816 [label=MeanBackward1]
	140235124299520 -> 140235124300816
	140235124301248 -> 140235124300624
	140235395927072 [label="blocks.2.1.se.conv_reduce.weight
 (10, 240, 1, 1)" fillcolor=lightblue]
	140235395927072 -> 140235124301248
	140235124301248 [label=AccumulateGrad]
	140235124305984 -> 140235124300624
	140235395927152 [label="blocks.2.1.se.conv_reduce.bias
 (10)" fillcolor=lightblue]
	140235395927152 -> 140235124305984
	140235124305984 [label=AccumulateGrad]
	140235124300432 -> 140235124299904
	140235395927312 [label="blocks.2.1.se.conv_expand.weight
 (240, 10, 1, 1)" fillcolor=lightblue]
	140235395927312 -> 140235124300432
	140235124300432 [label=AccumulateGrad]
	140235124299616 -> 140235124299904
	140235395927392 [label="blocks.2.1.se.conv_expand.bias
 (240)" fillcolor=lightblue]
	140235395927392 -> 140235124299616
	140235124299616 [label=AccumulateGrad]
	140235124299328 -> 140235124299184
	140235395927552 [label="blocks.2.1.conv_pwl.weight
 (40, 240, 1, 1)" fillcolor=lightblue]
	140235395927552 -> 140235124299328
	140235124299328 [label=AccumulateGrad]
	140235124299136 -> 140235124299040
	140235395927632 [label="blocks.2.1.bn3.weight
 (40)" fillcolor=lightblue]
	140235395927632 -> 140235124299136
	140235124299136 [label=AccumulateGrad]
	140235124299088 -> 140235124299040
	140235395927712 [label="blocks.2.1.bn3.bias
 (40)" fillcolor=lightblue]
	140235395927712 -> 140235124299088
	140235124299088 [label=AccumulateGrad]
	140235124298992 -> 140235124298896
	140235124298848 -> 140235124298608
	140236187209952 [label="blocks.3.0.conv_pw.weight
 (240, 40, 1, 1)" fillcolor=lightblue]
	140236187209952 -> 140235124298848
	140235124298848 [label=AccumulateGrad]
	140235124298464 -> 140235124298560
	140236187210032 [label="blocks.3.0.bn1.weight
 (240)" fillcolor=lightblue]
	140236187210032 -> 140235124298464
	140235124298464 [label=AccumulateGrad]
	140235124298704 -> 140235124298560
	140236187210112 [label="blocks.3.0.bn1.bias
 (240)" fillcolor=lightblue]
	140236187210112 -> 140235124298704
	140235124298704 [label=AccumulateGrad]
	140235124298368 -> 140235124298128
	140236187210592 [label="blocks.3.0.conv_dw.weight
 (240, 1, 3, 3)" fillcolor=lightblue]
	140236187210592 -> 140235124298368
	140235124298368 [label=AccumulateGrad]
	140235124297984 -> 140235124298080
	140236187210512 [label="blocks.3.0.bn2.weight
 (240)" fillcolor=lightblue]
	140236187210512 -> 140235124297984
	140235124297984 [label=AccumulateGrad]
	140235124298224 -> 140235124298080
	140236187210672 [label="blocks.3.0.bn2.bias
 (240)" fillcolor=lightblue]
	140236187210672 -> 140235124298224
	140235124298224 [label=AccumulateGrad]
	140235124297888 -> 140235124187088
	140235124297888 [label=SigmoidBackward0]
	140235124298320 -> 140235124297888
	140235124298320 [label=ConvolutionBackward0]
	140235124298752 -> 140235124298320
	140235124298752 [label=SiluBackward0]
	140235124298944 -> 140235124298752
	140235124298944 [label=ConvolutionBackward0]
	140235124299856 -> 140235124298944
	140235124299856 [label=MeanBackward1]
	140235124297936 -> 140235124299856
	140235124300096 -> 140235124298944
	140236187211072 [label="blocks.3.0.se.conv_reduce.weight
 (10, 240, 1, 1)" fillcolor=lightblue]
	140236187211072 -> 140235124300096
	140235124300096 [label=AccumulateGrad]
	140235124299280 -> 140235124298944
	140236187211152 [label="blocks.3.0.se.conv_reduce.bias
 (10)" fillcolor=lightblue]
	140236187211152 -> 140235124299280
	140235124299280 [label=AccumulateGrad]
	140235124298800 -> 140235124298320
	140236187211312 [label="blocks.3.0.se.conv_expand.weight
 (240, 10, 1, 1)" fillcolor=lightblue]
	140236187211312 -> 140235124298800
	140235124298800 [label=AccumulateGrad]
	140235124298032 -> 140235124298320
	140236187211392 [label="blocks.3.0.se.conv_expand.bias
 (240)" fillcolor=lightblue]
	140236187211392 -> 140235124298032
	140235124298032 [label=AccumulateGrad]
	140235124187040 -> 140235124186944
	140236187211552 [label="blocks.3.0.conv_pwl.weight
 (80, 240, 1, 1)" fillcolor=lightblue]
	140236187211552 -> 140235124187040
	140235124187040 [label=AccumulateGrad]
	140235124186896 -> 140235124185360
	140236187211632 [label="blocks.3.0.bn3.weight
 (80)" fillcolor=lightblue]
	140236187211632 -> 140235124186896
	140235124186896 [label=AccumulateGrad]
	140235124186752 -> 140235124185360
	140236187211712 [label="blocks.3.0.bn3.bias
 (80)" fillcolor=lightblue]
	140236187211712 -> 140235124186752
	140235124186752 [label=AccumulateGrad]
	140235124186848 -> 140235124186560
	140236187212192 [label="blocks.3.1.conv_pw.weight
 (480, 80, 1, 1)" fillcolor=lightblue]
	140236187212192 -> 140235124186848
	140235124186848 [label=AccumulateGrad]
	140235124186416 -> 140235124186512
	140236187212272 [label="blocks.3.1.bn1.weight
 (480)" fillcolor=lightblue]
	140236187212272 -> 140235124186416
	140235124186416 [label=AccumulateGrad]
	140235124186656 -> 140235124186512
	140236187212352 [label="blocks.3.1.bn1.bias
 (480)" fillcolor=lightblue]
	140236187212352 -> 140235124186656
	140235124186656 [label=AccumulateGrad]
	140235124186320 -> 140235124186080
	140236187212832 [label="blocks.3.1.conv_dw.weight
 (480, 1, 3, 3)" fillcolor=lightblue]
	140236187212832 -> 140235124186320
	140235124186320 [label=AccumulateGrad]
	140235124185936 -> 140235124186032
	140236187212752 [label="blocks.3.1.bn2.weight
 (480)" fillcolor=lightblue]
	140236187212752 -> 140235124185936
	140235124185936 [label=AccumulateGrad]
	140235124186176 -> 140235124186032
	140236187212912 [label="blocks.3.1.bn2.bias
 (480)" fillcolor=lightblue]
	140236187212912 -> 140235124186176
	140235124186176 [label=AccumulateGrad]
	140235124185840 -> 140235124185744
	140235124185840 [label=SigmoidBackward0]
	140235124186272 -> 140235124185840
	140235124186272 [label=ConvolutionBackward0]
	140235124186704 -> 140235124186272
	140235124186704 [label=SiluBackward0]
	140235124186992 -> 140235124186704
	140235124186992 [label=ConvolutionBackward0]
	140235124297840 -> 140235124186992
	140235124297840 [label=MeanBackward1]
	140235124185888 -> 140235124297840
	140235124298272 -> 140235124186992
	140236187213312 [label="blocks.3.1.se.conv_reduce.weight
 (20, 480, 1, 1)" fillcolor=lightblue]
	140236187213312 -> 140235124298272
	140235124298272 [label=AccumulateGrad]
	140235124298512 -> 140235124186992
	140236187213392 [label="blocks.3.1.se.conv_reduce.bias
 (20)" fillcolor=lightblue]
	140236187213392 -> 140235124298512
	140235124298512 [label=AccumulateGrad]
	140235124186800 -> 140235124186272
	140236187213552 [label="blocks.3.1.se.conv_expand.weight
 (480, 20, 1, 1)" fillcolor=lightblue]
	140236187213552 -> 140235124186800
	140235124186800 [label=AccumulateGrad]
	140235124185984 -> 140235124186272
	140236187213632 [label="blocks.3.1.se.conv_expand.bias
 (480)" fillcolor=lightblue]
	140236187213632 -> 140235124185984
	140235124185984 [label=AccumulateGrad]
	140235124185696 -> 140235124185552
	140236187332672 [label="blocks.3.1.conv_pwl.weight
 (80, 480, 1, 1)" fillcolor=lightblue]
	140236187332672 -> 140235124185696
	140235124185696 [label=AccumulateGrad]
	140235124185504 -> 140235124185408
	140236187332752 [label="blocks.3.1.bn3.weight
 (80)" fillcolor=lightblue]
	140236187332752 -> 140235124185504
	140235124185504 [label=AccumulateGrad]
	140235124185456 -> 140235124185408
	140236187332832 [label="blocks.3.1.bn3.bias
 (80)" fillcolor=lightblue]
	140236187332832 -> 140235124185456
	140235124185456 [label=AccumulateGrad]
	140235124185360 -> 140235124183824
	140235124185312 -> 140235124185024
	140236187333312 [label="blocks.3.2.conv_pw.weight
 (480, 80, 1, 1)" fillcolor=lightblue]
	140236187333312 -> 140235124185312
	140235124185312 [label=AccumulateGrad]
	140235124184880 -> 140235124184976
	140236187333392 [label="blocks.3.2.bn1.weight
 (480)" fillcolor=lightblue]
	140236187333392 -> 140235124184880
	140235124184880 [label=AccumulateGrad]
	140235124185120 -> 140235124184976
	140236187333472 [label="blocks.3.2.bn1.bias
 (480)" fillcolor=lightblue]
	140236187333472 -> 140235124185120
	140235124185120 [label=AccumulateGrad]
	140235124184784 -> 140235124184544
	140236187333952 [label="blocks.3.2.conv_dw.weight
 (480, 1, 3, 3)" fillcolor=lightblue]
	140236187333952 -> 140235124184784
	140235124184784 [label=AccumulateGrad]
	140235124184400 -> 140235124184496
	140236187333872 [label="blocks.3.2.bn2.weight
 (480)" fillcolor=lightblue]
	140236187333872 -> 140235124184400
	140235124184400 [label=AccumulateGrad]
	140235124184640 -> 140235124184496
	140236187334032 [label="blocks.3.2.bn2.bias
 (480)" fillcolor=lightblue]
	140236187334032 -> 140235124184640
	140235124184640 [label=AccumulateGrad]
	140235124184304 -> 140235124184208
	140235124184304 [label=SigmoidBackward0]
	140235124184736 -> 140235124184304
	140235124184736 [label=ConvolutionBackward0]
	140235124185168 -> 140235124184736
	140235124185168 [label=SiluBackward0]
	140235124185216 -> 140235124185168
	140235124185216 [label=ConvolutionBackward0]
	140235124186224 -> 140235124185216
	140235124186224 [label=MeanBackward1]
	140235124184352 -> 140235124186224
	140235124186464 -> 140235124185216
	140236187334432 [label="blocks.3.2.se.conv_reduce.weight
 (20, 480, 1, 1)" fillcolor=lightblue]
	140236187334432 -> 140235124186464
	140235124186464 [label=AccumulateGrad]
	140235124185648 -> 140235124185216
	140236187334512 [label="blocks.3.2.se.conv_reduce.bias
 (20)" fillcolor=lightblue]
	140236187334512 -> 140235124185648
	140235124185648 [label=AccumulateGrad]
	140235124185264 -> 140235124184736
	140236187334672 [label="blocks.3.2.se.conv_expand.weight
 (480, 20, 1, 1)" fillcolor=lightblue]
	140236187334672 -> 140235124185264
	140235124185264 [label=AccumulateGrad]
	140235124184448 -> 140235124184736
	140236187334752 [label="blocks.3.2.se.conv_expand.bias
 (480)" fillcolor=lightblue]
	140236187334752 -> 140235124184448
	140235124184448 [label=AccumulateGrad]
	140235124184160 -> 140235124184016
	140236187334912 [label="blocks.3.2.conv_pwl.weight
 (80, 480, 1, 1)" fillcolor=lightblue]
	140236187334912 -> 140235124184160
	140235124184160 [label=AccumulateGrad]
	140235124183968 -> 140235124183872
	140236187334992 [label="blocks.3.2.bn3.weight
 (80)" fillcolor=lightblue]
	140236187334992 -> 140235124183968
	140235124183968 [label=AccumulateGrad]
	140235124183920 -> 140235124183872
	140236187335072 [label="blocks.3.2.bn3.bias
 (80)" fillcolor=lightblue]
	140236187335072 -> 140235124183920
	140235124183920 [label=AccumulateGrad]
	140235124183824 -> 140235124183728
	140235124183680 -> 140235124183440
	140236187335552 [label="blocks.4.0.conv_pw.weight
 (480, 80, 1, 1)" fillcolor=lightblue]
	140236187335552 -> 140235124183680
	140235124183680 [label=AccumulateGrad]
	140235124183296 -> 140235124183392
	140236187335632 [label="blocks.4.0.bn1.weight
 (480)" fillcolor=lightblue]
	140236187335632 -> 140235124183296
	140235124183296 [label=AccumulateGrad]
	140235124183536 -> 140235124183392
	140236187335712 [label="blocks.4.0.bn1.bias
 (480)" fillcolor=lightblue]
	140236187335712 -> 140235124183536
	140235124183536 [label=AccumulateGrad]
	140235124183200 -> 140235124170608
	140236187336192 [label="blocks.4.0.conv_dw.weight
 (480, 1, 5, 5)" fillcolor=lightblue]
	140236187336192 -> 140235124183200
	140235124183200 [label=AccumulateGrad]
	140235124170464 -> 140235124170560
	140236187336112 [label="blocks.4.0.bn2.weight
 (480)" fillcolor=lightblue]
	140236187336112 -> 140235124170464
	140235124170464 [label=AccumulateGrad]
	140235124170704 -> 140235124170560
	140236187336272 [label="blocks.4.0.bn2.bias
 (480)" fillcolor=lightblue]
	140236187336272 -> 140235124170704
	140235124170704 [label=AccumulateGrad]
	140235124170368 -> 140235124170272
	140235124170368 [label=SigmoidBackward0]
	140235124170512 -> 140235124170368
	140235124170512 [label=ConvolutionBackward0]
	140235124183584 -> 140235124170512
	140235124183584 [label=SiluBackward0]
	140235124183776 -> 140235124183584
	140235124183776 [label=ConvolutionBackward0]
	140235124184688 -> 140235124183776
	140235124184688 [label=MeanBackward1]
	140235124170416 -> 140235124184688
	140235124184928 -> 140235124183776
	140236188147776 [label="blocks.4.0.se.conv_reduce.weight
 (20, 480, 1, 1)" fillcolor=lightblue]
	140236188147776 -> 140235124184928
	140235124184928 [label=AccumulateGrad]
	140235124184112 -> 140235124183776
	140236188147856 [label="blocks.4.0.se.conv_reduce.bias
 (20)" fillcolor=lightblue]
	140236188147856 -> 140235124184112
	140235124184112 [label=AccumulateGrad]
	140235124183632 -> 140235124170512
	140236188148016 [label="blocks.4.0.se.conv_expand.weight
 (480, 20, 1, 1)" fillcolor=lightblue]
	140236188148016 -> 140235124183632
	140235124183632 [label=AccumulateGrad]
	140235124183104 -> 140235124170512
	140236188148096 [label="blocks.4.0.se.conv_expand.bias
 (480)" fillcolor=lightblue]
	140236188148096 -> 140235124183104
	140235124183104 [label=AccumulateGrad]
	140235124170224 -> 140235124170080
	140236188148256 [label="blocks.4.0.conv_pwl.weight
 (112, 480, 1, 1)" fillcolor=lightblue]
	140236188148256 -> 140235124170224
	140235124170224 [label=AccumulateGrad]
	140235124170032 -> 140235124168592
	140236188148336 [label="blocks.4.0.bn3.weight
 (112)" fillcolor=lightblue]
	140236188148336 -> 140235124170032
	140235124170032 [label=AccumulateGrad]
	140235124169888 -> 140235124168592
	140236188148416 [label="blocks.4.0.bn3.bias
 (112)" fillcolor=lightblue]
	140236188148416 -> 140235124169888
	140235124169888 [label=AccumulateGrad]
	140235124169984 -> 140235124169792
	140236188148896 [label="blocks.4.1.conv_pw.weight
 (672, 112, 1, 1)" fillcolor=lightblue]
	140236188148896 -> 140235124169984
	140235124169984 [label=AccumulateGrad]
	140235124169744 -> 140235124169696
	140236188148976 [label="blocks.4.1.bn1.weight
 (672)" fillcolor=lightblue]
	140236188148976 -> 140235124169744
	140235124169744 [label=AccumulateGrad]
	140235124169600 -> 140235124169696
	140236188149056 [label="blocks.4.1.bn1.bias
 (672)" fillcolor=lightblue]
	140236188149056 -> 140235124169600
	140235124169600 [label=AccumulateGrad]
	140235124169504 -> 140235124169360
	140236188149536 [label="blocks.4.1.conv_dw.weight
 (672, 1, 5, 5)" fillcolor=lightblue]
	140236188149536 -> 140235124169504
	140235124169504 [label=AccumulateGrad]
	140235124169312 -> 140235124169264
	140236188149456 [label="blocks.4.1.bn2.weight
 (672)" fillcolor=lightblue]
	140236188149456 -> 140235124169312
	140235124169312 [label=AccumulateGrad]
	140235124169168 -> 140235124169264
	140236188149616 [label="blocks.4.1.bn2.bias
 (672)" fillcolor=lightblue]
	140236188149616 -> 140235124169168
	140235124169168 [label=AccumulateGrad]
	140235124169072 -> 140235124168976
	140235124169072 [label=SigmoidBackward0]
	140235124169456 -> 140235124169072
	140235124169456 [label=ConvolutionBackward0]
	140235124169840 -> 140235124169456
	140235124169840 [label=SiluBackward0]
	140235124170128 -> 140235124169840
	140235124170128 [label=ConvolutionBackward0]
	140235124170320 -> 140235124170128
	140235124170320 [label=MeanBackward1]
	140235124169120 -> 140235124170320
	140235124183152 -> 140235124170128
	140236188150016 [label="blocks.4.1.se.conv_reduce.weight
 (28, 672, 1, 1)" fillcolor=lightblue]
	140236188150016 -> 140235124183152
	140235124183152 [label=AccumulateGrad]
	140235124183344 -> 140235124170128
	140236188150096 [label="blocks.4.1.se.conv_reduce.bias
 (28)" fillcolor=lightblue]
	140236188150096 -> 140235124183344
	140235124183344 [label=AccumulateGrad]
	140235124169936 -> 140235124169456
	140236188150256 [label="blocks.4.1.se.conv_expand.weight
 (672, 28, 1, 1)" fillcolor=lightblue]
	140236188150256 -> 140235124169936
	140235124169936 [label=AccumulateGrad]
	140235124169216 -> 140235124169456
	140236188150336 [label="blocks.4.1.se.conv_expand.bias
 (672)" fillcolor=lightblue]
	140236188150336 -> 140235124169216
	140235124169216 [label=AccumulateGrad]
	140235124168928 -> 140235124168784
	140236188150496 [label="blocks.4.1.conv_pwl.weight
 (112, 672, 1, 1)" fillcolor=lightblue]
	140236188150496 -> 140235124168928
	140235124168928 [label=AccumulateGrad]
	140235124168736 -> 140235124168640
	140236188150576 [label="blocks.4.1.bn3.weight
 (112)" fillcolor=lightblue]
	140236188150576 -> 140235124168736
	140235124168736 [label=AccumulateGrad]
	140235124168688 -> 140235124168640
	140236188150656 [label="blocks.4.1.bn3.bias
 (112)" fillcolor=lightblue]
	140236188150656 -> 140235124168688
	140235124168688 [label=AccumulateGrad]
	140235124168592 -> 140235124167152
	140235124168544 -> 140235124168352
	140236188151136 [label="blocks.4.2.conv_pw.weight
 (672, 112, 1, 1)" fillcolor=lightblue]
	140236188151136 -> 140235124168544
	140235124168544 [label=AccumulateGrad]
	140235124168304 -> 140235124168256
	140236188151216 [label="blocks.4.2.bn1.weight
 (672)" fillcolor=lightblue]
	140236188151216 -> 140235124168304
	140235124168304 [label=AccumulateGrad]
	140235124168160 -> 140235124168256
	140236188151296 [label="blocks.4.2.bn1.bias
 (672)" fillcolor=lightblue]
	140236188151296 -> 140235124168160
	140235124168160 [label=AccumulateGrad]
	140235124168064 -> 140235124167920
	140236188274752 [label="blocks.4.2.conv_dw.weight
 (672, 1, 5, 5)" fillcolor=lightblue]
	140236188274752 -> 140235124168064
	140235124168064 [label=AccumulateGrad]
	140235124167872 -> 140235124167824
	140236188151696 [label="blocks.4.2.bn2.weight
 (672)" fillcolor=lightblue]
	140236188151696 -> 140235124167872
	140235124167872 [label=AccumulateGrad]
	140235124167728 -> 140235124167824
	140236188274832 [label="blocks.4.2.bn2.bias
 (672)" fillcolor=lightblue]
	140236188274832 -> 140235124167728
	140235124167728 [label=AccumulateGrad]
	140235124167632 -> 140235124167536
	140235124167632 [label=SigmoidBackward0]
	140235124168016 -> 140235124167632
	140235124168016 [label=ConvolutionBackward0]
	140235124168400 -> 140235124168016
	140235124168400 [label=SiluBackward0]
	140235124168448 -> 140235124168400
	140235124168448 [label=ConvolutionBackward0]
	140235124169408 -> 140235124168448
	140235124169408 [label=MeanBackward1]
	140235124167680 -> 140235124169408
	140235124169648 -> 140235124168448
	140236188275232 [label="blocks.4.2.se.conv_reduce.weight
 (28, 672, 1, 1)" fillcolor=lightblue]
	140236188275232 -> 140235124169648
	140235124169648 [label=AccumulateGrad]
	140235124168880 -> 140235124168448
	140236188275312 [label="blocks.4.2.se.conv_reduce.bias
 (28)" fillcolor=lightblue]
	140236188275312 -> 140235124168880
	140235124168880 [label=AccumulateGrad]
	140235124168496 -> 140235124168016
	140236188275472 [label="blocks.4.2.se.conv_expand.weight
 (672, 28, 1, 1)" fillcolor=lightblue]
	140236188275472 -> 140235124168496
	140235124168496 [label=AccumulateGrad]
	140235124167776 -> 140235124168016
	140236188275552 [label="blocks.4.2.se.conv_expand.bias
 (672)" fillcolor=lightblue]
	140236188275552 -> 140235124167776
	140235124167776 [label=AccumulateGrad]
	140235124167488 -> 140235124167344
	140236188275712 [label="blocks.4.2.conv_pwl.weight
 (112, 672, 1, 1)" fillcolor=lightblue]
	140236188275712 -> 140235124167488
	140235124167488 [label=AccumulateGrad]
	140235124167296 -> 140235124167200
	140236188275792 [label="blocks.4.2.bn3.weight
 (112)" fillcolor=lightblue]
	140236188275792 -> 140235124167296
	140235124167296 [label=AccumulateGrad]
	140235124167248 -> 140235124167200
	140236188275872 [label="blocks.4.2.bn3.bias
 (112)" fillcolor=lightblue]
	140236188275872 -> 140235124167248
	140235124167248 [label=AccumulateGrad]
	140235124167152 -> 140235124167056
	140235124167008 -> 140235124166864
	140236188276352 [label="blocks.5.0.conv_pw.weight
 (672, 112, 1, 1)" fillcolor=lightblue]
	140236188276352 -> 140235124167008
	140235124167008 [label=AccumulateGrad]
	140235124166816 -> 140235124195280
	140236188276432 [label="blocks.5.0.bn1.weight
 (672)" fillcolor=lightblue]
	140236188276432 -> 140235124166816
	140235124166816 [label=AccumulateGrad]
	140235124166720 -> 140235124195280
	140236188276512 [label="blocks.5.0.bn1.bias
 (672)" fillcolor=lightblue]
	140236188276512 -> 140235124166720
	140235124166720 [label=AccumulateGrad]
	140235124195184 -> 140235124195040
	140236188276992 [label="blocks.5.0.conv_dw.weight
 (672, 1, 5, 5)" fillcolor=lightblue]
	140236188276992 -> 140235124195184
	140235124195184 [label=AccumulateGrad]
	140235124194992 -> 140235124194944
	140236188276912 [label="blocks.5.0.bn2.weight
 (672)" fillcolor=lightblue]
	140236188276912 -> 140235124194992
	140235124194992 [label=AccumulateGrad]
	140235124194848 -> 140235124194944
	140236188277072 [label="blocks.5.0.bn2.bias
 (672)" fillcolor=lightblue]
	140236188277072 -> 140235124194848
	140235124194848 [label=AccumulateGrad]
	140235124194752 -> 140235124194656
	140235124194752 [label=SigmoidBackward0]
	140235124195136 -> 140235124194752
	140235124195136 [label=ConvolutionBackward0]
	140235124194896 -> 140235124195136
	140235124194896 [label=SiluBackward0]
	140235124167104 -> 140235124194896
	140235124167104 [label=ConvolutionBackward0]
	140235124168208 -> 140235124167104
	140235124168208 [label=MeanBackward1]
	140235124194800 -> 140235124168208
	140235124168832 -> 140235124167104
	140236188277472 [label="blocks.5.0.se.conv_reduce.weight
 (28, 672, 1, 1)" fillcolor=lightblue]
	140236188277472 -> 140235124168832
	140235124168832 [label=AccumulateGrad]
	140235124167440 -> 140235124167104
	140236188277552 [label="blocks.5.0.se.conv_reduce.bias
 (28)" fillcolor=lightblue]
	140236188277552 -> 140235124167440
	140235124167440 [label=AccumulateGrad]
	140235124166912 -> 140235124195136
	140236188277712 [label="blocks.5.0.se.conv_expand.weight
 (672, 28, 1, 1)" fillcolor=lightblue]
	140236188277712 -> 140235124166912
	140235124166912 [label=AccumulateGrad]
	140235124166960 -> 140235124195136
	140236188277792 [label="blocks.5.0.se.conv_expand.bias
 (672)" fillcolor=lightblue]
	140236188277792 -> 140235124166960
	140235124166960 [label=AccumulateGrad]
	140235124194608 -> 140235124194464
	140236188277952 [label="blocks.5.0.conv_pwl.weight
 (192, 672, 1, 1)" fillcolor=lightblue]
	140236188277952 -> 140235124194608
	140235124194608 [label=AccumulateGrad]
	140235124194416 -> 140235124192976
	140236188278032 [label="blocks.5.0.bn3.weight
 (192)" fillcolor=lightblue]
	140236188278032 -> 140235124194416
	140235124194416 [label=AccumulateGrad]
	140235124194272 -> 140235124192976
	140236188278112 [label="blocks.5.0.bn3.bias
 (192)" fillcolor=lightblue]
	140236188278112 -> 140235124194272
	140235124194272 [label=AccumulateGrad]
	140235124194368 -> 140235124194176
	140236188278592 [label="blocks.5.1.conv_pw.weight
 (1152, 192, 1, 1)" fillcolor=lightblue]
	140236188278592 -> 140235124194368
	140235124194368 [label=AccumulateGrad]
	140235124194128 -> 140235124194080
	140236188278672 [label="blocks.5.1.bn1.weight
 (1152)" fillcolor=lightblue]
	140236188278672 -> 140235124194128
	140235124194128 [label=AccumulateGrad]
	140235124193984 -> 140235124194080
	140236191187008 [label="blocks.5.1.bn1.bias
 (1152)" fillcolor=lightblue]
	140236191187008 -> 140235124193984
	140235124193984 [label=AccumulateGrad]
	140235124193888 -> 140235124193744
	140236191187488 [label="blocks.5.1.conv_dw.weight
 (1152, 1, 5, 5)" fillcolor=lightblue]
	140236191187488 -> 140235124193888
	140235124193888 [label=AccumulateGrad]
	140235124193696 -> 140235124193648
	140236191187408 [label="blocks.5.1.bn2.weight
 (1152)" fillcolor=lightblue]
	140236191187408 -> 140235124193696
	140235124193696 [label=AccumulateGrad]
	140235124193552 -> 140235124193648
	140236191187568 [label="blocks.5.1.bn2.bias
 (1152)" fillcolor=lightblue]
	140236191187568 -> 140235124193552
	140235124193552 [label=AccumulateGrad]
	140235124193456 -> 140235124193360
	140235124193456 [label=SigmoidBackward0]
	140235124193840 -> 140235124193456
	140235124193840 [label=ConvolutionBackward0]
	140235124194224 -> 140235124193840
	140235124194224 [label=SiluBackward0]
	140235124194512 -> 140235124194224
	140235124194512 [label=ConvolutionBackward0]
	140235124194704 -> 140235124194512
	140235124194704 [label=MeanBackward1]
	140235124193504 -> 140235124194704
	140235124195088 -> 140235124194512
	140236191187968 [label="blocks.5.1.se.conv_reduce.weight
 (48, 1152, 1, 1)" fillcolor=lightblue]
	140236191187968 -> 140235124195088
	140235124195088 [label=AccumulateGrad]
	140235124166768 -> 140235124194512
	140236191188048 [label="blocks.5.1.se.conv_reduce.bias
 (48)" fillcolor=lightblue]
	140236191188048 -> 140235124166768
	140235124166768 [label=AccumulateGrad]
	140235124194320 -> 140235124193840
	140236191188208 [label="blocks.5.1.se.conv_expand.weight
 (1152, 48, 1, 1)" fillcolor=lightblue]
	140236191188208 -> 140235124194320
	140235124194320 [label=AccumulateGrad]
	140235124193600 -> 140235124193840
	140236191188288 [label="blocks.5.1.se.conv_expand.bias
 (1152)" fillcolor=lightblue]
	140236191188288 -> 140235124193600
	140235124193600 [label=AccumulateGrad]
	140235124193312 -> 140235124193168
	140236191188448 [label="blocks.5.1.conv_pwl.weight
 (192, 1152, 1, 1)" fillcolor=lightblue]
	140236191188448 -> 140235124193312
	140235124193312 [label=AccumulateGrad]
	140235124193120 -> 140235124193024
	140236191188528 [label="blocks.5.1.bn3.weight
 (192)" fillcolor=lightblue]
	140236191188528 -> 140235124193120
	140235124193120 [label=AccumulateGrad]
	140235124193072 -> 140235124193024
	140236191188608 [label="blocks.5.1.bn3.bias
 (192)" fillcolor=lightblue]
	140236191188608 -> 140235124193072
	140235124193072 [label=AccumulateGrad]
	140235124192976 -> 140235124191536
	140235124192928 -> 140235124192736
	140236191189088 [label="blocks.5.2.conv_pw.weight
 (1152, 192, 1, 1)" fillcolor=lightblue]
	140236191189088 -> 140235124192928
	140235124192928 [label=AccumulateGrad]
	140235124192688 -> 140235124192640
	140236191189168 [label="blocks.5.2.bn1.weight
 (1152)" fillcolor=lightblue]
	140236191189168 -> 140235124192688
	140235124192688 [label=AccumulateGrad]
	140235124192544 -> 140235124192640
	140236191189248 [label="blocks.5.2.bn1.bias
 (1152)" fillcolor=lightblue]
	140236191189248 -> 140235124192544
	140235124192544 [label=AccumulateGrad]
	140235124192448 -> 140235124192304
	140236191189728 [label="blocks.5.2.conv_dw.weight
 (1152, 1, 5, 5)" fillcolor=lightblue]
	140236191189728 -> 140235124192448
	140235124192448 [label=AccumulateGrad]
	140235124192256 -> 140235124192208
	140236191189648 [label="blocks.5.2.bn2.weight
 (1152)" fillcolor=lightblue]
	140236191189648 -> 140235124192256
	140235124192256 [label=AccumulateGrad]
	140235124192112 -> 140235124192208
	140236191189808 [label="blocks.5.2.bn2.bias
 (1152)" fillcolor=lightblue]
	140236191189808 -> 140235124192112
	140235124192112 [label=AccumulateGrad]
	140235124192016 -> 140235124191920
	140235124192016 [label=SigmoidBackward0]
	140235124192400 -> 140235124192016
	140235124192400 [label=ConvolutionBackward0]
	140235124192784 -> 140235124192400
	140235124192784 [label=SiluBackward0]
	140235124192832 -> 140235124192784
	140235124192832 [label=ConvolutionBackward0]
	140235124193792 -> 140235124192832
	140235124193792 [label=MeanBackward1]
	140235124192064 -> 140235124193792
	140235124194032 -> 140235124192832
	140236191190208 [label="blocks.5.2.se.conv_reduce.weight
 (48, 1152, 1, 1)" fillcolor=lightblue]
	140236191190208 -> 140235124194032
	140235124194032 [label=AccumulateGrad]
	140235124193264 -> 140235124192832
	140236191190288 [label="blocks.5.2.se.conv_reduce.bias
 (48)" fillcolor=lightblue]
	140236191190288 -> 140235124193264
	140235124193264 [label=AccumulateGrad]
	140235124192880 -> 140235124192400
	140236191190448 [label="blocks.5.2.se.conv_expand.weight
 (1152, 48, 1, 1)" fillcolor=lightblue]
	140236191190448 -> 140235124192880
	140235124192880 [label=AccumulateGrad]
	140235124192160 -> 140235124192400
	140236191190528 [label="blocks.5.2.se.conv_expand.bias
 (1152)" fillcolor=lightblue]
	140236191190528 -> 140235124192160
	140235124192160 [label=AccumulateGrad]
	140235124191872 -> 140235124191728
	140236191190688 [label="blocks.5.2.conv_pwl.weight
 (192, 1152, 1, 1)" fillcolor=lightblue]
	140236191190688 -> 140235124191872
	140235124191872 [label=AccumulateGrad]
	140235124191680 -> 140235124191584
	140236191190768 [label="blocks.5.2.bn3.weight
 (192)" fillcolor=lightblue]
	140236191190768 -> 140235124191680
	140235124191680 [label=AccumulateGrad]
	140235124191632 -> 140235124191584
	140236191190848 [label="blocks.5.2.bn3.bias
 (192)" fillcolor=lightblue]
	140236191190848 -> 140235124191632
	140235124191632 [label=AccumulateGrad]
	140235124191536 -> 140235113319248
	140235124191488 -> 140235113320400
	140236191310208 [label="blocks.5.3.conv_pw.weight
 (1152, 192, 1, 1)" fillcolor=lightblue]
	140236191310208 -> 140235124191488
	140235124191488 [label=AccumulateGrad]
	140235113320256 -> 140235113320352
	140236191310288 [label="blocks.5.3.bn1.weight
 (1152)" fillcolor=lightblue]
	140236191310288 -> 140235113320256
	140235113320256 [label=AccumulateGrad]
	140235124191296 -> 140235113320352
	140236191310368 [label="blocks.5.3.bn1.bias
 (1152)" fillcolor=lightblue]
	140236191310368 -> 140235124191296
	140235124191296 [label=AccumulateGrad]
	140235113320160 -> 140235113320016
	140236191310848 [label="blocks.5.3.conv_dw.weight
 (1152, 1, 5, 5)" fillcolor=lightblue]
	140236191310848 -> 140235113320160
	140235113320160 [label=AccumulateGrad]
	140235113319968 -> 140235113319920
	140236191310768 [label="blocks.5.3.bn2.weight
 (1152)" fillcolor=lightblue]
	140236191310768 -> 140235113319968
	140235113319968 [label=AccumulateGrad]
	140235113319824 -> 140235113319920
	140236191310928 [label="blocks.5.3.bn2.bias
 (1152)" fillcolor=lightblue]
	140236191310928 -> 140235113319824
	140235113319824 [label=AccumulateGrad]
	140235113319728 -> 140235113319632
	140235113319728 [label=SigmoidBackward0]
	140235113320112 -> 140235113319728
	140235113320112 [label=ConvolutionBackward0]
	140235113320304 -> 140235113320112
	140235113320304 [label=SiluBackward0]
	140235124191392 -> 140235113320304
	140235124191392 [label=ConvolutionBackward0]
	140235124192352 -> 140235124191392
	140235124192352 [label=MeanBackward1]
	140235113319776 -> 140235124192352
	140235124192592 -> 140235124191392
	140236191311328 [label="blocks.5.3.se.conv_reduce.weight
 (48, 1152, 1, 1)" fillcolor=lightblue]
	140236191311328 -> 140235124192592
	140235124192592 [label=AccumulateGrad]
	140235124191824 -> 140235124191392
	140236191311408 [label="blocks.5.3.se.conv_reduce.bias
 (48)" fillcolor=lightblue]
	140236191311408 -> 140235124191824
	140235124191824 [label=AccumulateGrad]
	140235113319872 -> 140235113320112
	140236191311568 [label="blocks.5.3.se.conv_expand.weight
 (1152, 48, 1, 1)" fillcolor=lightblue]
	140236191311568 -> 140235113319872
	140235113319872 [label=AccumulateGrad]
	140235124191440 -> 140235113320112
	140236191311648 [label="blocks.5.3.se.conv_expand.bias
 (1152)" fillcolor=lightblue]
	140236191311648 -> 140235124191440
	140235124191440 [label=AccumulateGrad]
	140235113319584 -> 140235113319440
	140236191311808 [label="blocks.5.3.conv_pwl.weight
 (192, 1152, 1, 1)" fillcolor=lightblue]
	140236191311808 -> 140235113319584
	140235113319584 [label=AccumulateGrad]
	140235113319392 -> 140235113319296
	140236191311888 [label="blocks.5.3.bn3.weight
 (192)" fillcolor=lightblue]
	140236191311888 -> 140235113319392
	140235113319392 [label=AccumulateGrad]
	140235113319344 -> 140235113319296
	140236191311968 [label="blocks.5.3.bn3.bias
 (192)" fillcolor=lightblue]
	140236191311968 -> 140235113319344
	140235113319344 [label=AccumulateGrad]
	140235113319248 -> 140235113319152
	140235113319104 -> 140235113318960
	140236191312448 [label="blocks.6.0.conv_pw.weight
 (1152, 192, 1, 1)" fillcolor=lightblue]
	140236191312448 -> 140235113319104
	140235113319104 [label=AccumulateGrad]
	140235113318912 -> 140235113318864
	140236191312528 [label="blocks.6.0.bn1.weight
 (1152)" fillcolor=lightblue]
	140236191312528 -> 140235113318912
	140235113318912 [label=AccumulateGrad]
	140235113318768 -> 140235113318864
	140236191312608 [label="blocks.6.0.bn1.bias
 (1152)" fillcolor=lightblue]
	140236191312608 -> 140235113318768
	140235113318768 [label=AccumulateGrad]
	140235113318672 -> 140235113318528
	140236191313088 [label="blocks.6.0.conv_dw.weight
 (1152, 1, 3, 3)" fillcolor=lightblue]
	140236191313088 -> 140235113318672
	140235113318672 [label=AccumulateGrad]
	140235113318480 -> 140235113318432
	140236191313008 [label="blocks.6.0.bn2.weight
 (1152)" fillcolor=lightblue]
	140236191313008 -> 140235113318480
	140235113318480 [label=AccumulateGrad]
	140235113318336 -> 140235113318432
	140236191313168 [label="blocks.6.0.bn2.bias
 (1152)" fillcolor=lightblue]
	140236191313168 -> 140235113318336
	140235113318336 [label=AccumulateGrad]
	140235113318240 -> 140235113318144
	140235113318240 [label=SigmoidBackward0]
	140235113318624 -> 140235113318240
	140235113318624 [label=ConvolutionBackward0]
	140235113319008 -> 140235113318624
	140235113319008 [label=SiluBackward0]
	140235113319200 -> 140235113319008
	140235113319200 [label=ConvolutionBackward0]
	140235113319680 -> 140235113319200
	140235113319680 [label=MeanBackward1]
	140235113318288 -> 140235113319680
	140235113320064 -> 140235113319200
	140236191313568 [label="blocks.6.0.se.conv_reduce.weight
 (48, 1152, 1, 1)" fillcolor=lightblue]
	140236191313568 -> 140235113320064
	140235113320064 [label=AccumulateGrad]
	140235113319536 -> 140235113319200
	140236191313648 [label="blocks.6.0.se.conv_reduce.bias
 (48)" fillcolor=lightblue]
	140236191313648 -> 140235113319536
	140235113319536 [label=AccumulateGrad]
	140235113319056 -> 140235113318624
	140236191313808 [label="blocks.6.0.se.conv_expand.weight
 (1152, 48, 1, 1)" fillcolor=lightblue]
	140236191313808 -> 140235113319056
	140235113319056 [label=AccumulateGrad]
	140235113318384 -> 140235113318624
	140235113209920 [label="blocks.6.0.se.conv_expand.bias
 (1152)" fillcolor=lightblue]
	140235113209920 -> 140235113318384
	140235113318384 [label=AccumulateGrad]
	140235113317952 -> 140235113317904
	140235113210080 [label="blocks.6.0.conv_pwl.weight
 (320, 1152, 1, 1)" fillcolor=lightblue]
	140235113210080 -> 140235113317952
	140235113317952 [label=AccumulateGrad]
	140235113318096 -> 140235113317472
	140235113210160 [label="blocks.6.0.bn3.weight
 (320)" fillcolor=lightblue]
	140235113210160 -> 140235113318096
	140235113318096 [label=AccumulateGrad]
	140235113317232 -> 140235113317472
	140235113210240 [label="blocks.6.0.bn3.bias
 (320)" fillcolor=lightblue]
	140235113210240 -> 140235113317232
	140235113317232 [label=AccumulateGrad]
	140235113318000 -> 140235113318048
	140235113210560 [label="conv_head.weight
 (1280, 320, 1, 1)" fillcolor=lightblue]
	140235113210560 -> 140235113318000
	140235113318000 [label=AccumulateGrad]
	140235113317520 -> 140236191338304
	140235113210640 [label="bn2.weight
 (1280)" fillcolor=lightblue]
	140235113210640 -> 140235113317520
	140235113317520 [label=AccumulateGrad]
	140235113317616 -> 140236191338304
	140235113210720 [label="bn2.bias
 (1280)" fillcolor=lightblue]
	140235113210720 -> 140235113317616
	140235113317616 [label=AccumulateGrad]
	140236191338352 -> 140236191338208
	140236191338352 [label=TBackward0]
	140236191336720 -> 140236191338352
	140235113211040 [label="classifier.weight
 (1000, 1280)" fillcolor=lightblue]
	140235113211040 -> 140236191336720
	140236191336720 [label=AccumulateGrad]
	140236191338208 -> 140235124238512
}
