digraph {
	graph [size="221.25,221.25"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140265077025744 [label="
 (1, 1000)" fillcolor=darkolivegreen1]
	140265077177984 [label=AddmmBackward0]
	140265077177120 -> 140265077177984
	140266145476496 [label="fc.bias
 (1000)" fillcolor=lightblue]
	140266145476496 -> 140265077177120
	140265077177120 [label=AccumulateGrad]
	140265077177264 -> 140265077177984
	140265077177264 [label=ReshapeAliasBackward0]
	140265077177312 -> 140265077177264
	140265077177312 [label=MeanBackward1]
	140265077176976 -> 140265077177312
	140265077176976 [label=ReluBackward0]
	140265077176880 -> 140265077176976
	140265077176880 [label=AddBackward0]
	140265077176688 -> 140265077176880
	140265077176688 [label=ReluBackward0]
	140265077176352 -> 140265077176688
	140265077176352 [label=AddBackward0]
	140265077176160 -> 140265077176352
	140265077176160 [label=ReluBackward0]
	140265077176016 -> 140265077176160
	140265077176016 [label=AddBackward0]
	140265077175920 -> 140265077176016
	140265077175920 [label=ReluBackward0]
	140265077175584 -> 140265077175920
	140265077175584 [label=AddBackward0]
	140265077175392 -> 140265077175584
	140265077175392 [label=ReluBackward0]
	140265077175152 -> 140265077175392
	140265077175152 [label=AddBackward0]
	140265077175056 -> 140265077175152
	140265077175056 [label=ReluBackward0]
	140265077174816 -> 140265077175056
	140265077174816 [label=AddBackward0]
	140265077174624 -> 140265077174816
	140265077174624 [label=NativeBatchNormBackward0]
	140265077174480 -> 140265077174624
	140265077174480 [label=ConvolutionBackward0]
	140265077174384 -> 140265077174480
	140265077174384 [label=ReluBackward0]
	140265077153312 -> 140265077174384
	140265077153312 [label=AddBackward0]
	140265077153120 -> 140265077153312
	140265077153120 [label=ReluBackward0]
	140265077152976 -> 140265077153120
	140265077152976 [label=AddBackward0]
	140265077152880 -> 140265077152976
	140265077152880 [label=ReluBackward0]
	140265077152544 -> 140265077152880
	140265077152544 [label=AddBackward0]
	140265077152352 -> 140265077152544
	140265077152352 [label=ReluBackward0]
	140265077152112 -> 140265077152352
	140265077152112 [label=AddBackward0]
	140265077152016 -> 140265077152112
	140265077152016 [label=ReluBackward0]
	140265077151776 -> 140265077152016
	140265077151776 [label=AddBackward0]
	140265077151584 -> 140265077151776
	140265077151584 [label=ReluBackward0]
	140265077151344 -> 140265077151584
	140265077151344 [label=AddBackward0]
	140265077151152 -> 140265077151344
	140265077151152 [label=NativeBatchNormBackward0]
	140265077150912 -> 140265077151152
	140265077150912 [label=ConvolutionBackward0]
	140265077150624 -> 140265077150912
	140265077150624 [label=ReluBackward0]
	140265077150480 -> 140265077150624
	140265077150480 [label=AddBackward0]
	140265077150384 -> 140265077150480
	140265077150384 [label=ReluBackward0]
	140265077150048 -> 140265077150384
	140265077150048 [label=AddBackward0]
	140265077149856 -> 140265077150048
	140265077149856 [label=ReluBackward0]
	140265077149808 -> 140265077149856
	140265077149808 [label=AddBackward0]
	140265077124880 -> 140265077149808
	140265077124880 [label=NativeBatchNormBackward0]
	140265077124640 -> 140265077124880
	140265077124640 [label=ConvolutionBackward0]
	140265077124256 -> 140265077124640
	140265077124256 [label=ReluBackward0]
	140265077124016 -> 140265077124256
	140265077124016 [label=AddBackward0]
	140265077123920 -> 140265077124016
	140265077123920 [label=NativeBatchNormBackward0]
	140265077123680 -> 140265077123920
	140265077123680 [label=ConvolutionBackward0]
	140265077123296 -> 140265077123680
	140265077123296 [label=ReluBackward0]
	140265077123056 -> 140265077123296
	140265077123056 [label=NativeBatchNormBackward0]
	140265077122960 -> 140265077123056
	140265077122960 [label=ConvolutionBackward0]
	140265077122672 -> 140265077122960
	140266133997824 [label="stem.0.weight
 (32, 3, 3, 3)" fillcolor=lightblue]
	140266133997824 -> 140265077122672
	140265077122672 [label=AccumulateGrad]
	140265077123008 -> 140265077123056
	140266133997744 [label="stem.1.weight
 (32)" fillcolor=lightblue]
	140266133997744 -> 140265077123008
	140265077123008 [label=AccumulateGrad]
	140265077123248 -> 140265077123056
	140266133997904 [label="stem.1.bias
 (32)" fillcolor=lightblue]
	140266133997904 -> 140265077123248
	140265077123248 [label=AccumulateGrad]
	140265077123440 -> 140265077123680
	140266133998624 [label="trunk_output.block1.block1-0.proj.0.weight
 (48, 32, 1, 1)" fillcolor=lightblue]
	140266133998624 -> 140265077123440
	140265077123440 [label=AccumulateGrad]
	140265077123824 -> 140265077123920
	140266133998544 [label="trunk_output.block1.block1-0.proj.1.weight
 (48)" fillcolor=lightblue]
	140266133998544 -> 140265077123824
	140265077123824 [label=AccumulateGrad]
	140265077123872 -> 140265077123920
	140266133998704 [label="trunk_output.block1.block1-0.proj.1.bias
 (48)" fillcolor=lightblue]
	140266133998704 -> 140265077123872
	140265077123872 [label=AccumulateGrad]
	140265077123968 -> 140265077124016
	140265077123968 [label=NativeBatchNormBackward0]
	140265077122720 -> 140265077123968
	140265077122720 [label=ConvolutionBackward0]
	140265077122528 -> 140265077122720
	140265077122528 [label=MulBackward0]
	140265077122384 -> 140265077122528
	140265077122384 [label=SigmoidBackward0]
	140265077122144 -> 140265077122384
	140265077122144 [label=ConvolutionBackward0]
	140265077121952 -> 140265077122144
	140265077121952 [label=ReluBackward0]
	140265077121568 -> 140265077121952
	140265077121568 [label=ConvolutionBackward0]
	140265077121472 -> 140265077121568
	140265077121472 [label=MeanBackward1]
	140265077122432 -> 140265077121472
	140265077122432 [label=ReluBackward0]
	140265077121136 -> 140265077122432
	140265077121136 [label=NativeBatchNormBackward0]
	140265077121328 -> 140265077121136
	140265077121328 [label=ConvolutionBackward0]
	140265077095920 -> 140265077121328
	140265077095920 [label=ReluBackward0]
	140265077095776 -> 140265077095920
	140265077095776 [label=NativeBatchNormBackward0]
	140265077095584 -> 140265077095776
	140265077095584 [label=ConvolutionBackward0]
	140265077123296 -> 140265077095584
	140265077095200 -> 140265077095584
	140266133999264 [label="trunk_output.block1.block1-0.f.a.0.weight
 (48, 32, 1, 1)" fillcolor=lightblue]
	140266133999264 -> 140265077095200
	140265077095200 [label=AccumulateGrad]
	140265077095728 -> 140265077095776
	140266133999184 [label="trunk_output.block1.block1-0.f.a.1.weight
 (48)" fillcolor=lightblue]
	140266133999184 -> 140265077095728
	140265077095728 [label=AccumulateGrad]
	140265077095872 -> 140265077095776
	140266133999344 [label="trunk_output.block1.block1-0.f.a.1.bias
 (48)" fillcolor=lightblue]
	140266133999344 -> 140265077095872
	140265077095872 [label=AccumulateGrad]
	140265077095968 -> 140265077121328
	140266134040960 [label="trunk_output.block1.block1-0.f.b.0.weight
 (48, 8, 3, 3)" fillcolor=lightblue]
	140266134040960 -> 140265077095968
	140265077095968 [label=AccumulateGrad]
	140265077096304 -> 140265077121136
	140266134040880 [label="trunk_output.block1.block1-0.f.b.1.weight
 (48)" fillcolor=lightblue]
	140266134040880 -> 140265077096304
	140265077096304 [label=AccumulateGrad]
	140265077096352 -> 140265077121136
	140266134041040 [label="trunk_output.block1.block1-0.f.b.1.bias
 (48)" fillcolor=lightblue]
	140266134041040 -> 140265077096352
	140265077096352 [label=AccumulateGrad]
	140265077121520 -> 140265077121568
	140266134041440 [label="trunk_output.block1.block1-0.f.se.fc1.weight
 (8, 48, 1, 1)" fillcolor=lightblue]
	140266134041440 -> 140265077121520
	140265077121520 [label=AccumulateGrad]
	140265077121760 -> 140265077121568
	140266134041520 [label="trunk_output.block1.block1-0.f.se.fc1.bias
 (8)" fillcolor=lightblue]
	140266134041520 -> 140265077121760
	140265077121760 [label=AccumulateGrad]
	140265077122096 -> 140265077122144
	140266134041680 [label="trunk_output.block1.block1-0.f.se.fc2.weight
 (48, 8, 1, 1)" fillcolor=lightblue]
	140266134041680 -> 140265077122096
	140265077122096 [label=AccumulateGrad]
	140265077122336 -> 140265077122144
	140266134041760 [label="trunk_output.block1.block1-0.f.se.fc2.bias
 (48)" fillcolor=lightblue]
	140266134041760 -> 140265077122336
	140265077122336 [label=AccumulateGrad]
	140265077122432 -> 140265077122528
	140265077122480 -> 140265077122720
	140266134042000 [label="trunk_output.block1.block1-0.f.c.0.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	140266134042000 -> 140265077122480
	140265077122480 [label=AccumulateGrad]
	140265077123488 -> 140265077123968
	140266134041920 [label="trunk_output.block1.block1-0.f.c.1.weight
 (48)" fillcolor=lightblue]
	140266134041920 -> 140265077123488
	140265077123488 [label=AccumulateGrad]
	140265077123632 -> 140265077123968
	140266134042080 [label="trunk_output.block1.block1-0.f.c.1.bias
 (48)" fillcolor=lightblue]
	140266134042080 -> 140265077123632
	140265077123632 [label=AccumulateGrad]
	140265077124400 -> 140265077124640
	140266134042480 [label="trunk_output.block2.block2-0.proj.0.weight
 (104, 48, 1, 1)" fillcolor=lightblue]
	140266134042480 -> 140265077124400
	140265077124400 [label=AccumulateGrad]
	140265077124784 -> 140265077124880
	140266134042400 [label="trunk_output.block2.block2-0.proj.1.weight
 (104)" fillcolor=lightblue]
	140266134042400 -> 140265077124784
	140265077124784 [label=AccumulateGrad]
	140265077124832 -> 140265077124880
	140266134042560 [label="trunk_output.block2.block2-0.proj.1.bias
 (104)" fillcolor=lightblue]
	140266134042560 -> 140265077124832
	140265077124832 [label=AccumulateGrad]
	140265077124928 -> 140265077149808
	140265077124928 [label=NativeBatchNormBackward0]
	140265077122816 -> 140265077124928
	140265077122816 [label=ConvolutionBackward0]
	140265077121904 -> 140265077122816
	140265077121904 [label=MulBackward0]
	140265077121712 -> 140265077121904
	140265077121712 [label=SigmoidBackward0]
	140265077121376 -> 140265077121712
	140265077121376 [label=ConvolutionBackward0]
	140265077121424 -> 140265077121376
	140265077121424 [label=ReluBackward0]
	140265077095008 -> 140265077121424
	140265077095008 [label=ConvolutionBackward0]
	140265077095392 -> 140265077095008
	140265077095392 [label=MeanBackward1]
	140265077122768 -> 140265077095392
	140265077122768 [label=ReluBackward0]
	140265077094672 -> 140265077122768
	140265077094672 [label=NativeBatchNormBackward0]
	140265077094576 -> 140265077094672
	140265077094576 [label=ConvolutionBackward0]
	140265077094288 -> 140265077094576
	140265077094288 [label=ReluBackward0]
	140265077094048 -> 140265077094288
	140265077094048 [label=NativeBatchNormBackward0]
	140265077093856 -> 140265077094048
	140265077093856 [label=ConvolutionBackward0]
	140265077124256 -> 140265077093856
	140265077093472 -> 140265077093856
	140266134043120 [label="trunk_output.block2.block2-0.f.a.0.weight
 (104, 48, 1, 1)" fillcolor=lightblue]
	140266134043120 -> 140265077093472
	140265077093472 [label=AccumulateGrad]
	140265077094000 -> 140265077094048
	140266134043040 [label="trunk_output.block2.block2-0.f.a.1.weight
 (104)" fillcolor=lightblue]
	140266134043040 -> 140265077094000
	140265077094000 [label=AccumulateGrad]
	140265077094240 -> 140265077094048
	140266134043200 [label="trunk_output.block2.block2-0.f.a.1.bias
 (104)" fillcolor=lightblue]
	140266134043200 -> 140265077094240
	140265077094240 [label=AccumulateGrad]
	140265077094336 -> 140265077094576
	140266134043760 [label="trunk_output.block2.block2-0.f.b.0.weight
 (104, 8, 3, 3)" fillcolor=lightblue]
	140266134043760 -> 140265077094336
	140265077094336 [label=AccumulateGrad]
	140265077094624 -> 140265077094672
	140266134043680 [label="trunk_output.block2.block2-0.f.b.1.weight
 (104)" fillcolor=lightblue]
	140266134043680 -> 140265077094624
	140265077094624 [label=AccumulateGrad]
	140265077094864 -> 140265077094672
	140266134043840 [label="trunk_output.block2.block2-0.f.b.1.bias
 (104)" fillcolor=lightblue]
	140266134043840 -> 140265077094864
	140265077094864 [label=AccumulateGrad]
	140265077095152 -> 140265077095008
	140266134044240 [label="trunk_output.block2.block2-0.f.se.fc1.weight
 (12, 104, 1, 1)" fillcolor=lightblue]
	140266134044240 -> 140265077095152
	140265077095152 [label=AccumulateGrad]
	140265077095536 -> 140265077095008
	140266134044320 [label="trunk_output.block2.block2-0.f.se.fc1.bias
 (12)" fillcolor=lightblue]
	140266134044320 -> 140265077095536
	140265077095536 [label=AccumulateGrad]
	140265077096112 -> 140265077121376
	140266134044480 [label="trunk_output.block2.block2-0.f.se.fc2.weight
 (104, 12, 1, 1)" fillcolor=lightblue]
	140266134044480 -> 140265077096112
	140265077096112 [label=AccumulateGrad]
	140265077096160 -> 140265077121376
	140266134044560 [label="trunk_output.block2.block2-0.f.se.fc2.bias
 (104)" fillcolor=lightblue]
	140266134044560 -> 140265077096160
	140265077096160 [label=AccumulateGrad]
	140265077122768 -> 140265077121904
	140265077123104 -> 140265077122816
	140266134175968 [label="trunk_output.block2.block2-0.f.c.0.weight
 (104, 104, 1, 1)" fillcolor=lightblue]
	140266134175968 -> 140265077123104
	140265077123104 [label=AccumulateGrad]
	140265077124448 -> 140265077124928
	140266134175888 [label="trunk_output.block2.block2-0.f.c.1.weight
 (104)" fillcolor=lightblue]
	140266134175888 -> 140265077124448
	140265077124448 [label=AccumulateGrad]
	140265077124592 -> 140265077124928
	140266134176048 [label="trunk_output.block2.block2-0.f.c.1.bias
 (104)" fillcolor=lightblue]
	140266134176048 -> 140265077124592
	140265077124592 [label=AccumulateGrad]
	140265077150000 -> 140265077150048
	140265077150000 [label=NativeBatchNormBackward0]
	140265077124208 -> 140265077150000
	140265077124208 [label=ConvolutionBackward0]
	140265077122288 -> 140265077124208
	140265077122288 [label=MulBackward0]
	140265077094720 -> 140265077122288
	140265077094720 [label=SigmoidBackward0]
	140265077094384 -> 140265077094720
	140265077094384 [label=ConvolutionBackward0]
	140265077093808 -> 140265077094384
	140265077093808 [label=ReluBackward0]
	140265077093664 -> 140265077093808
	140265077093664 [label=ConvolutionBackward0]
	140265077093280 -> 140265077093664
	140265077093280 [label=MeanBackward1]
	140265077094960 -> 140265077093280
	140265077094960 [label=ReluBackward0]
	140265077092848 -> 140265077094960
	140265077092848 [label=NativeBatchNormBackward0]
	140265077092656 -> 140265077092848
	140265077092656 [label=ConvolutionBackward0]
	140265077092416 -> 140265077092656
	140265077092416 [label=ReluBackward0]
	140265077071584 -> 140265077092416
	140265077071584 [label=NativeBatchNormBackward0]
	140265077071392 -> 140265077071584
	140265077071392 [label=ConvolutionBackward0]
	140265077149856 -> 140265077071392
	140265077071008 -> 140265077071392
	140266134176528 [label="trunk_output.block2.block2-1.f.a.0.weight
 (104, 104, 1, 1)" fillcolor=lightblue]
	140266134176528 -> 140265077071008
	140265077071008 [label=AccumulateGrad]
	140265077071536 -> 140265077071584
	140266134176448 [label="trunk_output.block2.block2-1.f.a.1.weight
 (104)" fillcolor=lightblue]
	140266134176448 -> 140265077071536
	140265077071536 [label=AccumulateGrad]
	140265077071776 -> 140265077071584
	140266134176608 [label="trunk_output.block2.block2-1.f.a.1.bias
 (104)" fillcolor=lightblue]
	140266134176608 -> 140265077071776
	140265077071776 [label=AccumulateGrad]
	140265077092464 -> 140265077092656
	140266134177088 [label="trunk_output.block2.block2-1.f.b.0.weight
 (104, 8, 3, 3)" fillcolor=lightblue]
	140266134177088 -> 140265077092464
	140265077092464 [label=AccumulateGrad]
	140265077092704 -> 140265077092848
	140266134177008 [label="trunk_output.block2.block2-1.f.b.1.weight
 (104)" fillcolor=lightblue]
	140266134177008 -> 140265077092704
	140265077092704 [label=AccumulateGrad]
	140265077093040 -> 140265077092848
	140266134177168 [label="trunk_output.block2.block2-1.f.b.1.bias
 (104)" fillcolor=lightblue]
	140266134177168 -> 140265077093040
	140265077093040 [label=AccumulateGrad]
	140265077093328 -> 140265077093664
	140266134177568 [label="trunk_output.block2.block2-1.f.se.fc1.weight
 (26, 104, 1, 1)" fillcolor=lightblue]
	140266134177568 -> 140265077093328
	140265077093328 [label=AccumulateGrad]
	140265077093376 -> 140265077093664
	140266134177648 [label="trunk_output.block2.block2-1.f.se.fc1.bias
 (26)" fillcolor=lightblue]
	140266134177648 -> 140265077093376
	140265077093376 [label=AccumulateGrad]
	140265077093616 -> 140265077094384
	140266134177808 [label="trunk_output.block2.block2-1.f.se.fc2.weight
 (104, 26, 1, 1)" fillcolor=lightblue]
	140266134177808 -> 140265077093616
	140265077093616 [label=AccumulateGrad]
	140265077094912 -> 140265077094384
	140266134177888 [label="trunk_output.block2.block2-1.f.se.fc2.bias
 (104)" fillcolor=lightblue]
	140266134177888 -> 140265077094912
	140265077094912 [label=AccumulateGrad]
	140265077094960 -> 140265077122288
	140265077121184 -> 140265077124208
	140266134178128 [label="trunk_output.block2.block2-1.f.c.0.weight
 (104, 104, 1, 1)" fillcolor=lightblue]
	140266134178128 -> 140265077121184
	140265077121184 [label=AccumulateGrad]
	140265077125024 -> 140265077150000
	140266134178048 [label="trunk_output.block2.block2-1.f.c.1.weight
 (104)" fillcolor=lightblue]
	140266134178048 -> 140265077125024
	140265077125024 [label=AccumulateGrad]
	140265077124976 -> 140265077150000
	140266134178208 [label="trunk_output.block2.block2-1.f.c.1.bias
 (104)" fillcolor=lightblue]
	140266134178208 -> 140265077124976
	140265077124976 [label=AccumulateGrad]
	140265077150432 -> 140265077150480
	140265077150432 [label=NativeBatchNormBackward0]
	140265077124064 -> 140265077150432
	140265077124064 [label=ConvolutionBackward0]
	140265077095824 -> 140265077124064
	140265077095824 [label=MulBackward0]
	140265077092896 -> 140265077095824
	140265077092896 [label=SigmoidBackward0]
	140265077092512 -> 140265077092896
	140265077092512 [label=ConvolutionBackward0]
	140265077071344 -> 140265077092512
	140265077071344 [label=ReluBackward0]
	140265077071200 -> 140265077071344
	140265077071200 [label=ConvolutionBackward0]
	140265077070720 -> 140265077071200
	140265077070720 [label=MeanBackward1]
	140265077093232 -> 140265077070720
	140265077093232 [label=ReluBackward0]
	140265077070384 -> 140265077093232
	140265077070384 [label=NativeBatchNormBackward0]
	140265077070288 -> 140265077070384
	140265077070288 [label=ConvolutionBackward0]
	140265077070000 -> 140265077070288
	140265077070000 [label=ReluBackward0]
	140265077069664 -> 140265077070000
	140265077069664 [label=NativeBatchNormBackward0]
	140265077069472 -> 140265077069664
	140265077069472 [label=ConvolutionBackward0]
	140265077150384 -> 140265077069472
	140265077069280 -> 140265077069472
	140266134178688 [label="trunk_output.block2.block2-2.f.a.0.weight
 (104, 104, 1, 1)" fillcolor=lightblue]
	140266134178688 -> 140265077069280
	140265077069280 [label=AccumulateGrad]
	140265077069616 -> 140265077069664
	140266134178608 [label="trunk_output.block2.block2-2.f.a.1.weight
 (104)" fillcolor=lightblue]
	140266134178608 -> 140265077069616
	140265077069616 [label=AccumulateGrad]
	140265077069856 -> 140265077069664
	140266134178768 [label="trunk_output.block2.block2-2.f.a.1.bias
 (104)" fillcolor=lightblue]
	140266134178768 -> 140265077069856
	140265077069856 [label=AccumulateGrad]
	140265077070048 -> 140265077070288
	140266134179248 [label="trunk_output.block2.block2-2.f.b.0.weight
 (104, 8, 3, 3)" fillcolor=lightblue]
	140266134179248 -> 140265077070048
	140265077070048 [label=AccumulateGrad]
	140265077070336 -> 140265077070384
	140266134179168 [label="trunk_output.block2.block2-2.f.b.1.weight
 (104)" fillcolor=lightblue]
	140266134179168 -> 140265077070336
	140265077070336 [label=AccumulateGrad]
	140265077070576 -> 140265077070384
	140266134179328 [label="trunk_output.block2.block2-2.f.b.1.bias
 (104)" fillcolor=lightblue]
	140266134179328 -> 140265077070576
	140265077070576 [label=AccumulateGrad]
	140265077070864 -> 140265077071200
	140266134179728 [label="trunk_output.block2.block2-2.f.se.fc1.weight
 (26, 104, 1, 1)" fillcolor=lightblue]
	140266134179728 -> 140265077070864
	140265077070864 [label=AccumulateGrad]
	140265077070912 -> 140265077071200
	140266134306880 [label="trunk_output.block2.block2-2.f.se.fc1.bias
 (26)" fillcolor=lightblue]
	140266134306880 -> 140265077070912
	140265077070912 [label=AccumulateGrad]
	140265077071152 -> 140265077092512
	140266134307040 [label="trunk_output.block2.block2-2.f.se.fc2.weight
 (104, 26, 1, 1)" fillcolor=lightblue]
	140266134307040 -> 140265077071152
	140265077071152 [label=AccumulateGrad]
	140265077071824 -> 140265077092512
	140266134307120 [label="trunk_output.block2.block2-2.f.se.fc2.bias
 (104)" fillcolor=lightblue]
	140266134307120 -> 140265077071824
	140265077071824 [label=AccumulateGrad]
	140265077093232 -> 140265077095824
	140265077094432 -> 140265077124064
	140266134307360 [label="trunk_output.block2.block2-2.f.c.0.weight
 (104, 104, 1, 1)" fillcolor=lightblue]
	140266134307360 -> 140265077094432
	140265077094432 [label=AccumulateGrad]
	140265077150240 -> 140265077150432
	140266134307280 [label="trunk_output.block2.block2-2.f.c.1.weight
 (104)" fillcolor=lightblue]
	140266134307280 -> 140265077150240
	140265077150240 [label=AccumulateGrad]
	140265077150192 -> 140265077150432
	140266134307440 [label="trunk_output.block2.block2-2.f.c.1.bias
 (104)" fillcolor=lightblue]
	140266134307440 -> 140265077150192
	140265077150192 [label=AccumulateGrad]
	140265077150768 -> 140265077150912
	140266134307840 [label="trunk_output.block3.block3-0.proj.0.weight
 (208, 104, 1, 1)" fillcolor=lightblue]
	140266134307840 -> 140265077150768
	140265077150768 [label=AccumulateGrad]
	140265077151056 -> 140265077151152
	140266134307760 [label="trunk_output.block3.block3-0.proj.1.weight
 (208)" fillcolor=lightblue]
	140266134307760 -> 140265077151056
	140265077151056 [label=AccumulateGrad]
	140265077151104 -> 140265077151152
	140266134307920 [label="trunk_output.block3.block3-0.proj.1.bias
 (208)" fillcolor=lightblue]
	140266134307920 -> 140265077151104
	140265077151104 [label=AccumulateGrad]
	140265077151200 -> 140265077151344
	140265077151200 [label=NativeBatchNormBackward0]
	140265077150576 -> 140265077151200
	140265077150576 [label=ConvolutionBackward0]
	140265077093088 -> 140265077150576
	140265077093088 [label=MulBackward0]
	140265077070672 -> 140265077093088
	140265077070672 [label=SigmoidBackward0]
	140265077070240 -> 140265077070672
	140265077070240 [label=ConvolutionBackward0]
	140265077069328 -> 140265077070240
	140265077069328 [label=ReluBackward0]
	140265077069232 -> 140265077069328
	140265077069232 [label=ConvolutionBackward0]
	140265077069040 -> 140265077069232
	140265077069040 [label=MeanBackward1]
	140265077071728 -> 140265077069040
	140265077071728 [label=ReluBackward0]
	140265077068512 -> 140265077071728
	140265077068512 [label=NativeBatchNormBackward0]
	140265077068416 -> 140265077068512
	140265077068416 [label=ConvolutionBackward0]
	140265077068128 -> 140265077068416
	140265077068128 [label=ReluBackward0]
	140265077067888 -> 140265077068128
	140265077067888 [label=NativeBatchNormBackward0]
	140265077068080 -> 140265077067888
	140265077068080 [label=ConvolutionBackward0]
	140265077150624 -> 140265077068080
	140265077046864 -> 140265077068080
	140266134308480 [label="trunk_output.block3.block3-0.f.a.0.weight
 (208, 104, 1, 1)" fillcolor=lightblue]
	140266134308480 -> 140265077046864
	140265077046864 [label=AccumulateGrad]
	140265077047152 -> 140265077067888
	140266134308400 [label="trunk_output.block3.block3-0.f.a.1.weight
 (208)" fillcolor=lightblue]
	140266134308400 -> 140265077047152
	140265077047152 [label=AccumulateGrad]
	140265077047200 -> 140265077067888
	140266134308560 [label="trunk_output.block3.block3-0.f.a.1.bias
 (208)" fillcolor=lightblue]
	140266134308560 -> 140265077047200
	140265077047200 [label=AccumulateGrad]
	140265077068272 -> 140265077068416
	140266134309040 [label="trunk_output.block3.block3-0.f.b.0.weight
 (208, 8, 3, 3)" fillcolor=lightblue]
	140266134309040 -> 140265077068272
	140265077068272 [label=AccumulateGrad]
	140265077068464 -> 140265077068512
	140266134308960 [label="trunk_output.block3.block3-0.f.b.1.weight
 (208)" fillcolor=lightblue]
	140266134308960 -> 140265077068464
	140265077068464 [label=AccumulateGrad]
	140265077068704 -> 140265077068512
	140266134309120 [label="trunk_output.block3.block3-0.f.b.1.bias
 (208)" fillcolor=lightblue]
	140266134309120 -> 140265077068704
	140265077068704 [label=AccumulateGrad]
	140265077069376 -> 140265077069232
	140266134309520 [label="trunk_output.block3.block3-0.f.se.fc1.weight
 (26, 208, 1, 1)" fillcolor=lightblue]
	140266134309520 -> 140265077069376
	140265077069376 [label=AccumulateGrad]
	140265077069808 -> 140265077069232
	140266134309600 [label="trunk_output.block3.block3-0.f.se.fc1.bias
 (26)" fillcolor=lightblue]
	140266134309600 -> 140265077069808
	140265077069808 [label=AccumulateGrad]
	140265077070192 -> 140265077070240
	140266134309760 [label="trunk_output.block3.block3-0.f.se.fc2.weight
 (208, 26, 1, 1)" fillcolor=lightblue]
	140266134309760 -> 140265077070192
	140265077070192 [label=AccumulateGrad]
	140265077070432 -> 140265077070240
	140266134309840 [label="trunk_output.block3.block3-0.f.se.fc2.bias
 (208)" fillcolor=lightblue]
	140266134309840 -> 140265077070432
	140265077070432 [label=AccumulateGrad]
	140265077071728 -> 140265077093088
	140265077094192 -> 140265077150576
	140266134310080 [label="trunk_output.block3.block3-0.f.c.0.weight
 (208, 208, 1, 1)" fillcolor=lightblue]
	140266134310080 -> 140265077094192
	140265077094192 [label=AccumulateGrad]
	140265077150816 -> 140265077151200
	140266134310000 [label="trunk_output.block3.block3-0.f.c.1.weight
 (208)" fillcolor=lightblue]
	140266134310000 -> 140265077150816
	140265077150816 [label=AccumulateGrad]
	140265077150864 -> 140265077151200
	140266134310160 [label="trunk_output.block3.block3-0.f.c.1.bias
 (208)" fillcolor=lightblue]
	140266134310160 -> 140265077150864
	140265077150864 [label=AccumulateGrad]
	140265077151728 -> 140265077151776
	140265077151728 [label=NativeBatchNormBackward0]
	140265077150528 -> 140265077151728
	140265077150528 [label=ConvolutionBackward0]
	140265077070960 -> 140265077150528
	140265077070960 [label=MulBackward0]
	140265077068656 -> 140265077070960
	140265077068656 [label=SigmoidBackward0]
	140265077068320 -> 140265077068656
	140265077068320 [label=ConvolutionBackward0]
	140265077067936 -> 140265077068320
	140265077067936 [label=ReluBackward0]
	140265077046960 -> 140265077067936
	140265077046960 [label=ConvolutionBackward0]
	140265077046576 -> 140265077046960
	140265077046576 [label=MeanBackward1]
	140265077068896 -> 140265077046576
	140265077068896 [label=ReluBackward0]
	140265077046048 -> 140265077068896
	140265077046048 [label=NativeBatchNormBackward0]
	140265077045952 -> 140265077046048
	140265077045952 [label=ConvolutionBackward0]
	140265077045664 -> 140265077045952
	140265077045664 [label=ReluBackward0]
	140265077045424 -> 140265077045664
	140265077045424 [label=NativeBatchNormBackward0]
	140265077045328 -> 140265077045424
	140265077045328 [label=ConvolutionBackward0]
	140265077151584 -> 140265077045328
	140265077045040 -> 140265077045328
	140266134310640 [label="trunk_output.block3.block3-1.f.a.0.weight
 (208, 208, 1, 1)" fillcolor=lightblue]
	140266134310640 -> 140265077045040
	140265077045040 [label=AccumulateGrad]
	140265077045376 -> 140265077045424
	140266134310560 [label="trunk_output.block3.block3-1.f.a.1.weight
 (208)" fillcolor=lightblue]
	140266134310560 -> 140265077045376
	140265077045376 [label=AccumulateGrad]
	140265077045616 -> 140265077045424
	140266134310720 [label="trunk_output.block3.block3-1.f.a.1.bias
 (208)" fillcolor=lightblue]
	140266134310720 -> 140265077045616
	140265077045616 [label=AccumulateGrad]
	140265077045712 -> 140265077045952
	140266134434176 [label="trunk_output.block3.block3-1.f.b.0.weight
 (208, 8, 3, 3)" fillcolor=lightblue]
	140266134434176 -> 140265077045712
	140265077045712 [label=AccumulateGrad]
	140265077046000 -> 140265077046048
	140266134434096 [label="trunk_output.block3.block3-1.f.b.1.weight
 (208)" fillcolor=lightblue]
	140266134434096 -> 140265077046000
	140265077046000 [label=AccumulateGrad]
	140265077046240 -> 140265077046048
	140266134434256 [label="trunk_output.block3.block3-1.f.b.1.bias
 (208)" fillcolor=lightblue]
	140266134434256 -> 140265077046240
	140265077046240 [label=AccumulateGrad]
	140265077046624 -> 140265077046960
	140266134434656 [label="trunk_output.block3.block3-1.f.se.fc1.weight
 (52, 208, 1, 1)" fillcolor=lightblue]
	140266134434656 -> 140265077046624
	140265077046624 [label=AccumulateGrad]
	140265077046768 -> 140265077046960
	140266134434736 [label="trunk_output.block3.block3-1.f.se.fc1.bias
 (52)" fillcolor=lightblue]
	140266134434736 -> 140265077046768
	140265077046768 [label=AccumulateGrad]
	140265077068848 -> 140265077068320
	140266134434896 [label="trunk_output.block3.block3-1.f.se.fc2.weight
 (208, 52, 1, 1)" fillcolor=lightblue]
	140266134434896 -> 140265077068848
	140265077068848 [label=AccumulateGrad]
	140265077046912 -> 140265077068320
	140266134434976 [label="trunk_output.block3.block3-1.f.se.fc2.bias
 (208)" fillcolor=lightblue]
	140266134434976 -> 140265077046912
	140265077046912 [label=AccumulateGrad]
	140265077068896 -> 140265077070960
	140265077070624 -> 140265077150528
	140266134435216 [label="trunk_output.block3.block3-1.f.c.0.weight
 (208, 208, 1, 1)" fillcolor=lightblue]
	140266134435216 -> 140265077070624
	140265077070624 [label=AccumulateGrad]
	140265077151536 -> 140265077151728
	140266134435136 [label="trunk_output.block3.block3-1.f.c.1.weight
 (208)" fillcolor=lightblue]
	140266134435136 -> 140265077151536
	140265077151536 [label=AccumulateGrad]
	140265077151392 -> 140265077151728
	140266134435296 [label="trunk_output.block3.block3-1.f.c.1.bias
 (208)" fillcolor=lightblue]
	140266134435296 -> 140265077151392
	140265077151392 [label=AccumulateGrad]
	140265077152064 -> 140265077152112
	140265077152064 [label=NativeBatchNormBackward0]
	140265077095344 -> 140265077152064
	140265077095344 [label=ConvolutionBackward0]
	140265077069088 -> 140265077095344
	140265077069088 [label=MulBackward0]
	140265077046192 -> 140265077069088
	140265077046192 [label=SigmoidBackward0]
	140265077045760 -> 140265077046192
	140265077045760 [label=ConvolutionBackward0]
	140265077045280 -> 140265077045760
	140265077045280 [label=ReluBackward0]
	140265077045232 -> 140265077045280
	140265077045232 [label=ConvolutionBackward0]
	140265077044656 -> 140265077045232
	140265077044656 [label=MeanBackward1]
	140265077046432 -> 140265077044656
	140265077046432 [label=ReluBackward0]
	140265077044320 -> 140265077046432
	140265077044320 [label=NativeBatchNormBackward0]
	140265077044128 -> 140265077044320
	140265077044128 [label=ConvolutionBackward0]
	140265077043744 -> 140265077044128
	140265077043744 [label=ReluBackward0]
	140265077043504 -> 140265077043744
	140265077043504 [label=NativeBatchNormBackward0]
	140265077043408 -> 140265077043504
	140265077043408 [label=ConvolutionBackward0]
	140265077152016 -> 140265077043408
	140265077043312 -> 140265077043408
	140266134435776 [label="trunk_output.block3.block3-2.f.a.0.weight
 (208, 208, 1, 1)" fillcolor=lightblue]
	140266134435776 -> 140265077043312
	140265077043312 [label=AccumulateGrad]
	140265077043456 -> 140265077043504
	140266134435696 [label="trunk_output.block3.block3-2.f.a.1.weight
 (208)" fillcolor=lightblue]
	140266134435696 -> 140265077043456
	140265077043456 [label=AccumulateGrad]
	140265077043696 -> 140265077043504
	140266134435856 [label="trunk_output.block3.block3-2.f.a.1.bias
 (208)" fillcolor=lightblue]
	140266134435856 -> 140265077043696
	140265077043696 [label=AccumulateGrad]
	140265077043888 -> 140265077044128
	140266134436336 [label="trunk_output.block3.block3-2.f.b.0.weight
 (208, 8, 3, 3)" fillcolor=lightblue]
	140266134436336 -> 140265077043888
	140265077043888 [label=AccumulateGrad]
	140265077044272 -> 140265077044320
	140266134436256 [label="trunk_output.block3.block3-2.f.b.1.weight
 (208)" fillcolor=lightblue]
	140266134436256 -> 140265077044272
	140265077044272 [label=AccumulateGrad]
	140265077044416 -> 140265077044320
	140266134436416 [label="trunk_output.block3.block3-2.f.b.1.bias
 (208)" fillcolor=lightblue]
	140266134436416 -> 140265077044416
	140265077044416 [label=AccumulateGrad]
	140265077044704 -> 140265077045232
	140266134436816 [label="trunk_output.block3.block3-2.f.se.fc1.weight
 (52, 208, 1, 1)" fillcolor=lightblue]
	140266134436816 -> 140265077044704
	140265077044704 [label=AccumulateGrad]
	140265077044848 -> 140265077045232
	140266134436896 [label="trunk_output.block3.block3-2.f.se.fc1.bias
 (52)" fillcolor=lightblue]
	140266134436896 -> 140265077044848
	140265077044848 [label=AccumulateGrad]
	140265077045088 -> 140265077045760
	140266134437056 [label="trunk_output.block3.block3-2.f.se.fc2.weight
 (208, 52, 1, 1)" fillcolor=lightblue]
	140266134437056 -> 140265077045088
	140265077045088 [label=AccumulateGrad]
	140265077046384 -> 140265077045760
	140266134437136 [label="trunk_output.block3.block3-2.f.se.fc2.bias
 (208)" fillcolor=lightblue]
	140266134437136 -> 140265077046384
	140265077046384 [label=AccumulateGrad]
	140265077046432 -> 140265077069088
	140265077068368 -> 140265077095344
	140266134437376 [label="trunk_output.block3.block3-2.f.c.0.weight
 (208, 208, 1, 1)" fillcolor=lightblue]
	140266134437376 -> 140265077068368
	140265077068368 [label=AccumulateGrad]
	140265077151968 -> 140265077152064
	140266134437296 [label="trunk_output.block3.block3-2.f.c.1.weight
 (208)" fillcolor=lightblue]
	140266134437296 -> 140265077151968
	140265077151968 [label=AccumulateGrad]
	140265077151920 -> 140265077152064
	140266134437456 [label="trunk_output.block3.block3-2.f.c.1.bias
 (208)" fillcolor=lightblue]
	140266134437456 -> 140265077151920
	140265077151920 [label=AccumulateGrad]
	140265077152496 -> 140265077152544
	140265077152496 [label=NativeBatchNormBackward0]
	140265077069424 -> 140265077152496
	140265077069424 [label=ConvolutionBackward0]
	140265077046816 -> 140265077069424
	140265077046816 [label=MulBackward0]
	140265077044368 -> 140265077046816
	140265077044368 [label=SigmoidBackward0]
	140265077043936 -> 140265077044368
	140265077043936 [label=ConvolutionBackward0]
	140265077043552 -> 140265077043936
	140265077043552 [label=ReluBackward0]
	140265077018528 -> 140265077043552
	140265077018528 [label=ConvolutionBackward0]
	140265077018096 -> 140265077018528
	140265077018096 [label=MeanBackward1]
	140265077044512 -> 140265077018096
	140265077044512 [label=ReluBackward0]
	140265077017664 -> 140265077044512
	140265077017664 [label=NativeBatchNormBackward0]
	140265077017568 -> 140265077017664
	140265077017568 [label=ConvolutionBackward0]
	140265077017280 -> 140265077017568
	140265077017280 [label=ReluBackward0]
	140265077017136 -> 140265077017280
	140265077017136 [label=NativeBatchNormBackward0]
	140265077016944 -> 140265077017136
	140265077016944 [label=ConvolutionBackward0]
	140265077152352 -> 140265077016944
	140265077016560 -> 140265077016944
	140266135965840 [label="trunk_output.block3.block3-3.f.a.0.weight
 (208, 208, 1, 1)" fillcolor=lightblue]
	140266135965840 -> 140265077016560
	140265077016560 [label=AccumulateGrad]
	140265077016992 -> 140265077017136
	140266135965760 [label="trunk_output.block3.block3-3.f.a.1.weight
 (208)" fillcolor=lightblue]
	140266135965760 -> 140265077016992
	140265077016992 [label=AccumulateGrad]
	140265077017232 -> 140265077017136
	140266135965920 [label="trunk_output.block3.block3-3.f.a.1.bias
 (208)" fillcolor=lightblue]
	140266135965920 -> 140265077017232
	140265077017232 [label=AccumulateGrad]
	140265077017328 -> 140265077017568
	140266135966400 [label="trunk_output.block3.block3-3.f.b.0.weight
 (208, 8, 3, 3)" fillcolor=lightblue]
	140266135966400 -> 140265077017328
	140265077017328 [label=AccumulateGrad]
	140265077017616 -> 140265077017664
	140266135966320 [label="trunk_output.block3.block3-3.f.b.1.weight
 (208)" fillcolor=lightblue]
	140266135966320 -> 140265077017616
	140265077017616 [label=AccumulateGrad]
	140265077017856 -> 140265077017664
	140266135966480 [label="trunk_output.block3.block3-3.f.b.1.bias
 (208)" fillcolor=lightblue]
	140266135966480 -> 140265077017856
	140265077017856 [label=AccumulateGrad]
	140265077018144 -> 140265077018528
	140266135966880 [label="trunk_output.block3.block3-3.f.se.fc1.weight
 (52, 208, 1, 1)" fillcolor=lightblue]
	140266135966880 -> 140265077018144
	140265077018144 [label=AccumulateGrad]
	140265077018288 -> 140265077018528
	140266135966960 [label="trunk_output.block3.block3-3.f.se.fc1.bias
 (52)" fillcolor=lightblue]
	140266135966960 -> 140265077018288
	140265077018288 [label=AccumulateGrad]
	140265077043360 -> 140265077043936
	140266135967120 [label="trunk_output.block3.block3-3.f.se.fc2.weight
 (208, 52, 1, 1)" fillcolor=lightblue]
	140266135967120 -> 140265077043360
	140265077043360 [label=AccumulateGrad]
	140265077044464 -> 140265077043936
	140266135967200 [label="trunk_output.block3.block3-3.f.se.fc2.bias
 (208)" fillcolor=lightblue]
	140266135967200 -> 140265077044464
	140265077044464 [label=AccumulateGrad]
	140265077044512 -> 140265077046816
	140265077045904 -> 140265077069424
	140266135967440 [label="trunk_output.block3.block3-3.f.c.0.weight
 (208, 208, 1, 1)" fillcolor=lightblue]
	140266135967440 -> 140265077045904
	140265077045904 [label=AccumulateGrad]
	140265077152304 -> 140265077152496
	140266135967360 [label="trunk_output.block3.block3-3.f.c.1.weight
 (208)" fillcolor=lightblue]
	140266135967360 -> 140265077152304
	140265077152304 [label=AccumulateGrad]
	140265077152160 -> 140265077152496
	140266135967520 [label="trunk_output.block3.block3-3.f.c.1.bias
 (208)" fillcolor=lightblue]
	140266135967520 -> 140265077152160
	140265077152160 [label=AccumulateGrad]
	140265077152928 -> 140265077152976
	140265077152928 [label=NativeBatchNormBackward0]
	140265077152736 -> 140265077152928
	140265077152736 [label=ConvolutionBackward0]
	140265077044896 -> 140265077152736
	140265077044896 [label=MulBackward0]
	140265077017808 -> 140265077044896
	140265077017808 [label=SigmoidBackward0]
	140265077017376 -> 140265077017808
	140265077017376 [label=ConvolutionBackward0]
	140265077016800 -> 140265077017376
	140265077016800 [label=ReluBackward0]
	140265077016752 -> 140265077016800
	140265077016752 [label=ConvolutionBackward0]
	140265077016272 -> 140265077016752
	140265077016272 [label=MeanBackward1]
	140265077017952 -> 140265077016272
	140265077017952 [label=ReluBackward0]
	140265077015840 -> 140265077017952
	140265077015840 [label=NativeBatchNormBackward0]
	140265077015648 -> 140265077015840
	140265077015648 [label=ConvolutionBackward0]
	140265077015360 -> 140265077015648
	140265077015360 [label=ReluBackward0]
	140265077015216 -> 140265077015360
	140265077015216 [label=NativeBatchNormBackward0]
	140265077015024 -> 140265077015216
	140265077015024 [label=ConvolutionBackward0]
	140265077152880 -> 140265077015024
	140265077014640 -> 140265077015024
	140266135968000 [label="trunk_output.block3.block3-4.f.a.0.weight
 (208, 208, 1, 1)" fillcolor=lightblue]
	140266135968000 -> 140265077014640
	140265077014640 [label=AccumulateGrad]
	140265077015072 -> 140265077015216
	140266135967920 [label="trunk_output.block3.block3-4.f.a.1.weight
 (208)" fillcolor=lightblue]
	140266135967920 -> 140265077015072
	140265077015072 [label=AccumulateGrad]
	140265077015312 -> 140265077015216
	140266135968080 [label="trunk_output.block3.block3-4.f.a.1.bias
 (208)" fillcolor=lightblue]
	140266135968080 -> 140265077015312
	140265077015312 [label=AccumulateGrad]
	140265077015408 -> 140265077015648
	140266135968560 [label="trunk_output.block3.block3-4.f.b.0.weight
 (208, 8, 3, 3)" fillcolor=lightblue]
	140266135968560 -> 140265077015408
	140265077015408 [label=AccumulateGrad]
	140265077015792 -> 140265077015840
	140266135968480 [label="trunk_output.block3.block3-4.f.b.1.weight
 (208)" fillcolor=lightblue]
	140266135968480 -> 140265077015792
	140265077015792 [label=AccumulateGrad]
	140265077016032 -> 140265077015840
	140266135968640 [label="trunk_output.block3.block3-4.f.b.1.bias
 (208)" fillcolor=lightblue]
	140266135968640 -> 140265077016032
	140265077016032 [label=AccumulateGrad]
	140265077016320 -> 140265077016752
	140266135969040 [label="trunk_output.block3.block3-4.f.se.fc1.weight
 (52, 208, 1, 1)" fillcolor=lightblue]
	140266135969040 -> 140265077016320
	140265077016320 [label=AccumulateGrad]
	140265077016368 -> 140265077016752
	140266135969120 [label="trunk_output.block3.block3-4.f.se.fc1.bias
 (52)" fillcolor=lightblue]
	140266135969120 -> 140265077016368
	140265077016368 [label=AccumulateGrad]
	140265077016608 -> 140265077017376
	140266135969280 [label="trunk_output.block3.block3-4.f.se.fc2.weight
 (208, 52, 1, 1)" fillcolor=lightblue]
	140266135969280 -> 140265077016608
	140265077016608 [label=AccumulateGrad]
	140265077017904 -> 140265077017376
	140266135969360 [label="trunk_output.block3.block3-4.f.se.fc2.bias
 (208)" fillcolor=lightblue]
	140266135969360 -> 140265077017904
	140265077017904 [label=AccumulateGrad]
	140265077017952 -> 140265077044896
	140265077044080 -> 140265077152736
	140266135969600 [label="trunk_output.block3.block3-4.f.c.0.weight
 (208, 208, 1, 1)" fillcolor=lightblue]
	140266135969600 -> 140265077044080
	140265077044080 [label=AccumulateGrad]
	140265077152688 -> 140265077152928
	140266135969520 [label="trunk_output.block3.block3-4.f.c.1.weight
 (208)" fillcolor=lightblue]
	140266135969520 -> 140265077152688
	140265077152688 [label=AccumulateGrad]
	140265077047008 -> 140265077152928
	140266135969680 [label="trunk_output.block3.block3-4.f.c.1.bias
 (208)" fillcolor=lightblue]
	140266135969680 -> 140265077047008
	140265077047008 [label=AccumulateGrad]
	140265077153264 -> 140265077153312
	140265077153264 [label=NativeBatchNormBackward0]
	140265077045472 -> 140265077153264
	140265077045472 [label=ConvolutionBackward0]
	140265077018336 -> 140265077045472
	140265077018336 [label=MulBackward0]
	140265077015984 -> 140265077018336
	140265077015984 [label=SigmoidBackward0]
	140265077015456 -> 140265077015984
	140265077015456 [label=ConvolutionBackward0]
	140265077014880 -> 140265077015456
	140265077014880 [label=ReluBackward0]
	140265077014832 -> 140265077014880
	140265077014832 [label=ConvolutionBackward0]
	140265076985616 -> 140265077014832
	140265076985616 [label=MeanBackward1]
	140265077016224 -> 140265076985616
	140265077016224 [label=ReluBackward0]
	140265076985184 -> 140265077016224
	140265076985184 [label=NativeBatchNormBackward0]
	140265076985088 -> 140265076985184
	140265076985088 [label=ConvolutionBackward0]
	140265076984800 -> 140265076985088
	140265076984800 [label=ReluBackward0]
	140265076984560 -> 140265076984800
	140265076984560 [label=NativeBatchNormBackward0]
	140265076984368 -> 140265076984560
	140265076984368 [label=ConvolutionBackward0]
	140265077153120 -> 140265076984368
	140265076984080 -> 140265076984368
	140266136089040 [label="trunk_output.block3.block3-5.f.a.0.weight
 (208, 208, 1, 1)" fillcolor=lightblue]
	140266136089040 -> 140265076984080
	140265076984080 [label=AccumulateGrad]
	140265076984416 -> 140265076984560
	140266136088960 [label="trunk_output.block3.block3-5.f.a.1.weight
 (208)" fillcolor=lightblue]
	140266136088960 -> 140265076984416
	140265076984416 [label=AccumulateGrad]
	140265076984752 -> 140265076984560
	140266136089120 [label="trunk_output.block3.block3-5.f.a.1.bias
 (208)" fillcolor=lightblue]
	140266136089120 -> 140265076984752
	140265076984752 [label=AccumulateGrad]
	140265076984944 -> 140265076985088
	140266136089600 [label="trunk_output.block3.block3-5.f.b.0.weight
 (208, 8, 3, 3)" fillcolor=lightblue]
	140266136089600 -> 140265076984944
	140265076984944 [label=AccumulateGrad]
	140265076985136 -> 140265076985184
	140266136089520 [label="trunk_output.block3.block3-5.f.b.1.weight
 (208)" fillcolor=lightblue]
	140266136089520 -> 140265076985136
	140265076985136 [label=AccumulateGrad]
	140265076985376 -> 140265076985184
	140266136089680 [label="trunk_output.block3.block3-5.f.b.1.bias
 (208)" fillcolor=lightblue]
	140266136089680 -> 140265076985376
	140265076985376 [label=AccumulateGrad]
	140265076985664 -> 140265077014832
	140266136090080 [label="trunk_output.block3.block3-5.f.se.fc1.weight
 (52, 208, 1, 1)" fillcolor=lightblue]
	140266136090080 -> 140265076985664
	140265076985664 [label=AccumulateGrad]
	140265076985712 -> 140265077014832
	140266136090160 [label="trunk_output.block3.block3-5.f.se.fc1.bias
 (52)" fillcolor=lightblue]
	140266136090160 -> 140265076985712
	140265076985712 [label=AccumulateGrad]
	140265077014688 -> 140265077015456
	140266136090320 [label="trunk_output.block3.block3-5.f.se.fc2.weight
 (208, 52, 1, 1)" fillcolor=lightblue]
	140266136090320 -> 140265077014688
	140265077014688 [label=AccumulateGrad]
	140265077016176 -> 140265077015456
	140266136090400 [label="trunk_output.block3.block3-5.f.se.fc2.bias
 (208)" fillcolor=lightblue]
	140266136090400 -> 140265077016176
	140265077016176 [label=AccumulateGrad]
	140265077016224 -> 140265077018336
	140265077017520 -> 140265077045472
	140266136090640 [label="trunk_output.block3.block3-5.f.c.0.weight
 (208, 208, 1, 1)" fillcolor=lightblue]
	140266136090640 -> 140265077017520
	140265077017520 [label=AccumulateGrad]
	140265077153072 -> 140265077153264
	140266136090560 [label="trunk_output.block3.block3-5.f.c.1.weight
 (208)" fillcolor=lightblue]
	140266136090560 -> 140265077153072
	140265077153072 [label=AccumulateGrad]
	140265077153024 -> 140265077153264
	140266136090720 [label="trunk_output.block3.block3-5.f.c.1.bias
 (208)" fillcolor=lightblue]
	140266136090720 -> 140265077153024
	140265077153024 [label=AccumulateGrad]
	140265077153648 -> 140265077174480
	140266136091120 [label="trunk_output.block4.block4-0.proj.0.weight
 (440, 208, 1, 1)" fillcolor=lightblue]
	140266136091120 -> 140265077153648
	140265077153648 [label=AccumulateGrad]
	140265077174528 -> 140265077174624
	140266136091040 [label="trunk_output.block4.block4-0.proj.1.weight
 (440)" fillcolor=lightblue]
	140266136091040 -> 140265077174528
	140265077174528 [label=AccumulateGrad]
	140265077174576 -> 140265077174624
	140266136091200 [label="trunk_output.block4.block4-0.proj.1.bias
 (440)" fillcolor=lightblue]
	140266136091200 -> 140265077174576
	140265077174576 [label=AccumulateGrad]
	140265077174768 -> 140265077174816
	140265077174768 [label=NativeBatchNormBackward0]
	140265077174432 -> 140265077174768
	140265077174432 [label=ConvolutionBackward0]
	140265077015264 -> 140265077174432
	140265077015264 [label=MulBackward0]
	140265077016416 -> 140265077015264
	140265077016416 [label=SigmoidBackward0]
	140265076985424 -> 140265077016416
	140265076985424 [label=ConvolutionBackward0]
	140265076984992 -> 140265076985424
	140265076984992 [label=ReluBackward0]
	140265076983984 -> 140265076984992
	140265076983984 [label=ConvolutionBackward0]
	140265076984176 -> 140265076983984
	140265076984176 [label=MeanBackward1]
	140265077015600 -> 140265076984176
	140265077015600 [label=ReluBackward0]
	140265076983456 -> 140265077015600
	140265076983456 [label=NativeBatchNormBackward0]
	140265076983264 -> 140265076983456
	140265076983264 [label=ConvolutionBackward0]
	140265076983072 -> 140265076983264
	140265076983072 [label=ReluBackward0]
	140265076982832 -> 140265076983072
	140265076982832 [label=NativeBatchNormBackward0]
	140265076982640 -> 140265076982832
	140265076982640 [label=ConvolutionBackward0]
	140265077174384 -> 140265076982640
	140265076982256 -> 140265076982640
	140266136091760 [label="trunk_output.block4.block4-0.f.a.0.weight
 (440, 208, 1, 1)" fillcolor=lightblue]
	140266136091760 -> 140265076982256
	140265076982256 [label=AccumulateGrad]
	140265076982688 -> 140265076982832
	140266136091680 [label="trunk_output.block4.block4-0.f.a.1.weight
 (440)" fillcolor=lightblue]
	140266136091680 -> 140265076982688
	140265076982688 [label=AccumulateGrad]
	140265076983024 -> 140265076982832
	140266136091840 [label="trunk_output.block4.block4-0.f.a.1.bias
 (440)" fillcolor=lightblue]
	140266136091840 -> 140265076983024
	140265076983024 [label=AccumulateGrad]
	140265076983120 -> 140265076983264
	140266136092320 [label="trunk_output.block4.block4-0.f.b.0.weight
 (440, 8, 3, 3)" fillcolor=lightblue]
	140266136092320 -> 140265076983120
	140265076983120 [label=AccumulateGrad]
	140265076983408 -> 140265076983456
	140266136092240 [label="trunk_output.block4.block4-0.f.b.1.weight
 (440)" fillcolor=lightblue]
	140266136092240 -> 140265076983408
	140265076983408 [label=AccumulateGrad]
	140265076983648 -> 140265076983456
	140266136092400 [label="trunk_output.block4.block4-0.f.b.1.bias
 (440)" fillcolor=lightblue]
	140266136092400 -> 140265076983648
	140265076983648 [label=AccumulateGrad]
	140265076984032 -> 140265076983984
	140266138333408 [label="trunk_output.block4.block4-0.f.se.fc1.weight
 (52, 440, 1, 1)" fillcolor=lightblue]
	140266138333408 -> 140265076984032
	140265076984032 [label=AccumulateGrad]
	140265076984224 -> 140265076983984
	140266138333488 [label="trunk_output.block4.block4-0.f.se.fc1.bias
 (52)" fillcolor=lightblue]
	140266138333488 -> 140265076984224
	140265076984224 [label=AccumulateGrad]
	140265076985040 -> 140265076985424
	140266138333648 [label="trunk_output.block4.block4-0.f.se.fc2.weight
 (440, 52, 1, 1)" fillcolor=lightblue]
	140266138333648 -> 140265076985040
	140265076985040 [label=AccumulateGrad]
	140265076985472 -> 140265076985424
	140266138333728 [label="trunk_output.block4.block4-0.f.se.fc2.bias
 (440)" fillcolor=lightblue]
	140266138333728 -> 140265076985472
	140265076985472 [label=AccumulateGrad]
	140265077015600 -> 140265077015264
	140265077017184 -> 140265077174432
	140266138333968 [label="trunk_output.block4.block4-0.f.c.0.weight
 (440, 440, 1, 1)" fillcolor=lightblue]
	140266138333968 -> 140265077017184
	140265077017184 [label=AccumulateGrad]
	140265077153504 -> 140265077174768
	140266138333888 [label="trunk_output.block4.block4-0.f.c.1.weight
 (440)" fillcolor=lightblue]
	140266138333888 -> 140265077153504
	140265077153504 [label=AccumulateGrad]
	140265077153696 -> 140265077174768
	140266138334048 [label="trunk_output.block4.block4-0.f.c.1.bias
 (440)" fillcolor=lightblue]
	140266138334048 -> 140265077153696
	140265077153696 [label=AccumulateGrad]
	140265077175104 -> 140265077175152
	140265077175104 [label=NativeBatchNormBackward0]
	140265077153456 -> 140265077175104
	140265077153456 [label=ConvolutionBackward0]
	140265076985760 -> 140265077153456
	140265076985760 [label=MulBackward0]
	140265076983600 -> 140265076985760
	140265076983600 [label=SigmoidBackward0]
	140265076983168 -> 140265076983600
	140265076983168 [label=ConvolutionBackward0]
	140265076982496 -> 140265076983168
	140265076982496 [label=ReluBackward0]
	140265076982208 -> 140265076982496
	140265076982208 [label=ConvolutionBackward0]
	140265076981920 -> 140265076982208
	140265076981920 [label=MeanBackward1]
	140265076983840 -> 140265076981920
	140265076983840 [label=ReluBackward0]
	140265076969232 -> 140265076983840
	140265076969232 [label=NativeBatchNormBackward0]
	140265076969136 -> 140265076969232
	140265076969136 [label=ConvolutionBackward0]
	140265076968752 -> 140265076969136
	140265076968752 [label=ReluBackward0]
	140265076968416 -> 140265076968752
	140265076968416 [label=NativeBatchNormBackward0]
	140265076968320 -> 140265076968416
	140265076968320 [label=ConvolutionBackward0]
	140265077175056 -> 140265076968320
	140265076968032 -> 140265076968320
	140266138334528 [label="trunk_output.block4.block4-1.f.a.0.weight
 (440, 440, 1, 1)" fillcolor=lightblue]
	140266138334528 -> 140265076968032
	140265076968032 [label=AccumulateGrad]
	140265076968368 -> 140265076968416
	140266138334448 [label="trunk_output.block4.block4-1.f.a.1.weight
 (440)" fillcolor=lightblue]
	140266138334448 -> 140265076968368
	140265076968368 [label=AccumulateGrad]
	140265076968608 -> 140265076968416
	140266138334608 [label="trunk_output.block4.block4-1.f.a.1.bias
 (440)" fillcolor=lightblue]
	140266138334608 -> 140265076968608
	140265076968608 [label=AccumulateGrad]
	140265076968800 -> 140265076969136
	140266138335088 [label="trunk_output.block4.block4-1.f.b.0.weight
 (440, 8, 3, 3)" fillcolor=lightblue]
	140266138335088 -> 140265076968800
	140265076968800 [label=AccumulateGrad]
	140265076969184 -> 140265076969232
	140266138335008 [label="trunk_output.block4.block4-1.f.b.1.weight
 (440)" fillcolor=lightblue]
	140266138335008 -> 140265076969184
	140265076969184 [label=AccumulateGrad]
	140265076969328 -> 140265076969232
	140266138335168 [label="trunk_output.block4.block4-1.f.b.1.bias
 (440)" fillcolor=lightblue]
	140266138335168 -> 140265076969328
	140265076969328 [label=AccumulateGrad]
	140265076981968 -> 140265076982208
	140266138335568 [label="trunk_output.block4.block4-1.f.se.fc1.weight
 (110, 440, 1, 1)" fillcolor=lightblue]
	140266138335568 -> 140265076981968
	140265076981968 [label=AccumulateGrad]
	140265076982016 -> 140265076982208
	140266138335648 [label="trunk_output.block4.block4-1.f.se.fc1.bias
 (110)" fillcolor=lightblue]
	140266138335648 -> 140265076982016
	140265076982016 [label=AccumulateGrad]
	140265076982304 -> 140265076983168
	140266138335808 [label="trunk_output.block4.block4-1.f.se.fc2.weight
 (440, 110, 1, 1)" fillcolor=lightblue]
	140266138335808 -> 140265076982304
	140265076982304 [label=AccumulateGrad]
	140265076983792 -> 140265076983168
	140266138335888 [label="trunk_output.block4.block4-1.f.se.fc2.bias
 (440)" fillcolor=lightblue]
	140266138335888 -> 140265076983792
	140265076983792 [label=AccumulateGrad]
	140265076983840 -> 140265076985760
	140265076985328 -> 140265077153456
	140266138336128 [label="trunk_output.block4.block4-1.f.c.0.weight
 (440, 440, 1, 1)" fillcolor=lightblue]
	140266138336128 -> 140265076985328
	140265076985328 [label=AccumulateGrad]
	140265077174912 -> 140265077175104
	140266138336048 [label="trunk_output.block4.block4-1.f.c.1.weight
 (440)" fillcolor=lightblue]
	140266138336048 -> 140265077174912
	140265077174912 [label=AccumulateGrad]
	140265077174864 -> 140265077175104
	140266138336208 [label="trunk_output.block4.block4-1.f.c.1.bias
 (440)" fillcolor=lightblue]
	140266138336208 -> 140265077174864
	140265077174864 [label=AccumulateGrad]
	140265077175536 -> 140265077175584
	140265077175536 [label=NativeBatchNormBackward0]
	140265077018480 -> 140265077175536
	140265077018480 [label=ConvolutionBackward0]
	140265076984608 -> 140265077018480
	140265076984608 [label=MulBackward0]
	140265076981872 -> 140265076984608
	140265076981872 [label=SigmoidBackward0]
	140265076968944 -> 140265076981872
	140265076968944 [label=ConvolutionBackward0]
	140265076968272 -> 140265076968944
	140265076968272 [label=ReluBackward0]
	140265076968224 -> 140265076968272
	140265076968224 [label=ConvolutionBackward0]
	140265076967648 -> 140265076968224
	140265076967648 [label=MeanBackward1]
	140265076982160 -> 140265076967648
	140265076982160 [label=ReluBackward0]
	140265076967312 -> 140265076982160
	140265076967312 [label=NativeBatchNormBackward0]
	140265076967216 -> 140265076967312
	140265076967216 [label=ConvolutionBackward0]
	140265076966832 -> 140265076967216
	140265076966832 [label=ReluBackward0]
	140265076966496 -> 140265076966832
	140265076966496 [label=NativeBatchNormBackward0]
	140265076966400 -> 140265076966496
	140265076966400 [label=ConvolutionBackward0]
	140265077175392 -> 140265076966400
	140265076966112 -> 140265076966400
	140266138336688 [label="trunk_output.block4.block4-2.f.a.0.weight
 (440, 440, 1, 1)" fillcolor=lightblue]
	140266138336688 -> 140265076966112
	140265076966112 [label=AccumulateGrad]
	140265076966448 -> 140265076966496
	140266138336608 [label="trunk_output.block4.block4-2.f.a.1.weight
 (440)" fillcolor=lightblue]
	140266138336608 -> 140265076966448
	140265076966448 [label=AccumulateGrad]
	140265076966688 -> 140265076966496
	140266138336768 [label="trunk_output.block4.block4-2.f.a.1.bias
 (440)" fillcolor=lightblue]
	140266138336768 -> 140265076966688
	140265076966688 [label=AccumulateGrad]
	140265076966880 -> 140265076967216
	140266138456128 [label="trunk_output.block4.block4-2.f.b.0.weight
 (440, 8, 3, 3)" fillcolor=lightblue]
	140266138456128 -> 140265076966880
	140265076966880 [label=AccumulateGrad]
	140265076967264 -> 140265076967312
	140266138337168 [label="trunk_output.block4.block4-2.f.b.1.weight
 (440)" fillcolor=lightblue]
	140266138337168 -> 140265076967264
	140265076967264 [label=AccumulateGrad]
	140265076967408 -> 140265076967312
	140266138456208 [label="trunk_output.block4.block4-2.f.b.1.bias
 (440)" fillcolor=lightblue]
	140266138456208 -> 140265076967408
	140265076967408 [label=AccumulateGrad]
	140265076967792 -> 140265076968224
	140266138456608 [label="trunk_output.block4.block4-2.f.se.fc1.weight
 (110, 440, 1, 1)" fillcolor=lightblue]
	140266138456608 -> 140265076967792
	140265076967792 [label=AccumulateGrad]
	140265076967840 -> 140265076968224
	140266138456688 [label="trunk_output.block4.block4-2.f.se.fc1.bias
 (110)" fillcolor=lightblue]
	140266138456688 -> 140265076967840
	140265076967840 [label=AccumulateGrad]
	140265076968176 -> 140265076968944
	140266138456848 [label="trunk_output.block4.block4-2.f.se.fc2.weight
 (440, 110, 1, 1)" fillcolor=lightblue]
	140266138456848 -> 140265076968176
	140265076968176 [label=AccumulateGrad]
	140265076969376 -> 140265076968944
	140266138456928 [label="trunk_output.block4.block4-2.f.se.fc2.bias
 (440)" fillcolor=lightblue]
	140266138456928 -> 140265076969376
	140265076969376 [label=AccumulateGrad]
	140265076982160 -> 140265076984608
	140265076983216 -> 140265077018480
	140266138457168 [label="trunk_output.block4.block4-2.f.c.0.weight
 (440, 440, 1, 1)" fillcolor=lightblue]
	140266138457168 -> 140265076983216
	140265076983216 [label=AccumulateGrad]
	140265077175344 -> 140265077175536
	140266138457088 [label="trunk_output.block4.block4-2.f.c.1.weight
 (440)" fillcolor=lightblue]
	140266138457088 -> 140265077175344
	140265077175344 [label=AccumulateGrad]
	140265077175200 -> 140265077175536
	140266138457248 [label="trunk_output.block4.block4-2.f.c.1.bias
 (440)" fillcolor=lightblue]
	140266138457248 -> 140265077175200
	140265077175200 [label=AccumulateGrad]
	140265077175968 -> 140265077176016
	140265077175968 [label=NativeBatchNormBackward0]
	140265077175776 -> 140265077175968
	140265077175776 [label=ConvolutionBackward0]
	140265076969280 -> 140265077175776
	140265076969280 [label=MulBackward0]
	140265076967360 -> 140265076969280
	140265076967360 [label=SigmoidBackward0]
	140265076967024 -> 140265076967360
	140265076967024 [label=ConvolutionBackward0]
	140265076966352 -> 140265076967024
	140265076966352 [label=ReluBackward0]
	140265076966208 -> 140265076966352
	140265076966208 [label=ConvolutionBackward0]
	140265076965824 -> 140265076966208
	140265076965824 [label=MeanBackward1]
	140265076967600 -> 140265076965824
	140265076967600 [label=ReluBackward0]
	140265076965488 -> 140265076967600
	140265076965488 [label=NativeBatchNormBackward0]
	140265076965680 -> 140265076965488
	140265076965680 [label=ConvolutionBackward0]
	140265076936176 -> 140265076965680
	140265076936176 [label=ReluBackward0]
	140265076936032 -> 140265076936176
	140265076936032 [label=NativeBatchNormBackward0]
	140265076935840 -> 140265076936032
	140265076935840 [label=ConvolutionBackward0]
	140265077175920 -> 140265076935840
	140265076935456 -> 140265076935840
	140266138457728 [label="trunk_output.block4.block4-3.f.a.0.weight
 (440, 440, 1, 1)" fillcolor=lightblue]
	140266138457728 -> 140265076935456
	140265076935456 [label=AccumulateGrad]
	140265076935984 -> 140265076936032
	140266138457648 [label="trunk_output.block4.block4-3.f.a.1.weight
 (440)" fillcolor=lightblue]
	140266138457648 -> 140265076935984
	140265076935984 [label=AccumulateGrad]
	140265076936128 -> 140265076936032
	140266138457808 [label="trunk_output.block4.block4-3.f.a.1.bias
 (440)" fillcolor=lightblue]
	140266138457808 -> 140265076936128
	140265076936128 [label=AccumulateGrad]
	140265076936224 -> 140265076965680
	140266138458288 [label="trunk_output.block4.block4-3.f.b.0.weight
 (440, 8, 3, 3)" fillcolor=lightblue]
	140266138458288 -> 140265076936224
	140265076936224 [label=AccumulateGrad]
	140265076936560 -> 140265076965488
	140266138458208 [label="trunk_output.block4.block4-3.f.b.1.weight
 (440)" fillcolor=lightblue]
	140266138458208 -> 140265076936560
	140265076936560 [label=AccumulateGrad]
	140265076936608 -> 140265076965488
	140266138458368 [label="trunk_output.block4.block4-3.f.b.1.bias
 (440)" fillcolor=lightblue]
	140266138458368 -> 140265076936608
	140265076936608 [label=AccumulateGrad]
	140265076965872 -> 140265076966208
	140266138458768 [label="trunk_output.block4.block4-3.f.se.fc1.weight
 (110, 440, 1, 1)" fillcolor=lightblue]
	140266138458768 -> 140265076965872
	140265076965872 [label=AccumulateGrad]
	140265076965920 -> 140265076966208
	140266138458848 [label="trunk_output.block4.block4-3.f.se.fc1.bias
 (110)" fillcolor=lightblue]
	140266138458848 -> 140265076965920
	140265076965920 [label=AccumulateGrad]
	140265076966160 -> 140265076967024
	140266138459008 [label="trunk_output.block4.block4-3.f.se.fc2.weight
 (440, 110, 1, 1)" fillcolor=lightblue]
	140266138459008 -> 140265076966160
	140265076966160 [label=AccumulateGrad]
	140265076967456 -> 140265076967024
	140266138459088 [label="trunk_output.block4.block4-3.f.se.fc2.bias
 (440)" fillcolor=lightblue]
	140266138459088 -> 140265076967456
	140265076967456 [label=AccumulateGrad]
	140265076967600 -> 140265076969280
	140265076968992 -> 140265077175776
	140266138459328 [label="trunk_output.block4.block4-3.f.c.0.weight
 (440, 440, 1, 1)" fillcolor=lightblue]
	140266138459328 -> 140265076968992
	140265076968992 [label=AccumulateGrad]
	140265077175728 -> 140265077175968
	140266138459248 [label="trunk_output.block4.block4-3.f.c.1.weight
 (440)" fillcolor=lightblue]
	140266138459248 -> 140265077175728
	140265077175728 [label=AccumulateGrad]
	140265076984128 -> 140265077175968
	140266138459408 [label="trunk_output.block4.block4-3.f.c.1.bias
 (440)" fillcolor=lightblue]
	140266138459408 -> 140265076984128
	140265076984128 [label=AccumulateGrad]
	140265077176304 -> 140265077176352
	140265077176304 [label=NativeBatchNormBackward0]
	140265076982880 -> 140265077176304
	140265076982880 [label=ConvolutionBackward0]
	140265076967984 -> 140265076982880
	140265076967984 [label=MulBackward0]
	140265076965536 -> 140265076967984
	140265076965536 [label=SigmoidBackward0]
	140265076965728 -> 140265076965536
	140265076965728 [label=ConvolutionBackward0]
	140265076935792 -> 140265076965728
	140265076935792 [label=ReluBackward0]
	140265076935648 -> 140265076935792
	140265076935648 [label=ConvolutionBackward0]
	140265076935168 -> 140265076935648
	140265076935168 [label=MeanBackward1]
	140265076965776 -> 140265076935168
	140265076965776 [label=ReluBackward0]
	140265076934832 -> 140265076965776
	140265076934832 [label=NativeBatchNormBackward0]
	140265076934640 -> 140265076934832
	140265076934640 [label=ConvolutionBackward0]
	140265076934256 -> 140265076934640
	140265076934256 [label=ReluBackward0]
	140265076934016 -> 140265076934256
	140265076934016 [label=NativeBatchNormBackward0]
	140265076933920 -> 140265076934016
	140265076933920 [label=ConvolutionBackward0]
	140265077176160 -> 140265076933920
	140265076933632 -> 140265076933920
	140266138459888 [label="trunk_output.block4.block4-4.f.a.0.weight
 (440, 440, 1, 1)" fillcolor=lightblue]
	140266138459888 -> 140265076933632
	140265076933632 [label=AccumulateGrad]
	140265076933968 -> 140265076934016
	140266138459808 [label="trunk_output.block4.block4-4.f.a.1.weight
 (440)" fillcolor=lightblue]
	140266138459808 -> 140265076933968
	140265076933968 [label=AccumulateGrad]
	140265076934208 -> 140265076934016
	140266138460048 [label="trunk_output.block4.block4-4.f.a.1.bias
 (440)" fillcolor=lightblue]
	140266138460048 -> 140265076934208
	140265076934208 [label=AccumulateGrad]
	140265076934304 -> 140265076934640
	140266145472976 [label="trunk_output.block4.block4-4.f.b.0.weight
 (440, 8, 3, 3)" fillcolor=lightblue]
	140266145472976 -> 140265076934304
	140265076934304 [label=AccumulateGrad]
	140265076934688 -> 140265076934832
	140266145472896 [label="trunk_output.block4.block4-4.f.b.1.weight
 (440)" fillcolor=lightblue]
	140266145472896 -> 140265076934688
	140265076934688 [label=AccumulateGrad]
	140265076935024 -> 140265076934832
	140266145473056 [label="trunk_output.block4.block4-4.f.b.1.bias
 (440)" fillcolor=lightblue]
	140266145473056 -> 140265076935024
	140265076935024 [label=AccumulateGrad]
	140265076935216 -> 140265076935648
	140266145473456 [label="trunk_output.block4.block4-4.f.se.fc1.weight
 (110, 440, 1, 1)" fillcolor=lightblue]
	140266145473456 -> 140265076935216
	140265076935216 [label=AccumulateGrad]
	140265076935264 -> 140265076935648
	140266145473536 [label="trunk_output.block4.block4-4.f.se.fc1.bias
 (110)" fillcolor=lightblue]
	140266145473536 -> 140265076935264
	140265076935264 [label=AccumulateGrad]
	140265076935600 -> 140265076965728
	140266145473696 [label="trunk_output.block4.block4-4.f.se.fc2.weight
 (440, 110, 1, 1)" fillcolor=lightblue]
	140266145473696 -> 140265076935600
	140265076935600 [label=AccumulateGrad]
	140265076936416 -> 140265076965728
	140266145473776 [label="trunk_output.block4.block4-4.f.se.fc2.bias
 (440)" fillcolor=lightblue]
	140266145473776 -> 140265076936416
	140265076936416 [label=AccumulateGrad]
	140265076965776 -> 140265076967984
	140265076967072 -> 140265076982880
	140266145474016 [label="trunk_output.block4.block4-4.f.c.0.weight
 (440, 440, 1, 1)" fillcolor=lightblue]
	140266145474016 -> 140265076967072
	140265076967072 [label=AccumulateGrad]
	140265077176112 -> 140265077176304
	140266145473936 [label="trunk_output.block4.block4-4.f.c.1.weight
 (440)" fillcolor=lightblue]
	140266145473936 -> 140265077176112
	140265077176112 [label=AccumulateGrad]
	140265077176064 -> 140265077176304
	140266145474096 [label="trunk_output.block4.block4-4.f.c.1.bias
 (440)" fillcolor=lightblue]
	140266145474096 -> 140265077176064
	140265077176064 [label=AccumulateGrad]
	140265077176736 -> 140265077176880
	140265077176736 [label=NativeBatchNormBackward0]
	140265077176544 -> 140265077176736
	140265077176544 [label=ConvolutionBackward0]
	140265076966064 -> 140265077176544
	140265076966064 [label=MulBackward0]
	140265076934880 -> 140265076966064
	140265076934880 [label=SigmoidBackward0]
	140265076934448 -> 140265076934880
	140265076934448 [label=ConvolutionBackward0]
	140265076933872 -> 140265076934448
	140265076933872 [label=ReluBackward0]
	140265076933728 -> 140265076933872
	140265076933728 [label=ConvolutionBackward0]
	140265076933344 -> 140265076933728
	140265076933344 [label=MeanBackward1]
	140265076935120 -> 140265076933344
	140265076935120 [label=ReluBackward0]
	140265076932912 -> 140265076935120
	140265076932912 [label=NativeBatchNormBackward0]
	140265076932720 -> 140265076932912
	140265076932720 [label=ConvolutionBackward0]
	140264505368432 -> 140265076932720
	140264505368432 [label=ReluBackward0]
	140264505368096 -> 140264505368432
	140264505368096 [label=NativeBatchNormBackward0]
	140264505367904 -> 140264505368096
	140264505367904 [label=ConvolutionBackward0]
	140265077176688 -> 140264505367904
	140264505367616 -> 140264505367904
	140266145474576 [label="trunk_output.block4.block4-5.f.a.0.weight
 (440, 440, 1, 1)" fillcolor=lightblue]
	140266145474576 -> 140264505367616
	140264505367616 [label=AccumulateGrad]
	140264505368048 -> 140264505368096
	140266145474496 [label="trunk_output.block4.block4-5.f.a.1.weight
 (440)" fillcolor=lightblue]
	140266145474496 -> 140264505368048
	140264505368048 [label=AccumulateGrad]
	140264505368288 -> 140264505368096
	140266145474656 [label="trunk_output.block4.block4-5.f.a.1.bias
 (440)" fillcolor=lightblue]
	140266145474656 -> 140264505368288
	140264505368288 [label=AccumulateGrad]
	140264505368480 -> 140265076932720
	140266145475136 [label="trunk_output.block4.block4-5.f.b.0.weight
 (440, 8, 3, 3)" fillcolor=lightblue]
	140266145475136 -> 140264505368480
	140264505368480 [label=AccumulateGrad]
	140265076932768 -> 140265076932912
	140266145475056 [label="trunk_output.block4.block4-5.f.b.1.weight
 (440)" fillcolor=lightblue]
	140266145475056 -> 140265076932768
	140265076932768 [label=AccumulateGrad]
	140265076933104 -> 140265076932912
	140266145475216 [label="trunk_output.block4.block4-5.f.b.1.bias
 (440)" fillcolor=lightblue]
	140266145475216 -> 140265076933104
	140265076933104 [label=AccumulateGrad]
	140265076933488 -> 140265076933728
	140266145475616 [label="trunk_output.block4.block4-5.f.se.fc1.weight
 (110, 440, 1, 1)" fillcolor=lightblue]
	140266145475616 -> 140265076933488
	140265076933488 [label=AccumulateGrad]
	140265076933536 -> 140265076933728
	140266145475696 [label="trunk_output.block4.block4-5.f.se.fc1.bias
 (110)" fillcolor=lightblue]
	140266145475696 -> 140265076933536
	140265076933536 [label=AccumulateGrad]
	140265076933680 -> 140265076934448
	140266145475856 [label="trunk_output.block4.block4-5.f.se.fc2.weight
 (440, 110, 1, 1)" fillcolor=lightblue]
	140266145475856 -> 140265076933680
	140265076933680 [label=AccumulateGrad]
	140265076935072 -> 140265076934448
	140266145475936 [label="trunk_output.block4.block4-5.f.se.fc2.bias
 (440)" fillcolor=lightblue]
	140266145475936 -> 140265076935072
	140265076935072 [label=AccumulateGrad]
	140265076935120 -> 140265076966064
	140265076936368 -> 140265077176544
	140266145476176 [label="trunk_output.block4.block4-5.f.c.0.weight
 (440, 440, 1, 1)" fillcolor=lightblue]
	140266145476176 -> 140265076936368
	140265076936368 [label=AccumulateGrad]
	140265077176496 -> 140265077176736
	140266145476096 [label="trunk_output.block4.block4-5.f.c.1.weight
 (440)" fillcolor=lightblue]
	140266145476096 -> 140265077176496
	140265077176496 [label=AccumulateGrad]
	140265076968560 -> 140265077176736
	140266145476256 [label="trunk_output.block4.block4-5.f.c.1.bias
 (440)" fillcolor=lightblue]
	140266145476256 -> 140265076968560
	140265076968560 [label=AccumulateGrad]
	140265077177936 -> 140265077177984
	140265077177936 [label=TBackward0]
	140265077176928 -> 140265077177936
	140266136091440 [label="fc.weight
 (1000, 440)" fillcolor=lightblue]
	140266136091440 -> 140265077176928
	140265077176928 [label=AccumulateGrad]
	140265077177984 -> 140265077025744
}
