digraph {
	graph [size="178.35,178.35"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140498052392496 [label="
 (1, 1000)" fillcolor=darkolivegreen1]
	140498052439152 [label=AddmmBackward0]
	140498052439104 -> 140498052439152
	140497794041312 [label="fc.bias
 (1000)" fillcolor=lightblue]
	140497794041312 -> 140498052439104
	140498052439104 [label=AccumulateGrad]
	140498052439200 -> 140498052439152
	140498052439200 [label=MeanBackward1]
	140498052439440 -> 140498052439200
	140498052439440 [label=ReluBackward0]
	140498052438864 -> 140498052439440
	140498052438864 [label=NativeBatchNormBackward0]
	140498052438720 -> 140498052438864
	140498052438720 [label=ConvolutionBackward0]
	140498052438384 -> 140498052438720
	140498052438384 [label=ViewBackward0]
	140498052438240 -> 140498052438384
	140498052438240 [label=CloneBackward0]
	140498052438096 -> 140498052438240
	140498052438096 [label=TransposeBackward0]
	140498052437808 -> 140498052438096
	140498052437808 [label=ViewBackward0]
	140498052437760 -> 140498052437808
	140498052437760 [label=CatBackward0]
	140498052437616 -> 140498052437760
	140498052437616 [label=SplitBackward0]
	140498052437376 -> 140498052437616
	140498052437376 [label=ViewBackward0]
	140498052437184 -> 140498052437376
	140498052437184 [label=CloneBackward0]
	140498052437136 -> 140498052437184
	140498052437136 [label=TransposeBackward0]
	140498052436992 -> 140498052437136
	140498052436992 [label=ViewBackward0]
	140498052436704 -> 140498052436992
	140498052436704 [label=CatBackward0]
	140498052436656 -> 140498052436704
	140498052436656 [label=SplitBackward0]
	140498052436416 -> 140498052436656
	140498052436416 [label=ViewBackward0]
	140498052436272 -> 140498052436416
	140498052436272 [label=CloneBackward0]
	140498052436080 -> 140498052436272
	140498052436080 [label=TransposeBackward0]
	140498052436032 -> 140498052436080
	140498052436032 [label=ViewBackward0]
	140498052436464 -> 140498052436032
	140498052436464 [label=CatBackward0]
	140498052423248 -> 140498052436464
	140498052423248 [label=SplitBackward0]
	140498052423008 -> 140498052423248
	140498052423008 [label=ViewBackward0]
	140498052422960 -> 140498052423008
	140498052422960 [label=CloneBackward0]
	140498052422816 -> 140498052422960
	140498052422816 [label=TransposeBackward0]
	140498052422624 -> 140498052422816
	140498052422624 [label=ViewBackward0]
	140498052422576 -> 140498052422624
	140498052422576 [label=CatBackward0]
	140498052422432 -> 140498052422576
	140498052422432 [label=ReluBackward0]
	140498052422192 -> 140498052422432
	140498052422192 [label=NativeBatchNormBackward0]
	140498052421904 -> 140498052422192
	140498052421904 [label=ConvolutionBackward0]
	140498052421712 -> 140498052421904
	140498052421712 [label=NativeBatchNormBackward0]
	140498052421568 -> 140498052421712
	140498052421568 [label=ConvolutionBackward0]
	140498052421232 -> 140498052421568
	140498052421232 [label=ViewBackward0]
	140498052420992 -> 140498052421232
	140498052420992 [label=CloneBackward0]
	140498052420848 -> 140498052420992
	140498052420848 [label=TransposeBackward0]
	140498052420560 -> 140498052420848
	140498052420560 [label=ViewBackward0]
	140498052420512 -> 140498052420560
	140498052420512 [label=CatBackward0]
	140498052420464 -> 140498052420512
	140498052420464 [label=SplitBackward0]
	140498052420224 -> 140498052420464
	140498052420224 [label=ViewBackward0]
	140498052419936 -> 140498052420224
	140498052419936 [label=CloneBackward0]
	140498052419888 -> 140498052419936
	140498052419888 [label=TransposeBackward0]
	140498052419744 -> 140498052419888
	140498052419744 [label=ViewBackward0]
	140498052419648 -> 140498052419744
	140498052419648 [label=CatBackward0]
	140498052398864 -> 140498052419648
	140498052398864 [label=SplitBackward0]
	140498052398720 -> 140498052398864
	140498052398720 [label=ViewBackward0]
	140498052398576 -> 140498052398720
	140498052398576 [label=CloneBackward0]
	140498052398288 -> 140498052398576
	140498052398288 [label=TransposeBackward0]
	140498052398240 -> 140498052398288
	140498052398240 [label=ViewBackward0]
	140498052398096 -> 140498052398240
	140498052398096 [label=CatBackward0]
	140498052397808 -> 140498052398096
	140498052397808 [label=SplitBackward0]
	140498052397664 -> 140498052397808
	140498052397664 [label=ViewBackward0]
	140498052397616 -> 140498052397664
	140498052397616 [label=CloneBackward0]
	140498052397472 -> 140498052397616
	140498052397472 [label=TransposeBackward0]
	140498052397184 -> 140498052397472
	140498052397184 [label=ViewBackward0]
	140498052397136 -> 140498052397184
	140498052397136 [label=CatBackward0]
	140498052396992 -> 140498052397136
	140498052396992 [label=SplitBackward0]
	140498052396752 -> 140498052396992
	140498052396752 [label=ViewBackward0]
	140498052396560 -> 140498052396752
	140498052396560 [label=CloneBackward0]
	140498052396512 -> 140498052396560
	140498052396512 [label=TransposeBackward0]
	140498052396368 -> 140498052396512
	140498052396368 [label=ViewBackward0]
	140498052396080 -> 140498052396368
	140498052396080 [label=CatBackward0]
	140498052396032 -> 140498052396080
	140498052396032 [label=SplitBackward0]
	140498052395792 -> 140498052396032
	140498052395792 [label=ViewBackward0]
	140498052395648 -> 140498052395792
	140498052395648 [label=CloneBackward0]
	140498052395456 -> 140498052395648
	140498052395456 [label=TransposeBackward0]
	140498052395408 -> 140498052395456
	140498052395408 [label=ViewBackward0]
	140498052395264 -> 140498052395408
	140498052395264 [label=CatBackward0]
	140498052395168 -> 140498052395264
	140498052395168 [label=SplitBackward0]
	140498052374192 -> 140498052395168
	140498052374192 [label=ViewBackward0]
	140498052374144 -> 140498052374192
	140498052374144 [label=CloneBackward0]
	140498052374000 -> 140498052374144
	140498052374000 [label=TransposeBackward0]
	140498052373808 -> 140498052374000
	140498052373808 [label=ViewBackward0]
	140498052373760 -> 140498052373808
	140498052373760 [label=CatBackward0]
	140498052373616 -> 140498052373760
	140498052373616 [label=SplitBackward0]
	140498052373376 -> 140498052373616
	140498052373376 [label=ViewBackward0]
	140498052373088 -> 140498052373376
	140498052373088 [label=CloneBackward0]
	140498052373040 -> 140498052373088
	140498052373040 [label=TransposeBackward0]
	140498052372896 -> 140498052373040
	140498052372896 [label=ViewBackward0]
	140498052372704 -> 140498052372896
	140498052372704 [label=CatBackward0]
	140498052372656 -> 140498052372704
	140498052372656 [label=ReluBackward0]
	140498052372416 -> 140498052372656
	140498052372416 [label=NativeBatchNormBackward0]
	140498052372272 -> 140498052372416
	140498052372272 [label=ConvolutionBackward0]
	140498052371936 -> 140498052372272
	140498052371936 [label=NativeBatchNormBackward0]
	140498052371696 -> 140498052371936
	140498052371696 [label=ConvolutionBackward0]
	140498052371360 -> 140498052371696
	140498052371360 [label=ViewBackward0]
	140498052371120 -> 140498052371360
	140498052371120 [label=CloneBackward0]
	140498052371072 -> 140498052371120
	140498052371072 [label=TransposeBackward0]
	140498052370928 -> 140498052371072
	140498052370928 [label=ViewBackward0]
	140498052370640 -> 140498052370928
	140498052370640 [label=CatBackward0]
	140498052370592 -> 140498052370640
	140498052370592 [label=SplitBackward0]
	140498052370544 -> 140498052370592
	140498052370544 [label=ViewBackward0]
	140498052353856 -> 140498052370544
	140498052353856 [label=CloneBackward0]
	140498052353568 -> 140498052353856
	140498052353568 [label=TransposeBackward0]
	140498052353520 -> 140498052353568
	140498052353520 [label=ViewBackward0]
	140498052353376 -> 140498052353520
	140498052353376 [label=CatBackward0]
	140498052353088 -> 140498052353376
	140498052353088 [label=SplitBackward0]
	140498052352944 -> 140498052353088
	140498052352944 [label=ViewBackward0]
	140498052352896 -> 140498052352944
	140498052352896 [label=CloneBackward0]
	140498052352752 -> 140498052352896
	140498052352752 [label=TransposeBackward0]
	140498052352464 -> 140498052352752
	140498052352464 [label=ViewBackward0]
	140498052352416 -> 140498052352464
	140498052352416 [label=CatBackward0]
	140498052352272 -> 140498052352416
	140498052352272 [label=SplitBackward0]
	140498052352032 -> 140498052352272
	140498052352032 [label=ViewBackward0]
	140498052351840 -> 140498052352032
	140498052351840 [label=CloneBackward0]
	140498052351792 -> 140498052351840
	140498052351792 [label=TransposeBackward0]
	140498052351648 -> 140498052351792
	140498052351648 [label=ViewBackward0]
	140498052351360 -> 140498052351648
	140498052351360 [label=CatBackward0]
	140498052351312 -> 140498052351360
	140498052351312 [label=ReluBackward0]
	140498052351072 -> 140498052351312
	140498052351072 [label=NativeBatchNormBackward0]
	140498052350928 -> 140498052351072
	140498052350928 [label=ConvolutionBackward0]
	140498052350688 -> 140498052350928
	140498052350688 [label=NativeBatchNormBackward0]
	140498052350448 -> 140498052350688
	140498052350448 [label=ConvolutionBackward0]
	140498052350016 -> 140498052350448
	140498052350016 [label=MaxPool2DWithIndicesBackward0]
	140498052350064 -> 140498052350016
	140498052350064 [label=ReluBackward0]
	140498052329184 -> 140498052350064
	140498052329184 [label=NativeBatchNormBackward0]
	140498052329136 -> 140498052329184
	140498052329136 [label=ConvolutionBackward0]
	140498052328800 -> 140498052329136
	140498325915744 [label="conv1.0.weight
 (24, 3, 3, 3)" fillcolor=lightblue]
	140498325915744 -> 140498052328800
	140498052328800 [label=AccumulateGrad]
	140498052329088 -> 140498052329184
	140498325915664 [label="conv1.1.weight
 (24)" fillcolor=lightblue]
	140498325915664 -> 140498052329088
	140498052329088 [label=AccumulateGrad]
	140498052329424 -> 140498052329184
	140498325915824 [label="conv1.1.bias
 (24)" fillcolor=lightblue]
	140498325915824 -> 140498052329424
	140498052329424 [label=AccumulateGrad]
	140498052350208 -> 140498052350448
	140498325916304 [label="stage2.0.branch1.0.weight
 (24, 1, 3, 3)" fillcolor=lightblue]
	140498325916304 -> 140498052350208
	140498052350208 [label=AccumulateGrad]
	140498052350544 -> 140498052350688
	140498325916384 [label="stage2.0.branch1.1.weight
 (24)" fillcolor=lightblue]
	140498325916384 -> 140498052350544
	140498052350544 [label=AccumulateGrad]
	140498052350496 -> 140498052350688
	140498325916464 [label="stage2.0.branch1.1.bias
 (24)" fillcolor=lightblue]
	140498325916464 -> 140498052350496
	140498052350496 [label=AccumulateGrad]
	140498052350784 -> 140498052350928
	140498325916864 [label="stage2.0.branch1.2.weight
 (24, 24, 1, 1)" fillcolor=lightblue]
	140498325916864 -> 140498052350784
	140498052350784 [label=AccumulateGrad]
	140498052350880 -> 140498052351072
	140498325916944 [label="stage2.0.branch1.3.weight
 (24)" fillcolor=lightblue]
	140498325916944 -> 140498052350880
	140498052350880 [label=AccumulateGrad]
	140498052351120 -> 140498052351072
	140498325917024 [label="stage2.0.branch1.3.bias
 (24)" fillcolor=lightblue]
	140498325917024 -> 140498052351120
	140498052351120 [label=AccumulateGrad]
	140498052351408 -> 140498052351360
	140498052351408 [label=ReluBackward0]
	140498052350736 -> 140498052351408
	140498052350736 [label=NativeBatchNormBackward0]
	140498052350256 -> 140498052350736
	140498052350256 [label=ConvolutionBackward0]
	140498052328896 -> 140498052350256
	140498052328896 [label=NativeBatchNormBackward0]
	140498052328848 -> 140498052328896
	140498052328848 [label=ConvolutionBackward0]
	140498052328320 -> 140498052328848
	140498052328320 [label=ReluBackward0]
	140498052328080 -> 140498052328320
	140498052328080 [label=NativeBatchNormBackward0]
	140498052328032 -> 140498052328080
	140498052328032 [label=ConvolutionBackward0]
	140498052350016 -> 140498052328032
	140498052327696 -> 140498052328032
	140498325917424 [label="stage2.0.branch2.0.weight
 (24, 24, 1, 1)" fillcolor=lightblue]
	140498325917424 -> 140498052327696
	140498052327696 [label=AccumulateGrad]
	140498052327984 -> 140498052328080
	140498325917504 [label="stage2.0.branch2.1.weight
 (24)" fillcolor=lightblue]
	140498325917504 -> 140498052327984
	140498052327984 [label=AccumulateGrad]
	140498052328128 -> 140498052328080
	140498325917584 [label="stage2.0.branch2.1.bias
 (24)" fillcolor=lightblue]
	140498325917584 -> 140498052328128
	140498052328128 [label=AccumulateGrad]
	140498052328416 -> 140498052328848
	140498605052288 [label="stage2.0.branch2.3.weight
 (24, 1, 3, 3)" fillcolor=lightblue]
	140498605052288 -> 140498052328416
	140498052328416 [label=AccumulateGrad]
	140498052328608 -> 140498052328896
	140498605052368 [label="stage2.0.branch2.4.weight
 (24)" fillcolor=lightblue]
	140498605052368 -> 140498052328608
	140498052328608 [label=AccumulateGrad]
	140498052328656 -> 140498052328896
	140498605052448 [label="stage2.0.branch2.4.bias
 (24)" fillcolor=lightblue]
	140498605052448 -> 140498052328656
	140498052328656 [label=AccumulateGrad]
	140498052329232 -> 140498052350256
	140498605052848 [label="stage2.0.branch2.5.weight
 (24, 24, 1, 1)" fillcolor=lightblue]
	140498605052848 -> 140498052329232
	140498052329232 [label=AccumulateGrad]
	140498052350304 -> 140498052350736
	140498605052928 [label="stage2.0.branch2.6.weight
 (24)" fillcolor=lightblue]
	140498605052928 -> 140498052350304
	140498052350304 [label=AccumulateGrad]
	140498052351168 -> 140498052350736
	140498605053008 [label="stage2.0.branch2.6.bias
 (24)" fillcolor=lightblue]
	140498605053008 -> 140498052351168
	140498052351168 [label=AccumulateGrad]
	140498052352224 -> 140498052352416
	140498052352224 [label=ReluBackward0]
	140498052351888 -> 140498052352224
	140498052351888 [label=NativeBatchNormBackward0]
	140498052351552 -> 140498052351888
	140498052351552 [label=ConvolutionBackward0]
	140498052350832 -> 140498052351552
	140498052350832 [label=NativeBatchNormBackward0]
	140498052328560 -> 140498052350832
	140498052328560 [label=ConvolutionBackward0]
	140498052327504 -> 140498052328560
	140498052327504 [label=ReluBackward0]
	140498052327264 -> 140498052327504
	140498052327264 [label=NativeBatchNormBackward0]
	140498052327216 -> 140498052327264
	140498052327216 [label=ConvolutionBackward0]
	140498052352272 -> 140498052327216
	140498052326880 -> 140498052327216
	140498605053408 [label="stage2.1.branch2.0.weight
 (24, 24, 1, 1)" fillcolor=lightblue]
	140498605053408 -> 140498052326880
	140498052326880 [label=AccumulateGrad]
	140498052327312 -> 140498052327264
	140498605053488 [label="stage2.1.branch2.1.weight
 (24)" fillcolor=lightblue]
	140498605053488 -> 140498052327312
	140498052327312 [label=AccumulateGrad]
	140498052327744 -> 140498052327264
	140498605053568 [label="stage2.1.branch2.1.bias
 (24)" fillcolor=lightblue]
	140498605053568 -> 140498052327744
	140498052327744 [label=AccumulateGrad]
	140498052327552 -> 140498052328560
	140498605053968 [label="stage2.1.branch2.3.weight
 (24, 1, 3, 3)" fillcolor=lightblue]
	140498605053968 -> 140498052327552
	140498052327552 [label=AccumulateGrad]
	140498052328368 -> 140498052350832
	140498605054048 [label="stage2.1.branch2.4.weight
 (24)" fillcolor=lightblue]
	140498605054048 -> 140498052328368
	140498052328368 [label=AccumulateGrad]
	140498052327792 -> 140498052350832
	140498605054128 [label="stage2.1.branch2.4.bias
 (24)" fillcolor=lightblue]
	140498605054128 -> 140498052327792
	140498052327792 [label=AccumulateGrad]
	140498052329280 -> 140498052351552
	140498605054528 [label="stage2.1.branch2.5.weight
 (24, 24, 1, 1)" fillcolor=lightblue]
	140498605054528 -> 140498052329280
	140498052329280 [label=AccumulateGrad]
	140498052351600 -> 140498052351888
	140498605054608 [label="stage2.1.branch2.6.weight
 (24)" fillcolor=lightblue]
	140498605054608 -> 140498052351600
	140498052351600 [label=AccumulateGrad]
	140498052351984 -> 140498052351888
	140498605054688 [label="stage2.1.branch2.6.bias
 (24)" fillcolor=lightblue]
	140498605054688 -> 140498052351984
	140498052351984 [label=AccumulateGrad]
	140498052353280 -> 140498052353376
	140498052353280 [label=ReluBackward0]
	140498052352704 -> 140498052353280
	140498052352704 [label=NativeBatchNormBackward0]
	140498052352512 -> 140498052352704
	140498052352512 [label=ConvolutionBackward0]
	140498052352176 -> 140498052352512
	140498052352176 [label=NativeBatchNormBackward0]
	140498052327936 -> 140498052352176
	140498052327936 [label=ConvolutionBackward0]
	140498052326928 -> 140498052327936
	140498052326928 [label=ReluBackward0]
	140498052326688 -> 140498052326928
	140498052326688 [label=NativeBatchNormBackward0]
	140498052326400 -> 140498052326688
	140498052326400 [label=ConvolutionBackward0]
	140498052353088 -> 140498052326400
	140498052326208 -> 140498052326400
	140498605055088 [label="stage2.2.branch2.0.weight
 (24, 24, 1, 1)" fillcolor=lightblue]
	140498605055088 -> 140498052326208
	140498052326208 [label=AccumulateGrad]
	140498052326592 -> 140498052326688
	140498605055168 [label="stage2.2.branch2.1.weight
 (24)" fillcolor=lightblue]
	140498605055168 -> 140498052326592
	140498052326592 [label=AccumulateGrad]
	140498052327072 -> 140498052326688
	140498605055248 [label="stage2.2.branch2.1.bias
 (24)" fillcolor=lightblue]
	140498605055248 -> 140498052327072
	140498052327072 [label=AccumulateGrad]
	140498052326832 -> 140498052327936
	140498605055648 [label="stage2.2.branch2.3.weight
 (24, 1, 3, 3)" fillcolor=lightblue]
	140498605055648 -> 140498052326832
	140498052326832 [label=AccumulateGrad]
	140498052328176 -> 140498052352176
	140498605055728 [label="stage2.2.branch2.4.weight
 (24)" fillcolor=lightblue]
	140498605055728 -> 140498052328176
	140498052328176 [label=AccumulateGrad]
	140498052326976 -> 140498052352176
	140498605055808 [label="stage2.2.branch2.4.bias
 (24)" fillcolor=lightblue]
	140498605055808 -> 140498052326976
	140498052326976 [label=AccumulateGrad]
	140498052351936 -> 140498052352512
	140498605146416 [label="stage2.2.branch2.5.weight
 (24, 24, 1, 1)" fillcolor=lightblue]
	140498605146416 -> 140498052351936
	140498052351936 [label=AccumulateGrad]
	140498052352656 -> 140498052352704
	140498605146496 [label="stage2.2.branch2.6.weight
 (24)" fillcolor=lightblue]
	140498605146496 -> 140498052352656
	140498052352656 [label=AccumulateGrad]
	140498052353040 -> 140498052352704
	140498605146576 [label="stage2.2.branch2.6.bias
 (24)" fillcolor=lightblue]
	140498605146576 -> 140498052353040
	140498052353040 [label=AccumulateGrad]
	140498052370688 -> 140498052370640
	140498052370688 [label=ReluBackward0]
	140498052370496 -> 140498052370688
	140498052370496 [label=NativeBatchNormBackward0]
	140498052353328 -> 140498052370496
	140498052353328 [label=ConvolutionBackward0]
	140498052353136 -> 140498052353328
	140498052353136 [label=NativeBatchNormBackward0]
	140498052327024 -> 140498052353136
	140498052327024 [label=ConvolutionBackward0]
	140498052326112 -> 140498052327024
	140498052326112 [label=ReluBackward0]
	140498052325872 -> 140498052326112
	140498052325872 [label=NativeBatchNormBackward0]
	140498052325824 -> 140498052325872
	140498052325824 [label=ConvolutionBackward0]
	140498052370592 -> 140498052325824
	140498052325488 -> 140498052325824
	140498605146976 [label="stage2.3.branch2.0.weight
 (24, 24, 1, 1)" fillcolor=lightblue]
	140498605146976 -> 140498052325488
	140498052325488 [label=AccumulateGrad]
	140498052325776 -> 140498052325872
	140498605147056 [label="stage2.3.branch2.1.weight
 (24)" fillcolor=lightblue]
	140498605147056 -> 140498052325776
	140498052325776 [label=AccumulateGrad]
	140498052326352 -> 140498052325872
	140498605147136 [label="stage2.3.branch2.1.bias
 (24)" fillcolor=lightblue]
	140498605147136 -> 140498052326352
	140498052326352 [label=AccumulateGrad]
	140498052325920 -> 140498052327024
	140498605147536 [label="stage2.3.branch2.3.weight
 (24, 1, 3, 3)" fillcolor=lightblue]
	140498605147536 -> 140498052325920
	140498052325920 [label=AccumulateGrad]
	140498052327456 -> 140498052353136
	140498605147616 [label="stage2.3.branch2.4.weight
 (24)" fillcolor=lightblue]
	140498605147616 -> 140498052327456
	140498052327456 [label=AccumulateGrad]
	140498052326160 -> 140498052353136
	140498605147696 [label="stage2.3.branch2.4.bias
 (24)" fillcolor=lightblue]
	140498605147696 -> 140498052326160
	140498052326160 [label=AccumulateGrad]
	140498052352992 -> 140498052353328
	140498605148096 [label="stage2.3.branch2.5.weight
 (24, 24, 1, 1)" fillcolor=lightblue]
	140498605148096 -> 140498052352992
	140498052352992 [label=AccumulateGrad]
	140498052353616 -> 140498052370496
	140498605148176 [label="stage2.3.branch2.6.weight
 (24)" fillcolor=lightblue]
	140498605148176 -> 140498052353616
	140498052353616 [label=AccumulateGrad]
	140498052353808 -> 140498052370496
	140498605148256 [label="stage2.3.branch2.6.bias
 (24)" fillcolor=lightblue]
	140498605148256 -> 140498052353808
	140498052353808 [label=AccumulateGrad]
	140498052371552 -> 140498052371696
	140498605148656 [label="stage3.0.branch1.0.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	140498605148656 -> 140498052371552
	140498052371552 [label=AccumulateGrad]
	140498052371792 -> 140498052371936
	140498605148736 [label="stage3.0.branch1.1.weight
 (48)" fillcolor=lightblue]
	140498605148736 -> 140498052371792
	140498052371792 [label=AccumulateGrad]
	140498052371744 -> 140498052371936
	140498605148816 [label="stage3.0.branch1.1.bias
 (48)" fillcolor=lightblue]
	140498605148816 -> 140498052371744
	140498052371744 [label=AccumulateGrad]
	140498052372032 -> 140498052372272
	140498605149216 [label="stage3.0.branch1.2.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	140498605149216 -> 140498052372032
	140498052372032 [label=AccumulateGrad]
	140498052372224 -> 140498052372416
	140498605149296 [label="stage3.0.branch1.3.weight
 (48)" fillcolor=lightblue]
	140498605149296 -> 140498052372224
	140498052372224 [label=AccumulateGrad]
	140498052372464 -> 140498052372416
	140498605149376 [label="stage3.0.branch1.3.bias
 (48)" fillcolor=lightblue]
	140498605149376 -> 140498052372464
	140498052372464 [label=AccumulateGrad]
	140498052372752 -> 140498052372704
	140498052372752 [label=ReluBackward0]
	140498052371984 -> 140498052372752
	140498052371984 [label=NativeBatchNormBackward0]
	140498052371648 -> 140498052371984
	140498052371648 [label=ConvolutionBackward0]
	140498052370832 -> 140498052371648
	140498052370832 [label=NativeBatchNormBackward0]
	140498052354000 -> 140498052370832
	140498052354000 [label=ConvolutionBackward0]
	140498052326448 -> 140498052354000
	140498052326448 [label=ReluBackward0]
	140498052325536 -> 140498052326448
	140498052325536 [label=NativeBatchNormBackward0]
	140498052308800 -> 140498052325536
	140498052308800 [label=ConvolutionBackward0]
	140498052371360 -> 140498052308800
	140498052308368 -> 140498052308800
	140498605149776 [label="stage3.0.branch2.0.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	140498605149776 -> 140498052308368
	140498052308368 [label=AccumulateGrad]
	140498052308848 -> 140498052325536
	140498605149856 [label="stage3.0.branch2.1.weight
 (48)" fillcolor=lightblue]
	140498605149856 -> 140498052308848
	140498052308848 [label=AccumulateGrad]
	140498052308896 -> 140498052325536
	140498605149936 [label="stage3.0.branch2.1.bias
 (48)" fillcolor=lightblue]
	140498605149936 -> 140498052308896
	140498052308896 [label=AccumulateGrad]
	140498052325584 -> 140498052354000
	140498605252832 [label="stage3.0.branch2.3.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	140498605252832 -> 140498052325584
	140498052325584 [label=AccumulateGrad]
	140498052353760 -> 140498052370832
	140498605252912 [label="stage3.0.branch2.4.weight
 (48)" fillcolor=lightblue]
	140498605252912 -> 140498052353760
	140498052353760 [label=AccumulateGrad]
	140498052371408 -> 140498052370832
	140498605252992 [label="stage3.0.branch2.4.bias
 (48)" fillcolor=lightblue]
	140498605252992 -> 140498052371408
	140498052371408 [label=AccumulateGrad]
	140498052371312 -> 140498052371648
	140498605253392 [label="stage3.0.branch2.5.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	140498605253392 -> 140498052371312
	140498052371312 [label=AccumulateGrad]
	140498052370880 -> 140498052371984
	140498605253472 [label="stage3.0.branch2.6.weight
 (48)" fillcolor=lightblue]
	140498605253472 -> 140498052370880
	140498052370880 [label=AccumulateGrad]
	140498052372512 -> 140498052371984
	140498605253552 [label="stage3.0.branch2.6.bias
 (48)" fillcolor=lightblue]
	140498605253552 -> 140498052372512
	140498052372512 [label=AccumulateGrad]
	140498052373568 -> 140498052373760
	140498052373568 [label=ReluBackward0]
	140498052373136 -> 140498052373568
	140498052373136 [label=NativeBatchNormBackward0]
	140498052372800 -> 140498052373136
	140498052372800 [label=ConvolutionBackward0]
	140498052371168 -> 140498052372800
	140498052371168 [label=NativeBatchNormBackward0]
	140498052329040 -> 140498052371168
	140498052329040 [label=ConvolutionBackward0]
	140498052308416 -> 140498052329040
	140498052308416 [label=ReluBackward0]
	140498052308272 -> 140498052308416
	140498052308272 [label=NativeBatchNormBackward0]
	140498052307984 -> 140498052308272
	140498052307984 [label=ConvolutionBackward0]
	140498052373616 -> 140498052307984
	140498052307792 -> 140498052307984
	140498605253952 [label="stage3.1.branch2.0.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	140498605253952 -> 140498052307792
	140498052307792 [label=AccumulateGrad]
	140498052308176 -> 140498052308272
	140498605254032 [label="stage3.1.branch2.1.weight
 (48)" fillcolor=lightblue]
	140498605254032 -> 140498052308176
	140498052308176 [label=AccumulateGrad]
	140498052308656 -> 140498052308272
	140498605254112 [label="stage3.1.branch2.1.bias
 (48)" fillcolor=lightblue]
	140498605254112 -> 140498052308656
	140498052308656 [label=AccumulateGrad]
	140498052308320 -> 140498052329040
	140498605254512 [label="stage3.1.branch2.3.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	140498605254512 -> 140498052308320
	140498052308320 [label=AccumulateGrad]
	140498052325728 -> 140498052371168
	140498605254592 [label="stage3.1.branch2.4.weight
 (48)" fillcolor=lightblue]
	140498605254592 -> 140498052325728
	140498052325728 [label=AccumulateGrad]
	140498052325968 -> 140498052371168
	140498605254672 [label="stage3.1.branch2.4.bias
 (48)" fillcolor=lightblue]
	140498605254672 -> 140498052325968
	140498052325968 [label=AccumulateGrad]
	140498052371600 -> 140498052372800
	140498605255072 [label="stage3.1.branch2.5.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	140498605255072 -> 140498052371600
	140498052371600 [label=AccumulateGrad]
	140498052372848 -> 140498052373136
	140498605255152 [label="stage3.1.branch2.6.weight
 (48)" fillcolor=lightblue]
	140498605255152 -> 140498052372848
	140498052372848 [label=AccumulateGrad]
	140498052373328 -> 140498052373136
	140498605255232 [label="stage3.1.branch2.6.bias
 (48)" fillcolor=lightblue]
	140498605255232 -> 140498052373328
	140498052373328 [label=AccumulateGrad]
	140498052395840 -> 140498052395264
	140498052395840 [label=ReluBackward0]
	140498052373952 -> 140498052395840
	140498052373952 [label=NativeBatchNormBackward0]
	140498052373856 -> 140498052373952
	140498052373856 [label=ConvolutionBackward0]
	140498052372176 -> 140498052373856
	140498052372176 [label=NativeBatchNormBackward0]
	140498052308560 -> 140498052372176
	140498052308560 [label=ConvolutionBackward0]
	140498052307696 -> 140498052308560
	140498052307696 [label=ReluBackward0]
	140498052307456 -> 140498052307696
	140498052307456 [label=NativeBatchNormBackward0]
	140498052307312 -> 140498052307456
	140498052307312 [label=ConvolutionBackward0]
	140498052395168 -> 140498052307312
	140498052307072 -> 140498052307312
	140498605255632 [label="stage3.2.branch2.0.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	140498605255632 -> 140498052307072
	140498052307072 [label=AccumulateGrad]
	140498052307264 -> 140498052307456
	140498605255712 [label="stage3.2.branch2.1.weight
 (48)" fillcolor=lightblue]
	140498605255712 -> 140498052307264
	140498052307264 [label=AccumulateGrad]
	140498052307936 -> 140498052307456
	140498605255792 [label="stage3.2.branch2.1.bias
 (48)" fillcolor=lightblue]
	140498605255792 -> 140498052307936
	140498052307936 [label=AccumulateGrad]
	140498052307504 -> 140498052308560
	140498605256192 [label="stage3.2.branch2.3.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	140498605256192 -> 140498052307504
	140498052307504 [label=AccumulateGrad]
	140498052308608 -> 140498052372176
	140498605256272 [label="stage3.2.branch2.4.weight
 (48)" fillcolor=lightblue]
	140498605256272 -> 140498052308608
	140498052308608 [label=AccumulateGrad]
	140498052307744 -> 140498052372176
	140498605256352 [label="stage3.2.branch2.4.bias
 (48)" fillcolor=lightblue]
	140498605256352 -> 140498052307744
	140498052307744 [label=AccumulateGrad]
	140498052373520 -> 140498052373856
	140498605351056 [label="stage3.2.branch2.5.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	140498605351056 -> 140498052373520
	140498052373520 [label=AccumulateGrad]
	140498052373904 -> 140498052373952
	140498605351136 [label="stage3.2.branch2.6.weight
 (48)" fillcolor=lightblue]
	140498605351136 -> 140498052373904
	140498052373904 [label=AccumulateGrad]
	140498052374384 -> 140498052373952
	140498605351216 [label="stage3.2.branch2.6.bias
 (48)" fillcolor=lightblue]
	140498605351216 -> 140498052374384
	140498052374384 [label=AccumulateGrad]
	140498052396128 -> 140498052396080
	140498052396128 [label=ReluBackward0]
	140498052395552 -> 140498052396128
	140498052395552 [label=NativeBatchNormBackward0]
	140498052395216 -> 140498052395552
	140498052395216 [label=ConvolutionBackward0]
	140498052373280 -> 140498052395216
	140498052373280 [label=NativeBatchNormBackward0]
	140498052308032 -> 140498052373280
	140498052308032 [label=ConvolutionBackward0]
	140498052306880 -> 140498052308032
	140498052306880 [label=ReluBackward0]
	140498052306640 -> 140498052306880
	140498052306640 [label=NativeBatchNormBackward0]
	140498052306592 -> 140498052306640
	140498052306592 [label=ConvolutionBackward0]
	140498052396032 -> 140498052306592
	140498052306160 -> 140498052306592
	140498605351616 [label="stage3.3.branch2.0.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	140498605351616 -> 140498052306160
	140498052306160 [label=AccumulateGrad]
	140498052306688 -> 140498052306640
	140498605351696 [label="stage3.3.branch2.1.weight
 (48)" fillcolor=lightblue]
	140498605351696 -> 140498052306688
	140498052306688 [label=AccumulateGrad]
	140498052307120 -> 140498052306640
	140498605351776 [label="stage3.3.branch2.1.bias
 (48)" fillcolor=lightblue]
	140498605351776 -> 140498052307120
	140498052307120 [label=AccumulateGrad]
	140498052306928 -> 140498052308032
	140498605352176 [label="stage3.3.branch2.3.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	140498605352176 -> 140498052306928
	140498052306928 [label=AccumulateGrad]
	140498052308224 -> 140498052373280
	140498605352256 [label="stage3.3.branch2.4.weight
 (48)" fillcolor=lightblue]
	140498605352256 -> 140498052308224
	140498052308224 [label=AccumulateGrad]
	140498052307168 -> 140498052373280
	140498605352336 [label="stage3.3.branch2.4.bias
 (48)" fillcolor=lightblue]
	140498605352336 -> 140498052307168
	140498052307168 [label=AccumulateGrad]
	140498052374480 -> 140498052395216
	140498605352736 [label="stage3.3.branch2.5.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	140498605352736 -> 140498052374480
	140498052374480 [label=AccumulateGrad]
	140498052395504 -> 140498052395552
	140498605352816 [label="stage3.3.branch2.6.weight
 (48)" fillcolor=lightblue]
	140498605352816 -> 140498052395504
	140498052395504 [label=AccumulateGrad]
	140498052395888 -> 140498052395552
	140498605352896 [label="stage3.3.branch2.6.bias
 (48)" fillcolor=lightblue]
	140498605352896 -> 140498052395888
	140498052395888 [label=AccumulateGrad]
	140498052396944 -> 140498052397136
	140498052396944 [label=ReluBackward0]
	140498052396608 -> 140498052396944
	140498052396608 [label=NativeBatchNormBackward0]
	140498052396272 -> 140498052396608
	140498052396272 [label=ConvolutionBackward0]
	140498052374240 -> 140498052396272
	140498052374240 [label=NativeBatchNormBackward0]
	140498052307216 -> 140498052374240
	140498052307216 [label=ConvolutionBackward0]
	140498052306208 -> 140498052307216
	140498052306208 [label=ReluBackward0]
	140498052306064 -> 140498052306208
	140498052306064 [label=NativeBatchNormBackward0]
	140498052305776 -> 140498052306064
	140498052305776 [label=ConvolutionBackward0]
	140498052396992 -> 140498052305776
	140498052305584 -> 140498052305776
	140498605353296 [label="stage3.4.branch2.0.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	140498605353296 -> 140498052305584
	140498052305584 [label=AccumulateGrad]
	140498052305968 -> 140498052306064
	140498605353376 [label="stage3.4.branch2.1.weight
 (48)" fillcolor=lightblue]
	140498605353376 -> 140498052305968
	140498052305968 [label=AccumulateGrad]
	140498052306448 -> 140498052306064
	140498605353456 [label="stage3.4.branch2.1.bias
 (48)" fillcolor=lightblue]
	140498605353456 -> 140498052306448
	140498052306448 [label=AccumulateGrad]
	140498052306112 -> 140498052307216
	140498605353856 [label="stage3.4.branch2.3.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	140498605353856 -> 140498052306112
	140498052306112 [label=AccumulateGrad]
	140498052307552 -> 140498052374240
	140498605353936 [label="stage3.4.branch2.4.weight
 (48)" fillcolor=lightblue]
	140498605353936 -> 140498052307552
	140498052307552 [label=AccumulateGrad]
	140498052306352 -> 140498052374240
	140498605354016 [label="stage3.4.branch2.4.bias
 (48)" fillcolor=lightblue]
	140498605354016 -> 140498052306352
	140498052306352 [label=AccumulateGrad]
	140498052374432 -> 140498052396272
	140498605354416 [label="stage3.4.branch2.5.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	140498605354416 -> 140498052374432
	140498052374432 [label=AccumulateGrad]
	140498052396320 -> 140498052396608
	140498605354496 [label="stage3.4.branch2.6.weight
 (48)" fillcolor=lightblue]
	140498605354496 -> 140498052396320
	140498052396320 [label=AccumulateGrad]
	140498052396704 -> 140498052396608
	140498605354576 [label="stage3.4.branch2.6.bias
 (48)" fillcolor=lightblue]
	140498605354576 -> 140498052396704
	140498052396704 [label=AccumulateGrad]
	140498052398000 -> 140498052398096
	140498052398000 [label=ReluBackward0]
	140498052397424 -> 140498052398000
	140498052397424 [label=NativeBatchNormBackward0]
	140498052397232 -> 140498052397424
	140498052397232 [label=ConvolutionBackward0]
	140498052395600 -> 140498052397232
	140498052395600 [label=NativeBatchNormBackward0]
	140498052306400 -> 140498052395600
	140498052306400 [label=ConvolutionBackward0]
	140498052305488 -> 140498052306400
	140498052305488 [label=ReluBackward0]
	140498052305248 -> 140498052305488
	140498052305248 [label=NativeBatchNormBackward0]
	140498052305104 -> 140498052305248
	140498052305104 [label=ConvolutionBackward0]
	140498052397808 -> 140498052305104
	140498052304960 -> 140498052305104
	140498605445184 [label="stage3.5.branch2.0.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	140498605445184 -> 140498052304960
	140498052304960 [label=AccumulateGrad]
	140498052305056 -> 140498052305248
	140498605445264 [label="stage3.5.branch2.1.weight
 (48)" fillcolor=lightblue]
	140498605445264 -> 140498052305056
	140498052305056 [label=AccumulateGrad]
	140498052305728 -> 140498052305248
	140498605445344 [label="stage3.5.branch2.1.bias
 (48)" fillcolor=lightblue]
	140498605445344 -> 140498052305728
	140498052305728 [label=AccumulateGrad]
	140498052305296 -> 140498052306400
	140498605445744 [label="stage3.5.branch2.3.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	140498605445744 -> 140498052305296
	140498052305296 [label=AccumulateGrad]
	140498052306832 -> 140498052395600
	140498605445824 [label="stage3.5.branch2.4.weight
 (48)" fillcolor=lightblue]
	140498605445824 -> 140498052306832
	140498052306832 [label=AccumulateGrad]
	140498052305536 -> 140498052395600
	140498605445904 [label="stage3.5.branch2.4.bias
 (48)" fillcolor=lightblue]
	140498605445904 -> 140498052305536
	140498052305536 [label=AccumulateGrad]
	140498052396896 -> 140498052397232
	140498605446304 [label="stage3.5.branch2.5.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	140498605446304 -> 140498052396896
	140498052396896 [label=AccumulateGrad]
	140498052397376 -> 140498052397424
	140498605446384 [label="stage3.5.branch2.6.weight
 (48)" fillcolor=lightblue]
	140498605446384 -> 140498052397376
	140498052397376 [label=AccumulateGrad]
	140498052397760 -> 140498052397424
	140498605446464 [label="stage3.5.branch2.6.bias
 (48)" fillcolor=lightblue]
	140498605446464 -> 140498052397760
	140498052397760 [label=AccumulateGrad]
	140498052398960 -> 140498052419648
	140498052398960 [label=ReluBackward0]
	140498052398480 -> 140498052398960
	140498052398480 [label=NativeBatchNormBackward0]
	140498052398048 -> 140498052398480
	140498052398048 [label=ConvolutionBackward0]
	140498052396656 -> 140498052398048
	140498052396656 [label=NativeBatchNormBackward0]
	140498052305824 -> 140498052396656
	140498052305824 [label=ConvolutionBackward0]
	140498052284128 -> 140498052305824
	140498052284128 [label=ReluBackward0]
	140498052283888 -> 140498052284128
	140498052283888 [label=NativeBatchNormBackward0]
	140498052283840 -> 140498052283888
	140498052283840 [label=ConvolutionBackward0]
	140498052398864 -> 140498052283840
	140498052283408 -> 140498052283840
	140498605446944 [label="stage3.6.branch2.0.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	140498605446944 -> 140498052283408
	140498052283408 [label=AccumulateGrad]
	140498052283936 -> 140498052283888
	140498605447024 [label="stage3.6.branch2.1.weight
 (48)" fillcolor=lightblue]
	140498605447024 -> 140498052283936
	140498052283936 [label=AccumulateGrad]
	140498052284368 -> 140498052283888
	140498605447104 [label="stage3.6.branch2.1.bias
 (48)" fillcolor=lightblue]
	140498605447104 -> 140498052284368
	140498052284368 [label=AccumulateGrad]
	140498052284176 -> 140498052305824
	140498605447504 [label="stage3.6.branch2.3.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	140498605447504 -> 140498052284176
	140498052284176 [label=AccumulateGrad]
	140498052306016 -> 140498052396656
	140498605447584 [label="stage3.6.branch2.4.weight
 (48)" fillcolor=lightblue]
	140498605447584 -> 140498052306016
	140498052306016 [label=AccumulateGrad]
	140498052305008 -> 140498052396656
	140498605447664 [label="stage3.6.branch2.4.bias
 (48)" fillcolor=lightblue]
	140498605447664 -> 140498052305008
	140498052305008 [label=AccumulateGrad]
	140498052397856 -> 140498052398048
	140498605448064 [label="stage3.6.branch2.5.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	140498605448064 -> 140498052397856
	140498052397856 [label=AccumulateGrad]
	140498052398336 -> 140498052398480
	140498605448144 [label="stage3.6.branch2.6.weight
 (48)" fillcolor=lightblue]
	140498605448144 -> 140498052398336
	140498052398336 [label=AccumulateGrad]
	140498052398816 -> 140498052398480
	140498605448224 [label="stage3.6.branch2.6.bias
 (48)" fillcolor=lightblue]
	140498605448224 -> 140498052398816
	140498052398816 [label=AccumulateGrad]
	140498052420416 -> 140498052420512
	140498052420416 [label=ReluBackward0]
	140498052419984 -> 140498052420416
	140498052419984 [label=NativeBatchNormBackward0]
	140498052420368 -> 140498052419984
	140498052420368 [label=ConvolutionBackward0]
	140498052397712 -> 140498052420368
	140498052397712 [label=NativeBatchNormBackward0]
	140498052305344 -> 140498052397712
	140498052305344 [label=ConvolutionBackward0]
	140498052283456 -> 140498052305344
	140498052283456 [label=ReluBackward0]
	140498052283312 -> 140498052283456
	140498052283312 [label=NativeBatchNormBackward0]
	140498052283024 -> 140498052283312
	140498052283024 [label=ConvolutionBackward0]
	140498052420464 -> 140498052283024
	140498052282832 -> 140498052283024
	140498605448624 [label="stage3.7.branch2.0.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	140498605448624 -> 140498052282832
	140498052282832 [label=AccumulateGrad]
	140498052283216 -> 140498052283312
	140498605448704 [label="stage3.7.branch2.1.weight
 (48)" fillcolor=lightblue]
	140498605448704 -> 140498052283216
	140498052283216 [label=AccumulateGrad]
	140498052283696 -> 140498052283312
	140498605448784 [label="stage3.7.branch2.1.bias
 (48)" fillcolor=lightblue]
	140498605448784 -> 140498052283696
	140498052283696 [label=AccumulateGrad]
	140498052283360 -> 140498052305344
	140497793855552 [label="stage3.7.branch2.3.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	140497793855552 -> 140498052283360
	140498052283360 [label=AccumulateGrad]
	140498052284320 -> 140498052397712
	140497793855632 [label="stage3.7.branch2.4.weight
 (48)" fillcolor=lightblue]
	140497793855632 -> 140498052284320
	140498052284320 [label=AccumulateGrad]
	140498052283600 -> 140498052397712
	140497793855712 [label="stage3.7.branch2.4.bias
 (48)" fillcolor=lightblue]
	140497793855712 -> 140498052283600
	140498052283600 [label=AccumulateGrad]
	140498052398768 -> 140498052420368
	140497793856112 [label="stage3.7.branch2.5.weight
 (48, 48, 1, 1)" fillcolor=lightblue]
	140497793856112 -> 140498052398768
	140498052398768 [label=AccumulateGrad]
	140498052419696 -> 140498052419984
	140497793856192 [label="stage3.7.branch2.6.weight
 (48)" fillcolor=lightblue]
	140497793856192 -> 140498052419696
	140498052419696 [label=AccumulateGrad]
	140498052420176 -> 140498052419984
	140497793856272 [label="stage3.7.branch2.6.bias
 (48)" fillcolor=lightblue]
	140497793856272 -> 140498052420176
	140498052420176 [label=AccumulateGrad]
	140498052421328 -> 140498052421568
	140497793856672 [label="stage4.0.branch1.0.weight
 (96, 1, 3, 3)" fillcolor=lightblue]
	140497793856672 -> 140498052421328
	140498052421328 [label=AccumulateGrad]
	140498052421520 -> 140498052421712
	140497793856752 [label="stage4.0.branch1.1.weight
 (96)" fillcolor=lightblue]
	140497793856752 -> 140498052421520
	140498052421520 [label=AccumulateGrad]
	140498052421616 -> 140498052421712
	140497793856832 [label="stage4.0.branch1.1.bias
 (96)" fillcolor=lightblue]
	140497793856832 -> 140498052421616
	140498052421616 [label=AccumulateGrad]
	140498052421664 -> 140498052421904
	140497793857232 [label="stage4.0.branch1.2.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	140497793857232 -> 140498052421664
	140498052421664 [label=AccumulateGrad]
	140498052422096 -> 140498052422192
	140497793857312 [label="stage4.0.branch1.3.weight
 (96)" fillcolor=lightblue]
	140497793857312 -> 140498052422096
	140498052422096 [label=AccumulateGrad]
	140498052422336 -> 140498052422192
	140497793857392 [label="stage4.0.branch1.3.bias
 (96)" fillcolor=lightblue]
	140497793857392 -> 140498052422336
	140498052422336 [label=AccumulateGrad]
	140498052422384 -> 140498052422576
	140498052422384 [label=ReluBackward0]
	140498052421856 -> 140498052422384
	140498052421856 [label=NativeBatchNormBackward0]
	140498052421280 -> 140498052421856
	140498052421280 [label=ConvolutionBackward0]
	140498052420608 -> 140498052421280
	140498052420608 [label=NativeBatchNormBackward0]
	140498052420128 -> 140498052420608
	140498052420128 [label=ConvolutionBackward0]
	140498052283648 -> 140498052420128
	140498052283648 [label=ReluBackward0]
	140498052282544 -> 140498052283648
	140498052282544 [label=NativeBatchNormBackward0]
	140498052282976 -> 140498052282544
	140498052282976 [label=ConvolutionBackward0]
	140498052421232 -> 140498052282976
	140498052282352 -> 140498052282976
	140497793857792 [label="stage4.0.branch2.0.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	140497793857792 -> 140498052282352
	140498052282352 [label=AccumulateGrad]
	140498052282736 -> 140498052282544
	140497793857872 [label="stage4.0.branch2.1.weight
 (96)" fillcolor=lightblue]
	140497793857872 -> 140498052282736
	140498052282736 [label=AccumulateGrad]
	140498052283072 -> 140498052282544
	140497793857952 [label="stage4.0.branch2.1.bias
 (96)" fillcolor=lightblue]
	140497793857952 -> 140498052283072
	140498052283072 [label=AccumulateGrad]
	140498052284080 -> 140498052420128
	140497793858352 [label="stage4.0.branch2.3.weight
 (96, 1, 3, 3)" fillcolor=lightblue]
	140497793858352 -> 140498052284080
	140498052284080 [label=AccumulateGrad]
	140498052421040 -> 140498052420608
	140497793858432 [label="stage4.0.branch2.4.weight
 (96)" fillcolor=lightblue]
	140497793858432 -> 140498052421040
	140498052421040 [label=AccumulateGrad]
	140498052398912 -> 140498052420608
	140497793858512 [label="stage4.0.branch2.4.bias
 (96)" fillcolor=lightblue]
	140497793858512 -> 140498052398912
	140498052398912 [label=AccumulateGrad]
	140498052421088 -> 140498052421280
	140497793858912 [label="stage4.0.branch2.5.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	140497793858912 -> 140498052421088
	140498052421088 [label=AccumulateGrad]
	140498052420752 -> 140498052421856
	140497793858992 [label="stage4.0.branch2.6.weight
 (96)" fillcolor=lightblue]
	140497793858992 -> 140498052420752
	140498052420752 [label=AccumulateGrad]
	140498052422144 -> 140498052421856
	140497793859072 [label="stage4.0.branch2.6.bias
 (96)" fillcolor=lightblue]
	140497793859072 -> 140498052422144
	140498052422144 [label=AccumulateGrad]
	140498052423440 -> 140498052436464
	140498052423440 [label=ReluBackward0]
	140498052422720 -> 140498052423440
	140498052422720 [label=NativeBatchNormBackward0]
	140498052423296 -> 140498052422720
	140498052423296 [label=ConvolutionBackward0]
	140498052398528 -> 140498052423296
	140498052398528 [label=NativeBatchNormBackward0]
	140498052282592 -> 140498052398528
	140498052282592 [label=ConvolutionBackward0]
	140498052282496 -> 140498052282592
	140498052282496 [label=ReluBackward0]
	140498052281920 -> 140498052282496
	140498052281920 [label=NativeBatchNormBackward0]
	140498052281872 -> 140498052281920
	140498052281872 [label=ConvolutionBackward0]
	140498052423248 -> 140498052281872
	140498052281440 -> 140498052281872
	140497793859392 [label="stage4.1.branch2.0.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	140497793859392 -> 140498052281440
	140498052281440 [label=AccumulateGrad]
	140498052281968 -> 140498052281920
	140497793859472 [label="stage4.1.branch2.1.weight
 (96)" fillcolor=lightblue]
	140497793859472 -> 140498052281968
	140498052281968 [label=AccumulateGrad]
	140498052282208 -> 140498052281920
	140497793953856 [label="stage4.1.branch2.1.bias
 (96)" fillcolor=lightblue]
	140497793953856 -> 140498052282208
	140498052282208 [label=AccumulateGrad]
	140498052282256 -> 140498052282592
	140497793954256 [label="stage4.1.branch2.3.weight
 (96, 1, 3, 3)" fillcolor=lightblue]
	140497793954256 -> 140498052282256
	140498052282256 [label=AccumulateGrad]
	140498052282784 -> 140498052398528
	140497793954336 [label="stage4.1.branch2.4.weight
 (96)" fillcolor=lightblue]
	140497793954336 -> 140498052282784
	140498052282784 [label=AccumulateGrad]
	140498052282304 -> 140498052398528
	140497793954416 [label="stage4.1.branch2.4.bias
 (96)" fillcolor=lightblue]
	140497793954416 -> 140498052282304
	140498052282304 [label=AccumulateGrad]
	140498052420800 -> 140498052423296
	140497793954816 [label="stage4.1.branch2.5.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	140497793954816 -> 140498052420800
	140498052420800 [label=AccumulateGrad]
	140498052422672 -> 140498052422720
	140497793954896 [label="stage4.1.branch2.6.weight
 (96)" fillcolor=lightblue]
	140497793954896 -> 140498052422672
	140498052422672 [label=AccumulateGrad]
	140498052423056 -> 140498052422720
	140497793954976 [label="stage4.1.branch2.6.bias
 (96)" fillcolor=lightblue]
	140497793954976 -> 140498052423056
	140498052423056 [label=AccumulateGrad]
	140498052436752 -> 140498052436704
	140498052436752 [label=ReluBackward0]
	140498052436176 -> 140498052436752
	140498052436176 [label=NativeBatchNormBackward0]
	140498052436128 -> 140498052436176
	140498052436128 [label=ConvolutionBackward0]
	140498052421472 -> 140498052436128
	140498052421472 [label=NativeBatchNormBackward0]
	140498052283264 -> 140498052421472
	140498052283264 [label=ConvolutionBackward0]
	140498052281488 -> 140498052283264
	140498052281488 [label=ReluBackward0]
	140498052281248 -> 140498052281488
	140498052281248 [label=NativeBatchNormBackward0]
	140498052281056 -> 140498052281248
	140498052281056 [label=ConvolutionBackward0]
	140498052436656 -> 140498052281056
	140498052280864 -> 140498052281056
	140497793955376 [label="stage4.2.branch2.0.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	140497793955376 -> 140498052280864
	140498052280864 [label=AccumulateGrad]
	140498052281152 -> 140498052281248
	140497793955456 [label="stage4.2.branch2.1.weight
 (96)" fillcolor=lightblue]
	140497793955456 -> 140498052281152
	140498052281152 [label=AccumulateGrad]
	140498052281728 -> 140498052281248
	140497793955536 [label="stage4.2.branch2.1.bias
 (96)" fillcolor=lightblue]
	140497793955536 -> 140498052281728
	140498052281728 [label=AccumulateGrad]
	140498052281392 -> 140498052283264
	140497793955936 [label="stage4.2.branch2.3.weight
 (96, 1, 3, 3)" fillcolor=lightblue]
	140497793955936 -> 140498052281392
	140498052281392 [label=AccumulateGrad]
	140498052282160 -> 140498052421472
	140497793956016 [label="stage4.2.branch2.4.weight
 (96)" fillcolor=lightblue]
	140497793956016 -> 140498052282160
	140498052282160 [label=AccumulateGrad]
	140498052281632 -> 140498052421472
	140497793956096 [label="stage4.2.branch2.4.bias
 (96)" fillcolor=lightblue]
	140497793956096 -> 140498052281632
	140498052281632 [label=AccumulateGrad]
	140498052421952 -> 140498052436128
	140497793956496 [label="stage4.2.branch2.5.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	140497793956496 -> 140498052421952
	140498052421952 [label=AccumulateGrad]
	140498052436512 -> 140498052436176
	140497793956576 [label="stage4.2.branch2.6.weight
 (96)" fillcolor=lightblue]
	140497793956576 -> 140498052436512
	140498052436512 [label=AccumulateGrad]
	140498052423536 -> 140498052436176
	140497793956656 [label="stage4.2.branch2.6.bias
 (96)" fillcolor=lightblue]
	140497793956656 -> 140498052423536
	140498052423536 [label=AccumulateGrad]
	140498052437568 -> 140498052437760
	140498052437568 [label=ReluBackward0]
	140498052437232 -> 140498052437568
	140498052437232 [label=NativeBatchNormBackward0]
	140498052436896 -> 140498052437232
	140498052436896 [label=ConvolutionBackward0]
	140498052422768 -> 140498052436896
	140498052422768 [label=NativeBatchNormBackward0]
	140498052281680 -> 140498052422768
	140498052281680 [label=ConvolutionBackward0]
	140498052280768 -> 140498052281680
	140498052280768 [label=ReluBackward0]
	140498052280528 -> 140498052280768
	140498052280528 [label=NativeBatchNormBackward0]
	140498052280384 -> 140498052280528
	140498052280384 [label=ConvolutionBackward0]
	140498052437616 -> 140498052280384
	140498052263600 -> 140498052280384
	140497793957056 [label="stage4.3.branch2.0.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	140497793957056 -> 140498052263600
	140498052263600 [label=AccumulateGrad]
	140498052281008 -> 140498052280528
	140497793957136 [label="stage4.3.branch2.1.weight
 (96)" fillcolor=lightblue]
	140497793957136 -> 140498052281008
	140498052281008 [label=AccumulateGrad]
	140498052263888 -> 140498052280528
	140497793957216 [label="stage4.3.branch2.1.bias
 (96)" fillcolor=lightblue]
	140497793957216 -> 140498052263888
	140498052263888 [label=AccumulateGrad]
	140498052280576 -> 140498052281680
	140497793957616 [label="stage4.3.branch2.3.weight
 (96, 1, 3, 3)" fillcolor=lightblue]
	140497793957616 -> 140498052280576
	140498052280576 [label=AccumulateGrad]
	140498052282112 -> 140498052422768
	140497793957696 [label="stage4.3.branch2.4.weight
 (96)" fillcolor=lightblue]
	140497793957696 -> 140498052282112
	140498052282112 [label=AccumulateGrad]
	140498052280816 -> 140498052422768
	140497793957776 [label="stage4.3.branch2.4.bias
 (96)" fillcolor=lightblue]
	140497793957776 -> 140498052280816
	140498052280816 [label=AccumulateGrad]
	140498052423488 -> 140498052436896
	140497794040192 [label="stage4.3.branch2.5.weight
 (96, 96, 1, 1)" fillcolor=lightblue]
	140497794040192 -> 140498052423488
	140498052423488 [label=AccumulateGrad]
	140498052436944 -> 140498052437232
	140497794040272 [label="stage4.3.branch2.6.weight
 (96)" fillcolor=lightblue]
	140497794040272 -> 140498052436944
	140498052436944 [label=AccumulateGrad]
	140498052437328 -> 140498052437232
	140497794040352 [label="stage4.3.branch2.6.bias
 (96)" fillcolor=lightblue]
	140497794040352 -> 140498052437328
	140498052437328 [label=AccumulateGrad]
	140498052438480 -> 140498052438720
	140497794040752 [label="conv5.0.weight
 (1024, 192, 1, 1)" fillcolor=lightblue]
	140497794040752 -> 140498052438480
	140498052438480 [label=AccumulateGrad]
	140498052438672 -> 140498052438864
	140497794040832 [label="conv5.1.weight
 (1024)" fillcolor=lightblue]
	140497794040832 -> 140498052438672
	140498052438672 [label=AccumulateGrad]
	140498052438912 -> 140498052438864
	140497794040912 [label="conv5.1.bias
 (1024)" fillcolor=lightblue]
	140497794040912 -> 140498052438912
	140498052438912 [label=AccumulateGrad]
	140498052439824 -> 140498052439152
	140498052439824 [label=TBackward0]
	140498052438624 -> 140498052439824
	140497794041232 [label="fc.weight
 (1000, 1024)" fillcolor=lightblue]
	140497794041232 -> 140498052438624
	140498052438624 [label=AccumulateGrad]
	140498052439152 -> 140498052392496
}
